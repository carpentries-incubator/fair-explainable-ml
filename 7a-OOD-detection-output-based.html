<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Trustworthy AI: Explainability, Bias, and Fairness: OOD Detection: Overview, Output-Based Methods</title><meta name="viewport" content="width=device-width, initial-scale=1"><script src="assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="assets/styles.css"><script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png"><link rel="manifest" href="site.webmanifest"><link rel="mask-icon" href="safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="black"></head><body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Carpentries Incubator" src="assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text"><li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul></li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/7a-OOD-detection-output-based.html';">Instructor View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Trustworthy AI: Explainability, Bias, and Fairness
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Trustworthy AI: Explainability, Bias, and Fairness
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Trustworthy AI: Explainability, Bias, and Fairness
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 100%" class="percentage">
    100%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 100%" aria-valuenow="100" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text"><li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul></li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/7a-OOD-detection-output-based.html">Instructor View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->

            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="0-introduction.html">1. Overview</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="1-preparing-to-train.html">2. Preparing to train a model</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="2-model-fitting.html">3. Scientific validity in the modeling process</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="3-model-eval-and-fairness.html">4. Model evaluation and fairness</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="4-explainability-vs-interpretability.html">5. Interpretablility versus explainability</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="5a-explainable-AI-method-overview.html">6. Explainability methods overview</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="5b-deep-dive-into-methods.html">7. Explainability methods: deep dive</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="5c-probes.html">8. Explainability methods: linear probe</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="5d-gradcam.html">9. Explainability methods: GradCAM</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush11">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading11">
        <a href="6-confidence-intervals.html">10. Estimating model uncertainty</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        11. OOD Detection: Overview, Output-Based Methods
        </span>
      
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush13">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading13">
        <a href="7b-OOD-detection-distance-based.html">12. OOD Detection: Distance-Based and Contrastive Learning</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush14">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading14">
        <a href="7c-OOD-detection-algo-design.html">13. OOD Detection: Training-Time Regularization</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush15">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading15">
        <a href="8-releasing-a-model.html">14. Documenting and releasing a model</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width resources"><a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">

            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="6-confidence-intervals.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="7b-OOD-detection-distance-based.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="6-confidence-intervals.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Estimating model
        </a>
        <a class="chapter-link float-end" href="7b-OOD-detection-distance-based.html" rel="next">
          Next: OOD Detection:...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>OOD Detection: Overview, Output-Based Methods</h1>
        <p>Last updated on 2024-07-31 |

        <a href="https://github.com/carpentries-incubator/fair-explainable-ml/edit/main/episodes/7a-OOD-detection-output-based.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>



        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>What are out-of-distribution (OOD) data and why is detecting them
important in machine learning models?</li>
<li>How do output-based methods like softmax and energy-based methods
work for OOD detection?</li>
<li>What are the limitations of output-based OOD detection methods?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Understand the concept of out-of-distribution data and its
significance in building trustworthy machine learning models.</li>
<li>Learn about different output-based methods for OOD detection,
including softmax and energy-based methods</li>
<li>Identify the strengths and limitations of output-based OOD detection
techniques.</li>
</ul></div>
</div>
</div>
</div>
</div>
<div class="section level1">
<h1 id="introduction-to-out-of-distribution-ood-data">Introduction to Out-of-Distribution (OOD) Data<a class="anchor" aria-label="anchor" href="#introduction-to-out-of-distribution-ood-data"></a></h1>
<div class="section level2">
<h2 id="what-is-ood-data">What is OOD data?<a class="anchor" aria-label="anchor" href="#what-is-ood-data"></a></h2>
<p>Out-of-distribution (OOD) data refers to data that significantly
differs from the training data on which a machine learning model was
built. The difference can arise from either:</p>
<ul><li>Semantic shift: OOD sample is drawn from a class that was not
present during training</li>
<li>Covariate shift: OOD sample is drawn from a different domain; input
feature distribution is drastically different than training data</li>
</ul><p>When an ML model encounters OOD data, its performance can degrade
significantly because the model is not equipped to handle these
unfamiliar instances.</p>
<p><strong>TODO</strong>: Add closed/open-world image similar to Sharon
Li’s tutorial at 4:28: <a href="https://www.youtube.com/watch?v=hgLC9_9ZCJI" class="external-link uri">https://www.youtube.com/watch?v=hgLC9_9ZCJI</a></p>
</div>
<div class="section level2">
<h2 id="why-does-ood-data-matter">Why does OOD data matter?<a class="anchor" aria-label="anchor" href="#why-does-ood-data-matter"></a></h2>
<p>Model reliability: Models trained on a specific distribution might
make incorrect predictions on OOD data, leading to unreliable outputs.
In critical applications (e.g., healthcare, autonomous driving),
encountering OOD data without proper handling can have severe
consequences.</p>
<div class="section level3">
<h3 id="ex1-tesla-crashes-into-jet">Ex1: Tesla crashes into jet<a class="anchor" aria-label="anchor" href="#ex1-tesla-crashes-into-jet"></a></h3>
<p>In April 2022, a <a href="https://www.newsweek.com/video-tesla-smart-summon-mode-ramming-3m-jet-viewed-34m-times-1700310" class="external-link">Tesla
Model Y crashed into a $3.5 million private jet</a> at an aviation trade
show in Spokane, Washington, while operating on the “Smart Summon”
feature. The feature allows Tesla vehicles to autonomously navigate
parking lots to their owners, but in this case, it resulted in a
significant mishap. - The Tesla was summoned by its owner using the
Tesla app, which requires holding down a button to keep the car moving.
The car continued to move forward even after making contact with the
jet, pushing the expensive aircraft and causing notable damage. - The
crash highlighted several issues with Tesla’s Smart Summon feature,
particularly its object detection capabilities. The system failed to
recognize and appropriately react to the presence of the jet, a problem
that has been observed in other scenarios where the car’s sensors
struggle with objects that are lifted off the ground or have unusual
shapes.</p>
</div>
<div class="section level3">
<h3 id="ex2-ibm-watson-for-oncology">Ex2: IBM Watson for Oncology<a class="anchor" aria-label="anchor" href="#ex2-ibm-watson-for-oncology"></a></h3>
<p>IBM Watson for Oncology faced several issues due to OOD data. The
system was primarily trained on data from Memorial Sloan Kettering
Cancer Center (MSK), which did not generalize well to other healthcare
settings. This led to the following problems: 1. Unsafe Recommendations:
Watson for Oncology provided treatment recommendations that were not
safe or aligned with standard care guidelines in many cases outside of
MSK. This happened because the training data was not representative of
the diverse medical practices and patient populations in different
regions 2. Bias in Training Data: The system’s recommendations were
biased towards the practices at MSK, failing to account for different
treatment protocols and patient needs elsewhere. This bias is a classic
example of an OOD issue, where the model encounters data (patients and
treatments) during deployment that significantly differ from its
training data</p>
</div>
<div class="section level3">
<h3 id="ex3-doctors-using-gpt3">Ex3: Doctors using GPT3<a class="anchor" aria-label="anchor" href="#ex3-doctors-using-gpt3"></a></h3>
<div class="section level4">
<h4 id="misdiagnosis-and-inaccurate-medical-advice">Misdiagnosis and Inaccurate Medical Advice<a class="anchor" aria-label="anchor" href="#misdiagnosis-and-inaccurate-medical-advice"></a></h4>
<p>In various studies and real-world applications, GPT-3 has been shown
to generate inaccurate medical advice when faced with OOD data. This can
be attributed to the fact that the training data, while extensive, does
not cover all possible medical scenarios and nuances, leading to
hallucinations or incorrect responses when encountering unfamiliar
input.</p>
<p>A <a href="https://hai.stanford.edu/news/generating-medical-errors-genai-and-erroneous-medical-references" class="external-link">study
published by researchers at Stanford</a> found that GPT-3, even when
using retrieval-augmented generation, provided unsupported medical
advice in about 30% of its statements. For example, it suggested the use
of a specific dosage for a defibrillator based on monophasic technology,
while the cited source only discussed biphasic technology, which
operates differently.</p>
</div>
<div class="section level4">
<h4 id="fake-medical-literature-references">Fake Medical Literature References<a class="anchor" aria-label="anchor" href="#fake-medical-literature-references"></a></h4>
<p>Another critical OOD issue is the generation of fake or non-existent
medical references by LLMs. When LLMs are prompted to provide citations
for their responses, they sometimes generate references that sound
plausible but do not actually exist. This can be particularly
problematic in academic and medical contexts where accurate sourcing is
crucial.</p>
<p>In <a href="https://hai.stanford.edu/news/generating-medical-errors-genai-and-erroneous-medical-references" class="external-link">evaluations
of GPT-3’s ability to generate medical literature references</a> , it
was found that a significant portion of the references were either
entirely fabricated or did not support the claims being made. This was
especially true for complex medical inquiries that the model had not
seen in its training data. # Detecting and Handling OOD Data Given the
problems posed by OOD data, a reliable model should identify such
instances, and then either: 1. Reject them during inference 2. Hand them
off to a model trained on a more similar distribution (an
in-distribution)</p>
<p>How can we determine whether a given instance is OOD or ID? Over the
past several years, there have been a wide assortment of new methods
developed to tackle this task. In this episode, we will cover a few of
the most common approaches and discuss advantages/disadvantages of
each.</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="threshold-based-methods">Threshold-based methods<a class="anchor" aria-label="anchor" href="#threshold-based-methods"></a></h2>
<p>Threshold-based methods are one of the simplest and most intuitive
approaches for detecting out-of-distribution (OOD) data. The central
idea is to define a threshold on a certain score or confidence measure,
beyond which the data point is considered out-of-distribution.
Typically, these scores are derived from the model’s output
probabilities or other statistical measures of uncertainty. Common
approaches include:</p>
<div class="section level3">
<h3 id="output-based">Output-based<a class="anchor" aria-label="anchor" href="#output-based"></a></h3>
<ul><li>Softmax Scores: The softmax output of a neural network represents
the predicted probabilities for each class. A common threshold-based
method involves setting a confidence threshold, and if the maximum
softmax score of an instance falls below this threshold, it is flagged
as OOD.</li>
<li>Energy: Energy measures the uncertainty in the predicted probability
distribution. High Energy indicates high uncertainty. By setting a
threshold on the Energy value, instances with Energy above the threshold
can be classified as OOD.</li>
</ul></div>
<div class="section level3">
<h3 id="distance-based">Distance-based<a class="anchor" aria-label="anchor" href="#distance-based"></a></h3>
<ul><li>Distance: This method calculates the distance of an instance from
the distribution of training data features. If the distance is beyond a
certain threshold, the instance is considered OOD.</li>
</ul></div>
</div>
</div>
<div class="section level1">
<h1 id="example-1-softmax-scores">Example 1: Softmax scores<a class="anchor" aria-label="anchor" href="#example-1-softmax-scores"></a></h1>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>n_epochs <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>verbose <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>alpha<span class="op">=</span><span class="fl">0.2</span></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="im">from</span> keras.datasets <span class="im">import</span> fashion_mnist</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co"># Load Fashion MNIST dataset</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>(train_images, train_labels), (test_images, test_labels) <span class="op">=</span> fashion_mnist.load_data()</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co"># Define classes for simplicity</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>class_names <span class="op">=</span> [<span class="st">'T-shirt/top'</span>, <span class="st">'Trouser'</span>, <span class="st">'Pullover'</span>, <span class="st">'Dress'</span>, <span class="st">'Coat'</span>,</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>               <span class="st">'Sandal'</span>, <span class="st">'Shirt'</span>, <span class="st">'Sneaker'</span>, <span class="st">'Bag'</span>, <span class="st">'Ankle boot'</span>]</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a><span class="co"># Prepare OOD data - Sandals (5)</span></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>ood_data <span class="op">=</span> test_images[test_labels <span class="op">==</span> <span class="dv">5</span>]</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>ood_labels <span class="op">=</span> test_labels[test_labels <span class="op">==</span> <span class="dv">5</span>]</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'ood_data.shape=</span><span class="sc">{</span>ood_data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a><span class="co"># Filter data for T-shirts (0) and Trousers (1) as in-distribution</span></span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>train_filter <span class="op">=</span> np.isin(train_labels, [<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a>test_filter <span class="op">=</span> np.isin(test_labels, [<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a>train_data <span class="op">=</span> train_images[train_filter]</span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>train_labels <span class="op">=</span> train_labels[train_filter]</span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'train_data.shape=</span><span class="sc">{</span>train_data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a>test_data <span class="op">=</span> test_images[test_filter]</span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a>test_labels <span class="op">=</span> test_labels[test_filter]</span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'test_data.shape=</span><span class="sc">{</span>test_data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-30"><a href="#cb2-30" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" tabindex="-1"></a><span class="co"># Display examples of in-distribution and OOD data</span></span>
<span id="cb2-32"><a href="#cb2-32" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>))</span>
<span id="cb2-33"><a href="#cb2-33" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb2-34"><a href="#cb2-34" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">5</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb2-35"><a href="#cb2-35" tabindex="-1"></a>    plt.imshow(train_data[i], cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb2-36"><a href="#cb2-36" tabindex="-1"></a>    plt.title(<span class="st">"In-Dist"</span>)</span>
<span id="cb2-37"><a href="#cb2-37" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb2-38"><a href="#cb2-38" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb2-39"><a href="#cb2-39" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">5</span>, i <span class="op">+</span> <span class="dv">6</span>)</span>
<span id="cb2-40"><a href="#cb2-40" tabindex="-1"></a>    plt.imshow(ood_data[i], cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb2-41"><a href="#cb2-41" tabindex="-1"></a>    plt.title(<span class="st">"OOD"</span>)</span>
<span id="cb2-42"><a href="#cb2-42" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb2-43"><a href="#cb2-43" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>train_labels[<span class="dv">0</span>:<span class="dv">5</span>] <span class="co"># shirts are 0s, pants are 1s</span></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Flatten images for PCA and logistic regression</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>train_data_flat <span class="op">=</span> train_data.reshape((train_data.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>test_data_flat <span class="op">=</span> test_data.reshape((test_data.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>ood_data_flat <span class="op">=</span> ood_data.reshape((ood_data.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'train_data_flat.shape=</span><span class="sc">{</span>train_data_flat<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'test_data_flat.shape=</span><span class="sc">{</span>test_data_flat<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'ood_data_flat.shape=</span><span class="sc">{</span>ood_data_flat<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span></code></pre>
</div>
<div class="section level2">
<h2 id="visualizing-ood-and-id-data">Visualizing OOD and ID data<a class="anchor" aria-label="anchor" href="#visualizing-ood-and-id-data"></a></h2>
<div class="section level3">
<h3 id="pca">PCA<a class="anchor" aria-label="anchor" href="#pca"></a></h3>
<p>PCA visualization can provide insights into how well a model is
separating ID and OOD data. If the OOD data overlaps significantly with
ID data in the PCA space, it might indicate that the model could
struggle to correctly identify OOD samples.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Perform PCA to visualize the first two principal components</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>train_data_pca <span class="op">=</span> pca.fit_transform(train_data_flat)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>test_data_pca <span class="op">=</span> pca.transform(test_data_flat)</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>ood_data_pca <span class="op">=</span> pca.transform(ood_data_flat)</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co"># Plotting PCA components</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>scatter1 <span class="op">=</span> plt.scatter(train_data_pca[train_labels <span class="op">==</span> <span class="dv">0</span>, <span class="dv">0</span>], train_data_pca[train_labels <span class="op">==</span> <span class="dv">0</span>, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'T-shirts (ID)'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>scatter2 <span class="op">=</span> plt.scatter(train_data_pca[train_labels <span class="op">==</span> <span class="dv">1</span>, <span class="dv">0</span>], train_data_pca[train_labels <span class="op">==</span> <span class="dv">1</span>, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Trousers (ID)'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>scatter3 <span class="op">=</span> plt.scatter(ood_data_pca[:, <span class="dv">0</span>], ood_data_pca[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Sandals (OOD)'</span>, edgecolor<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="co"># Create a single legend for all classes</span></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>plt.legend(handles<span class="op">=</span>[scatter1, scatter2, scatter3], loc<span class="op">=</span><span class="st">"upper right"</span>)</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>plt.xlabel(<span class="st">'First Principal Component'</span>)</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>plt.ylabel(<span class="st">'Second Principal Component'</span>)</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>plt.title(<span class="st">'PCA of In-Distribution and OOD Data'</span>)</span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="umap-or-similar">UMAP (or similar)<a class="anchor" aria-label="anchor" href="#umap-or-similar"></a></h3>
<p>However, PCA also has some limitations that might make other
techniques, such as Uniform Manifold Approximation and Projection
(UMAP), more suitable in certain scenarios:</p>
<ol style="list-style-type: decimal"><li><p><strong>Focus on Linear Relationships</strong>: PCA is a linear
dimensionality reduction technique. It assumes that the directions of
maximum variance in the data can be captured by linear combinations of
the original features. This can be a limitation when the data has
complex, non-linear relationships, as PCA may not capture the true
structure of the data.</p></li>
<li><p><strong>Overlooked Non-Linear Structures</strong>: OOD data might
differ from ID data in non-linear ways that PCA cannot capture. For
instance, if OOD data lies in a non-linear manifold that differs from
the ID data manifold, PCA may not effectively separate them.</p></li>
<li><p><strong>Global Structure vs. Local Structure</strong>: PCA
emphasizes capturing the global variance in the data, which might not be
ideal if the distinctions between ID and OOD data are subtle and local.
In such cases, PCA might not highlight the differences
effectively.</p></li>
<li>
<p><strong>Alternative Methods Like UMAP</strong>:</p>
<ul><li>
<strong>UMAP</strong>: Uniform Manifold Approximation and Projection
(UMAP) is a non-linear dimensionality reduction technique that preserves
both the global structure and the local neighborhood relationships in
the data. UMAP is often better at maintaining the continuity of data
points that lie on non-linear manifolds.</li>
<li>
<strong>Better Clustering</strong>: UMAP tends to provide more
meaningful visualizations for clustering tasks, making it easier to
identify distinct clusters of ID and OOD data.</li>
<li>
<strong>Preservation of Local Distances</strong>: UMAP preserves
local distances more effectively than PCA, which can be crucial for
distinguishing between ID and OOD data that are close in the original
high-dimensional space but separate in the underlying manifold.</li>
</ul></li>
<li><p><strong>Visualization Clarity</strong>: UMAP often provides
clearer and more interpretable visualizations for complex datasets. It
can reveal patterns and structures that PCA might miss, making it a
valuable tool for analyzing ID and OOD distributions.</p></li>
</ol><div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="op">!</span>pip install umap<span class="op">-</span>learn</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">import</span> umap</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co"># Perform UMAP to visualize the data</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>umap_reducer <span class="op">=</span> umap.UMAP(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>combined_data <span class="op">=</span> np.vstack([train_data_flat, ood_data_flat])</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>combined_labels <span class="op">=</span> np.hstack([train_labels, np.full(ood_data_flat.shape[<span class="dv">0</span>], <span class="dv">2</span>)])  <span class="co"># Use 2 for OOD class</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>umap_results <span class="op">=</span> umap_reducer.fit_transform(combined_data)</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="co"># Split the results back into in-distribution and OOD data</span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>umap_in_dist <span class="op">=</span> umap_results[:<span class="bu">len</span>(train_data_flat)]</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>umap_ood <span class="op">=</span> umap_results[<span class="bu">len</span>(train_data_flat):]</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Plotting UMAP components</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co"># Plot in-distribution data</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>scatter1 <span class="op">=</span> plt.scatter(umap_in_dist[train_labels <span class="op">==</span> <span class="dv">0</span>, <span class="dv">0</span>], umap_in_dist[train_labels <span class="op">==</span> <span class="dv">0</span>, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'T-shirts (ID)'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>scatter2 <span class="op">=</span> plt.scatter(umap_in_dist[train_labels <span class="op">==</span> <span class="dv">1</span>, <span class="dv">0</span>], umap_in_dist[train_labels <span class="op">==</span> <span class="dv">1</span>, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Trousers (ID)'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co"># Plot OOD data</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>scatter3 <span class="op">=</span> plt.scatter(umap_ood[:, <span class="dv">0</span>], umap_ood[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Sandals (OOD)'</span>, edgecolor<span class="op">=</span><span class="st">'k'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="co"># Create a single legend for all classes</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>plt.legend(handles<span class="op">=</span>[scatter1, scatter2, scatter3], loc<span class="op">=</span><span class="st">"upper right"</span>)</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>plt.xlabel(<span class="st">'First UMAP Component'</span>)</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>plt.ylabel(<span class="st">'Second UMAP Component'</span>)</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>plt.title(<span class="st">'UMAP of In-Distribution and OOD Data'</span>)</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p>The warning message indicates that UMAP has overridden the n_jobs
parameter to 1 due to the random_state being set. This behavior ensures
reproducibility by using a single job. If you want to avoid the warning
and still use parallelism, you can remove the random_state parameter.
However, removing random_state will mean that the results might not be
reproducible. ## Model-Dependent Visualization The choice of
visualization technique can align with the nature of the model being
used. Here’s how you might frame this idea:</p>
<ul><li><p>Linear Models and PCA: If you’re using a linear model, PCA can be
more appropriate for visualizing in-distribution (ID) and
out-of-distribution (OOD) data because both PCA and linear models
operate under linear assumptions. PCA will effectively capture the main
variance in the data as seen by the linear model, making it easier to
understand the decision boundaries and how OOD data deviates from the ID
data within those boundaries.</p></li>
<li><p>Non-Linear Models and UMAP: For non-linear models, techniques
like UMAP are more suitable because they preserve both local and global
structures in a non-linear fashion, similar to how non-linear models
capture complex relationships in the data. UMAP can provide a more
accurate visualization of the data manifold, highlighting distinctions
between ID and OOD data that may not be apparent with PCA.</p></li>
</ul><div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Train a logistic regression classifier</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">10</span>, solver<span class="op">=</span><span class="st">'lbfgs'</span>, multi_class<span class="op">=</span><span class="st">'multinomial'</span>).fit(train_data_flat, train_labels)</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="co"># # Evaluate the model on in-distribution data</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="co"># in_dist_preds = model.predict(test_data_flat)</span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="co"># in_dist_accuracy = accuracy_score(test_labels, in_dist_preds)</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a><span class="co"># print(f'In-Distribution Accuracy: {in_dist_accuracy:.2f}')</span></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># Predict probabilities using the model on OOD data (Sandals)</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>ood_probs <span class="op">=</span> model.predict_proba(ood_data_flat)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>avg_ood_prob <span class="op">=</span> np.mean(ood_probs, <span class="dv">0</span>)</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Avg. probability of sandal being T-shirt: </span><span class="sc">{</span>avg_ood_prob[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Avg. probability of sandal being trousers: </span><span class="sc">{</span>avg_ood_prob[<span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>id_probs <span class="op">=</span> model.predict_proba(train_data_flat)</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>id_probs_shirts <span class="op">=</span> id_probs[train_labels<span class="op">==</span><span class="dv">0</span>,:]</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>id_probs_pants <span class="op">=</span> id_probs[train_labels<span class="op">==</span><span class="dv">1</span>,:]</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="co"># Creating the figure and subplots</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">4</span>), sharey<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>bins<span class="op">=</span><span class="dv">60</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="co"># Plotting the histogram of probabilities for OOD data (Sandals)</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>axes[<span class="dv">0</span>].hist(ood_probs[:, <span class="dv">0</span>], bins<span class="op">=</span>bins, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'T-shirt probability'</span>)</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Probability'</span>)</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'OOD Data (Sandals)'</span>)</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a><span class="co"># Plotting the histogram of probabilities for ID data (T-shirt)</span></span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>axes[<span class="dv">1</span>].hist(id_probs_shirts[:, <span class="dv">0</span>], bins<span class="op">=</span>bins, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'T-shirt probability'</span>, color<span class="op">=</span><span class="st">'orange'</span>)</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Probability'</span>)</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'ID Data (T-shirt)'</span>)</span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>axes[<span class="dv">1</span>].legend()</span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a><span class="co"># Plotting the histogram of probabilities for ID data (Pants)</span></span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a>axes[<span class="dv">2</span>].hist(id_probs_pants[:, <span class="dv">1</span>], bins<span class="op">=</span>bins, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Pants probability'</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'Probability'</span>)</span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'ID Data (Pants)'</span>)</span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a>axes[<span class="dv">2</span>].legend()</span>
<span id="cb11-24"><a href="#cb11-24" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" tabindex="-1"></a><span class="co"># Adjusting layout</span></span>
<span id="cb11-26"><a href="#cb11-26" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb11-27"><a href="#cb11-27" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" tabindex="-1"></a><span class="co"># Displaying the plot</span></span>
<span id="cb11-29"><a href="#cb11-29" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> gaussian_kde</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="co"># Assuming id_probs_shirts and id_probs_pants are subsets of id_probs</span></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>id_probs_shirts <span class="op">=</span> id_probs[train_labels <span class="op">==</span> <span class="dv">0</span>]</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>id_probs_pants <span class="op">=</span> id_probs[train_labels <span class="op">==</span> <span class="dv">1</span>]</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a><span class="co"># Create figure</span></span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a><span class="co"># Define bins</span></span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a><span class="co"># Plot PDF for ID T-shirt (T-shirt probability)</span></span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>density_id_shirts <span class="op">=</span> gaussian_kde(id_probs_shirts[:, <span class="dv">0</span>])</span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>x_id_shirts <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>plt.plot(x_id_shirts, density_id_shirts(x_id_shirts), label<span class="op">=</span><span class="st">'ID T-shirt (T-shirt probability)'</span>, color<span class="op">=</span><span class="st">'orange'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" tabindex="-1"></a><span class="co"># Plot PDF for ID Pants (Pants probability)</span></span>
<span id="cb12-21"><a href="#cb12-21" tabindex="-1"></a>density_id_pants <span class="op">=</span> gaussian_kde(id_probs_pants[:, <span class="dv">1</span>])</span>
<span id="cb12-22"><a href="#cb12-22" tabindex="-1"></a>x_id_pants <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb12-23"><a href="#cb12-23" tabindex="-1"></a>plt.plot(x_id_pants, density_id_pants(x_id_pants), label<span class="op">=</span><span class="st">'ID Pants (Pants probability)'</span>, color<span class="op">=</span><span class="st">'green'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb12-24"><a href="#cb12-24" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" tabindex="-1"></a><span class="co"># Plot PDF for OOD (T-shirt probability)</span></span>
<span id="cb12-26"><a href="#cb12-26" tabindex="-1"></a>density_ood <span class="op">=</span> gaussian_kde(ood_probs[:, <span class="dv">0</span>])</span>
<span id="cb12-27"><a href="#cb12-27" tabindex="-1"></a>x_ood <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb12-28"><a href="#cb12-28" tabindex="-1"></a>plt.plot(x_ood, density_ood(x_ood), label<span class="op">=</span><span class="st">'OOD (T-shirt probability)'</span>, color<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb12-29"><a href="#cb12-29" tabindex="-1"></a></span>
<span id="cb12-30"><a href="#cb12-30" tabindex="-1"></a><span class="co"># Adding labels and title</span></span>
<span id="cb12-31"><a href="#cb12-31" tabindex="-1"></a>plt.xlabel(<span class="st">'Probability'</span>)</span>
<span id="cb12-32"><a href="#cb12-32" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb12-33"><a href="#cb12-33" tabindex="-1"></a>plt.title(<span class="st">'Probability Density Distributions for OOD and ID Data'</span>)</span>
<span id="cb12-34"><a href="#cb12-34" tabindex="-1"></a>plt.legend()</span>
<span id="cb12-35"><a href="#cb12-35" tabindex="-1"></a></span>
<span id="cb12-36"><a href="#cb12-36" tabindex="-1"></a><span class="co"># Displaying the plot</span></span>
<span id="cb12-37"><a href="#cb12-37" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="co"># Assuming ood_probs, id_probs, and train_labels are defined</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="co"># Threshold values</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>upper_threshold <span class="op">=</span> <span class="fl">0.9999</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="co"># Classifying OOD examples (sandals)</span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>ood_classifications <span class="op">=</span> np.where(ood_probs[:, <span class="dv">1</span>] <span class="op">&gt;=</span> upper_threshold, <span class="dv">1</span>,  <span class="co"># classified as pants</span></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>                               np.where(ood_probs[:, <span class="dv">0</span>] <span class="op">&gt;=</span> upper_threshold, <span class="dv">0</span>,  <span class="co"># classified as shirts</span></span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a>                                        <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as OOD</span></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>ood_classifications</span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a>id_probs</span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a><span class="co"># Classifying ID examples (T-shirts and pants)</span></span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a>id_classifications <span class="op">=</span> np.where(id_probs[:, <span class="dv">1</span>] <span class="op">&gt;=</span> upper_threshold, <span class="dv">1</span>,  <span class="co"># classified as pants</span></span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a>                              np.where(id_probs[:, <span class="dv">0</span>] <span class="op">&gt;=</span> upper_threshold, <span class="dv">0</span>,  <span class="co"># classified as shirts</span></span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a>                                       <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as OOD</span></span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a>id_classifications</span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a><span class="co"># Combine OOD and ID classifications and true labels</span></span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a>all_predictions <span class="op">=</span> np.concatenate([ood_classifications, id_classifications])</span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a>all_true_labels <span class="op">=</span> np.concatenate([<span class="op">-</span><span class="dv">1</span> <span class="op">*</span> np.ones(ood_classifications.shape), train_labels])</span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb13-28"><a href="#cb13-28" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(all_true_labels, all_predictions, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb13-29"><a href="#cb13-29" tabindex="-1"></a></span>
<span id="cb13-30"><a href="#cb13-30" tabindex="-1"></a><span class="co"># Plotting the confusion matrix</span></span>
<span id="cb13-31"><a href="#cb13-31" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>[<span class="st">"Shirt"</span>, <span class="st">"Pants"</span>, <span class="st">"OOD"</span>])</span>
<span id="cb13-32"><a href="#cb13-32" tabindex="-1"></a>disp.plot(cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb13-33"><a href="#cb13-33" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix for OOD and ID Classification'</span>)</span>
<span id="cb13-34"><a href="#cb13-34" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p>With a very conservative threshold, we can make sure very few OOD
samples are incorrectly classified as ID. However, the flip side is that
conservative thresholds tend to incorrectly classify many ID samples as
being OOD. In this case, we incorrectly assume almost 20% of shirts are
OOD samples.</p>
<p>Quick exercise: What threhsold is required to ensure that no OOD
samples are incorrectly considered as IID? What percentage of ID samples
are mistaken as OOD at this threshold? Answer: 0.9999,
(3826+2414)/(3826+2414+2174+3586)=52% ## Iterative Threshold
Determination (setup as exercise?)</p>
<p>In practice, selecting an appropriate threshold is an iterative
process that balances the trade-off between correctly identifying
in-distribution (ID) data and accurately flagging out-of-distribution
(OOD) data. Here’s how you can iteratively determine the threshold:</p>
<ul><li><p>Define Evaluation Metrics: Decide on the performance metrics you
want to optimize, such as accuracy, precision, recall, or the F1 score
for both ID and OOD detection.</p></li>
<li><p>Evaluate Over a Range of Thresholds: Test different threshold
values and evaluate the performance on a validation set containing both
ID and OOD data.</p></li>
<li><p>Select the Optimal Threshold: Choose the threshold that provides
the best balance according to your chosen metrics.</p></li>
</ul><p><strong>Possible exercise (might not be our first priority since
these methods aren’t as popular anymore)</strong>: Use the below code to
determine what threshold should be set to ensure precision = 100%. What
threshold is required for recall to be 100%? What threshold gives the
highest F1 score?</p>
<p>Note: F1 scores can be calculated per class, and then averaged in
different ways (macro, micro, or weighted) when dealing with multiclass
or multilabel classification problems. Here are the key types of
averaging methods:</p>
<ul><li><p>Macro-Averaging: Calculates the F1 score for each class
independently and then takes the average of these scores. This treats
all classes equally, regardless of their support (number of true
instances for each class).</p></li>
<li><p>Micro-Averaging: Aggregates the contributions of all classes to
compute the average F1 score. This is typically used for imbalanced
datasets as it gives more weight to classes with more
instances.</p></li>
<li><p>Weighted-Averaging: Calculates the F1 score for each class
independently and then takes the average, weighted by the number of true
instances for each class. This accounts for class imbalance by giving
more weight to classes with more instances.</p></li>
</ul><div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_fscore_support, accuracy_score, confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a><span class="co"># Define thresholds to evaluate</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>thresholds <span class="op">=</span> np.linspace(<span class="fl">.5</span>, <span class="dv">1</span>, <span class="dv">50</span>)</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="co"># Store evaluation metrics for each threshold</span></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>accuracies <span class="op">=</span> []</span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>precisions <span class="op">=</span> []</span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a>recalls <span class="op">=</span> []</span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a>f1_scores <span class="op">=</span> []</span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a><span class="cf">for</span> threshold <span class="kw">in</span> thresholds:</span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a>  <span class="co"># threshold = 1</span></span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a>  <span class="co"># Classify OOD examples</span></span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a>  ood_classifications <span class="op">=</span> np.where(ood_probs[:, <span class="dv">1</span>] <span class="op">&gt;=</span> threshold, <span class="dv">1</span>,  <span class="co"># classified as pants</span></span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a>                                  np.where(ood_probs[:, <span class="dv">0</span>] <span class="op">&gt;=</span> threshold, <span class="dv">0</span>,  <span class="co"># classified as shirts</span></span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a>                                          <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as OOD</span></span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a>  <span class="co"># Classify ID examples</span></span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a>  id_classifications <span class="op">=</span> np.where(id_probs[:, <span class="dv">1</span>] <span class="op">&gt;=</span> threshold, <span class="dv">1</span>,  <span class="co"># classified as pants</span></span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a>                                np.where(id_probs[:, <span class="dv">0</span>] <span class="op">&gt;=</span> threshold, <span class="dv">0</span>,  <span class="co"># classified as shirts</span></span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a>                                          <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as OOD</span></span>
<span id="cb14-26"><a href="#cb14-26" tabindex="-1"></a></span>
<span id="cb14-27"><a href="#cb14-27" tabindex="-1"></a>  <span class="co"># Combine OOD and ID classifications and true labels</span></span>
<span id="cb14-28"><a href="#cb14-28" tabindex="-1"></a>  all_predictions <span class="op">=</span> np.concatenate([ood_classifications, id_classifications])</span>
<span id="cb14-29"><a href="#cb14-29" tabindex="-1"></a>  all_true_labels <span class="op">=</span> np.concatenate([<span class="op">-</span><span class="dv">1</span> <span class="op">*</span> np.ones(ood_classifications.shape), train_labels])</span>
<span id="cb14-30"><a href="#cb14-30" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" tabindex="-1"></a>  <span class="co"># Evaluate metrics</span></span>
<span id="cb14-32"><a href="#cb14-32" tabindex="-1"></a>  precision, recall, f1, _ <span class="op">=</span> precision_recall_fscore_support(all_true_labels, all_predictions, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>], average<span class="op">=</span><span class="st">'macro'</span>) <span class="co"># discuss macro vs micro .</span></span>
<span id="cb14-33"><a href="#cb14-33" tabindex="-1"></a>  accuracy <span class="op">=</span> accuracy_score(all_true_labels, all_predictions)</span>
<span id="cb14-34"><a href="#cb14-34" tabindex="-1"></a></span>
<span id="cb14-35"><a href="#cb14-35" tabindex="-1"></a>  accuracies.append(accuracy)</span>
<span id="cb14-36"><a href="#cb14-36" tabindex="-1"></a>  precisions.append(precision)</span>
<span id="cb14-37"><a href="#cb14-37" tabindex="-1"></a>  recalls.append(recall)</span>
<span id="cb14-38"><a href="#cb14-38" tabindex="-1"></a>  f1_scores.append(f1)</span>
<span id="cb14-39"><a href="#cb14-39" tabindex="-1"></a></span>
<span id="cb14-40"><a href="#cb14-40" tabindex="-1"></a><span class="co"># Find the best thresholds for each metric</span></span>
<span id="cb14-41"><a href="#cb14-41" tabindex="-1"></a>best_f1_index <span class="op">=</span> np.argmax(f1_scores)</span>
<span id="cb14-42"><a href="#cb14-42" tabindex="-1"></a>best_f1_threshold <span class="op">=</span> thresholds[best_f1_index]</span>
<span id="cb14-43"><a href="#cb14-43" tabindex="-1"></a></span>
<span id="cb14-44"><a href="#cb14-44" tabindex="-1"></a>best_precision_index <span class="op">=</span> np.argmax(precisions)</span>
<span id="cb14-45"><a href="#cb14-45" tabindex="-1"></a>best_precision_threshold <span class="op">=</span> thresholds[best_precision_index]</span>
<span id="cb14-46"><a href="#cb14-46" tabindex="-1"></a></span>
<span id="cb14-47"><a href="#cb14-47" tabindex="-1"></a>best_recall_index <span class="op">=</span> np.argmax(recalls)</span>
<span id="cb14-48"><a href="#cb14-48" tabindex="-1"></a>best_recall_threshold <span class="op">=</span> thresholds[best_recall_index]</span>
<span id="cb14-49"><a href="#cb14-49" tabindex="-1"></a></span>
<span id="cb14-50"><a href="#cb14-50" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best F1 threshold: </span><span class="sc">{</span>best_f1_threshold<span class="sc">}</span><span class="ss">, F1 Score: </span><span class="sc">{</span>f1_scores[best_f1_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-51"><a href="#cb14-51" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Precision threshold: </span><span class="sc">{</span>best_precision_threshold<span class="sc">}</span><span class="ss">, Precision: </span><span class="sc">{</span>precisions[best_precision_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-52"><a href="#cb14-52" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Recall threshold: </span><span class="sc">{</span>best_recall_threshold<span class="sc">}</span><span class="ss">, Recall: </span><span class="sc">{</span>recalls[best_recall_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-53"><a href="#cb14-53" tabindex="-1"></a></span>
<span id="cb14-54"><a href="#cb14-54" tabindex="-1"></a><span class="co"># Plot metrics as functions of the threshold</span></span>
<span id="cb14-55"><a href="#cb14-55" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb14-56"><a href="#cb14-56" tabindex="-1"></a>plt.plot(thresholds, precisions, label<span class="op">=</span><span class="st">'Precision'</span>, color<span class="op">=</span><span class="st">'g'</span>)</span>
<span id="cb14-57"><a href="#cb14-57" tabindex="-1"></a>plt.plot(thresholds, recalls, label<span class="op">=</span><span class="st">'Recall'</span>, color<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb14-58"><a href="#cb14-58" tabindex="-1"></a>plt.plot(thresholds, f1_scores, label<span class="op">=</span><span class="st">'F1 Score'</span>, color<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb14-59"><a href="#cb14-59" tabindex="-1"></a></span>
<span id="cb14-60"><a href="#cb14-60" tabindex="-1"></a><span class="co"># Add best threshold indicators</span></span>
<span id="cb14-61"><a href="#cb14-61" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>best_f1_threshold, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best F1 Threshold: </span><span class="sc">{</span>best_f1_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb14-62"><a href="#cb14-62" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>best_precision_threshold, color<span class="op">=</span><span class="st">'g'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best Precision Threshold: </span><span class="sc">{</span>best_precision_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb14-63"><a href="#cb14-63" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>best_recall_threshold, color<span class="op">=</span><span class="st">'b'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best Recall Threshold: </span><span class="sc">{</span>best_recall_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb14-64"><a href="#cb14-64" tabindex="-1"></a></span>
<span id="cb14-65"><a href="#cb14-65" tabindex="-1"></a>plt.xlabel(<span class="st">'Threshold'</span>)</span>
<span id="cb14-66"><a href="#cb14-66" tabindex="-1"></a>plt.ylabel(<span class="st">'Metric Value'</span>)</span>
<span id="cb14-67"><a href="#cb14-67" tabindex="-1"></a>plt.title(<span class="st">'Evaluation Metrics as Functions of Threshold'</span>)</span>
<span id="cb14-68"><a href="#cb14-68" tabindex="-1"></a>plt.legend()</span>
<span id="cb14-69"><a href="#cb14-69" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a><span class="co"># Assuming ood_probs, id_probs, and train_labels are defined</span></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a><span class="co"># Threshold values</span></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>upper_threshold <span class="op">=</span> best_f1_threshold</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a><span class="co"># Classifying OOD examples (sandals)</span></span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>ood_classifications <span class="op">=</span> np.where(ood_probs[:, <span class="dv">1</span>] <span class="op">&gt;=</span> upper_threshold, <span class="dv">1</span>,  <span class="co"># classified as pants</span></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a>                               np.where(ood_probs[:, <span class="dv">0</span>] <span class="op">&gt;=</span> upper_threshold, <span class="dv">0</span>,  <span class="co"># classified as shirts</span></span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a>                                        <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as OOD</span></span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a>ood_classifications</span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a>id_probs</span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a><span class="co"># Classifying ID examples (T-shirts and pants)</span></span>
<span id="cb15-17"><a href="#cb15-17" tabindex="-1"></a>id_classifications <span class="op">=</span> np.where(id_probs[:, <span class="dv">1</span>] <span class="op">&gt;=</span> upper_threshold, <span class="dv">1</span>,  <span class="co"># classified as pants</span></span>
<span id="cb15-18"><a href="#cb15-18" tabindex="-1"></a>                              np.where(id_probs[:, <span class="dv">0</span>] <span class="op">&gt;=</span> upper_threshold, <span class="dv">0</span>,  <span class="co"># classified as shirts</span></span>
<span id="cb15-19"><a href="#cb15-19" tabindex="-1"></a>                                       <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as OOD</span></span>
<span id="cb15-20"><a href="#cb15-20" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" tabindex="-1"></a>id_classifications</span>
<span id="cb15-22"><a href="#cb15-22" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" tabindex="-1"></a><span class="co"># Combine OOD and ID classifications and true labels</span></span>
<span id="cb15-24"><a href="#cb15-24" tabindex="-1"></a>all_predictions <span class="op">=</span> np.concatenate([ood_classifications, id_classifications])</span>
<span id="cb15-25"><a href="#cb15-25" tabindex="-1"></a>all_true_labels <span class="op">=</span> np.concatenate([<span class="op">-</span><span class="dv">1</span> <span class="op">*</span> np.ones(ood_classifications.shape), train_labels])</span>
<span id="cb15-26"><a href="#cb15-26" tabindex="-1"></a></span>
<span id="cb15-27"><a href="#cb15-27" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb15-28"><a href="#cb15-28" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(all_true_labels, all_predictions, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb15-29"><a href="#cb15-29" tabindex="-1"></a></span>
<span id="cb15-30"><a href="#cb15-30" tabindex="-1"></a><span class="co"># Plotting the confusion matrix</span></span>
<span id="cb15-31"><a href="#cb15-31" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>[<span class="st">"Shirt"</span>, <span class="st">"Pants"</span>, <span class="st">"OOD"</span>])</span>
<span id="cb15-32"><a href="#cb15-32" tabindex="-1"></a>disp.plot(cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb15-33"><a href="#cb15-33" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix for OOD and ID Classification'</span>)</span>
<span id="cb15-34"><a href="#cb15-34" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
</div>
</div>
</div>
<div class="section level1">
<h1 id="example-2-energy-based-ood-detection">Example 2: Energy-Based OOD Detection<a class="anchor" aria-label="anchor" href="#example-2-energy-based-ood-detection"></a></h1>
<p>Liu et al., Energy-based Out-of-distribution Detection, NeurIPS 2020;
<a href="https://arxiv.org/pdf/2010.03759" class="external-link uri">https://arxiv.org/pdf/2010.03759</a></p>
<ul><li><p>E(x, y) = energy value</p></li>
<li><p>if x and y are “compatitble”, lower energy</p></li>
<li>
<p>Energy can be turned into probability through Gibbs
distribution</p>
<ul><li>looks at integral over all possible y’s</li>
</ul></li>
<li><p>With energy scores, ID and OOD distributions become much more
separable</p></li>
<li><p>Another “output-based” method like softmax</p></li>
</ul><div class="section level2">
<h2 id="pytorch-out-of-distribution-detection">PyTorch Out-of-Distribution Detection<a class="anchor" aria-label="anchor" href="#pytorch-out-of-distribution-detection"></a></h2>
<p>There’s a Pytorch package for OOD detection! <a href="https://pytorch-ood.readthedocs.io/en/latest/info.html" class="external-link uri">https://pytorch-ood.readthedocs.io/en/latest/info.html</a></p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="op">!</span>pip install pytorch<span class="op">-</span>ood</span></code></pre>
</div>
<div class="section level3">
<h3 id="energy-based-is-designed-to-work-with-neural-nets-unpack-this-">Energy-based is designed to work with neural nets… unpack this.<a class="anchor" aria-label="anchor" href="#energy-based-is-designed-to-work-with-neural-nets-unpack-this-"></a></h3>
<p>Let’s train a simple CNN model on the FashionMNIST dataset.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a><span class="im">from</span> keras.datasets <span class="im">import</span> fashion_mnist</span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a><span class="co"># Load Fashion MNIST dataset</span></span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a>(train_images, train_labels), (test_images, test_labels) <span class="op">=</span> fashion_mnist.load_data()</span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" tabindex="-1"></a><span class="co"># Define classes for simplicity</span></span>
<span id="cb17-14"><a href="#cb17-14" tabindex="-1"></a>class_names <span class="op">=</span> [<span class="st">'T-shirt/top'</span>, <span class="st">'Trouser'</span>, <span class="st">'Pullover'</span>, <span class="st">'Dress'</span>, <span class="st">'Coat'</span>,</span>
<span id="cb17-15"><a href="#cb17-15" tabindex="-1"></a>               <span class="st">'Sandal'</span>, <span class="st">'Shirt'</span>, <span class="st">'Sneaker'</span>, <span class="st">'Bag'</span>, <span class="st">'Ankle boot'</span>]</span>
<span id="cb17-16"><a href="#cb17-16" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" tabindex="-1"></a><span class="co"># Prepare OOD data - Sandals (5)</span></span>
<span id="cb17-18"><a href="#cb17-18" tabindex="-1"></a>ood_data <span class="op">=</span> test_images[test_labels <span class="op">==</span> <span class="dv">5</span>]</span>
<span id="cb17-19"><a href="#cb17-19" tabindex="-1"></a>ood_labels <span class="op">=</span> test_labels[test_labels <span class="op">==</span> <span class="dv">5</span>]</span>
<span id="cb17-20"><a href="#cb17-20" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'ood_data.shape=</span><span class="sc">{</span>ood_data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb17-21"><a href="#cb17-21" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" tabindex="-1"></a><span class="co"># Filter data for T-shirts (0) and Trousers (1) as in-distribution</span></span>
<span id="cb17-23"><a href="#cb17-23" tabindex="-1"></a>train_filter <span class="op">=</span> np.isin(train_labels, [<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb17-24"><a href="#cb17-24" tabindex="-1"></a>test_filter <span class="op">=</span> np.isin(test_labels, [<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb17-25"><a href="#cb17-25" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" tabindex="-1"></a>train_data <span class="op">=</span> train_images[train_filter]</span>
<span id="cb17-27"><a href="#cb17-27" tabindex="-1"></a>train_labels <span class="op">=</span> train_labels[train_filter]</span>
<span id="cb17-28"><a href="#cb17-28" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'train_data.shape=</span><span class="sc">{</span>train_data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb17-29"><a href="#cb17-29" tabindex="-1"></a></span>
<span id="cb17-30"><a href="#cb17-30" tabindex="-1"></a>test_data <span class="op">=</span> test_images[test_filter]</span>
<span id="cb17-31"><a href="#cb17-31" tabindex="-1"></a>test_labels <span class="op">=</span> test_labels[test_filter]</span>
<span id="cb17-32"><a href="#cb17-32" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'test_data.shape=</span><span class="sc">{</span>test_data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb17-33"><a href="#cb17-33" tabindex="-1"></a></span>
<span id="cb17-34"><a href="#cb17-34" tabindex="-1"></a><span class="co"># Transform to Tensor and normalize</span></span>
<span id="cb17-35"><a href="#cb17-35" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb17-36"><a href="#cb17-36" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb17-37"><a href="#cb17-37" tabindex="-1"></a>    transforms.Normalize((<span class="fl">0.5</span>,), (<span class="fl">0.5</span>,))</span>
<span id="cb17-38"><a href="#cb17-38" tabindex="-1"></a>])</span>
<span id="cb17-39"><a href="#cb17-39" tabindex="-1"></a></span>
<span id="cb17-40"><a href="#cb17-40" tabindex="-1"></a><span class="co"># Convert to PyTorch tensors and normalize</span></span>
<span id="cb17-41"><a href="#cb17-41" tabindex="-1"></a>train_data_tensor <span class="op">=</span> torch.tensor(train_data, dtype<span class="op">=</span>torch.float32).unsqueeze(<span class="dv">1</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb17-42"><a href="#cb17-42" tabindex="-1"></a>test_data_tensor <span class="op">=</span> torch.tensor(test_data, dtype<span class="op">=</span>torch.float32).unsqueeze(<span class="dv">1</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb17-43"><a href="#cb17-43" tabindex="-1"></a>ood_data_tensor <span class="op">=</span> torch.tensor(ood_data, dtype<span class="op">=</span>torch.float32).unsqueeze(<span class="dv">1</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb17-44"><a href="#cb17-44" tabindex="-1"></a></span>
<span id="cb17-45"><a href="#cb17-45" tabindex="-1"></a>train_labels_tensor <span class="op">=</span> torch.tensor(train_labels, dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb17-46"><a href="#cb17-46" tabindex="-1"></a>test_labels_tensor <span class="op">=</span> torch.tensor(test_labels, dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb17-47"><a href="#cb17-47" tabindex="-1"></a></span>
<span id="cb17-48"><a href="#cb17-48" tabindex="-1"></a>train_dataset <span class="op">=</span> torch.utils.data.TensorDataset(train_data_tensor, train_labels_tensor)</span>
<span id="cb17-49"><a href="#cb17-49" tabindex="-1"></a>test_dataset <span class="op">=</span> torch.utils.data.TensorDataset(test_data_tensor, test_labels_tensor)</span>
<span id="cb17-50"><a href="#cb17-50" tabindex="-1"></a>ood_dataset <span class="op">=</span> torch.utils.data.TensorDataset(ood_data_tensor, torch.zeros(ood_data_tensor.shape[<span class="dv">0</span>], dtype<span class="op">=</span>torch.<span class="bu">long</span>))</span>
<span id="cb17-51"><a href="#cb17-51" tabindex="-1"></a></span>
<span id="cb17-52"><a href="#cb17-52" tabindex="-1"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(train_dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-53"><a href="#cb17-53" tabindex="-1"></a>test_loader <span class="op">=</span> torch.utils.data.DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-54"><a href="#cb17-54" tabindex="-1"></a>ood_loader <span class="op">=</span> torch.utils.data.DataLoader(ood_dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-55"><a href="#cb17-55" tabindex="-1"></a></span>
<span id="cb17-56"><a href="#cb17-56" tabindex="-1"></a><span class="co"># Define a simple CNN model</span></span>
<span id="cb17-57"><a href="#cb17-57" tabindex="-1"></a><span class="kw">class</span> SimpleCNN(nn.Module):</span>
<span id="cb17-58"><a href="#cb17-58" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb17-59"><a href="#cb17-59" tabindex="-1"></a>        <span class="bu">super</span>(SimpleCNN, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb17-60"><a href="#cb17-60" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">1</span>, <span class="dv">32</span>, kernel_size<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb17-61"><a href="#cb17-61" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">32</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb17-62"><a href="#cb17-62" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">64</span><span class="op">*</span><span class="dv">5</span><span class="op">*</span><span class="dv">5</span>, <span class="dv">128</span>)  <span class="co"># Updated this line</span></span>
<span id="cb17-63"><a href="#cb17-63" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">128</span>, <span class="dv">2</span>)</span>
<span id="cb17-64"><a href="#cb17-64" tabindex="-1"></a></span>
<span id="cb17-65"><a href="#cb17-65" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb17-66"><a href="#cb17-66" tabindex="-1"></a>        x <span class="op">=</span> F.relu(F.max_pool2d(<span class="va">self</span>.conv1(x), <span class="dv">2</span>))</span>
<span id="cb17-67"><a href="#cb17-67" tabindex="-1"></a>        x <span class="op">=</span> F.relu(F.max_pool2d(<span class="va">self</span>.conv2(x), <span class="dv">2</span>))</span>
<span id="cb17-68"><a href="#cb17-68" tabindex="-1"></a>        x <span class="op">=</span> x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">64</span><span class="op">*</span><span class="dv">5</span><span class="op">*</span><span class="dv">5</span>)  <span class="co"># Updated this line</span></span>
<span id="cb17-69"><a href="#cb17-69" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.fc1(x))</span>
<span id="cb17-70"><a href="#cb17-70" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb17-71"><a href="#cb17-71" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb17-72"><a href="#cb17-72" tabindex="-1"></a></span>
<span id="cb17-73"><a href="#cb17-73" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span>)</span>
<span id="cb17-74"><a href="#cb17-74" tabindex="-1"></a>model <span class="op">=</span> SimpleCNN().to(device)</span>
<span id="cb17-75"><a href="#cb17-75" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb17-76"><a href="#cb17-76" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb17-77"><a href="#cb17-77" tabindex="-1"></a></span>
<span id="cb17-78"><a href="#cb17-78" tabindex="-1"></a><span class="kw">def</span> train_model(model, train_loader, criterion, optimizer, epochs<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb17-79"><a href="#cb17-79" tabindex="-1"></a>    model.train()</span>
<span id="cb17-80"><a href="#cb17-80" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb17-81"><a href="#cb17-81" tabindex="-1"></a>        running_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb17-82"><a href="#cb17-82" tabindex="-1"></a>        <span class="cf">for</span> inputs, labels <span class="kw">in</span> train_loader:</span>
<span id="cb17-83"><a href="#cb17-83" tabindex="-1"></a>            inputs, labels <span class="op">=</span> inputs.to(device), labels.to(device)</span>
<span id="cb17-84"><a href="#cb17-84" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb17-85"><a href="#cb17-85" tabindex="-1"></a>            outputs <span class="op">=</span> model(inputs)</span>
<span id="cb17-86"><a href="#cb17-86" tabindex="-1"></a>            loss <span class="op">=</span> criterion(outputs, labels)</span>
<span id="cb17-87"><a href="#cb17-87" tabindex="-1"></a>            loss.backward()</span>
<span id="cb17-88"><a href="#cb17-88" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb17-89"><a href="#cb17-89" tabindex="-1"></a>            running_loss <span class="op">+=</span> loss.item()</span>
<span id="cb17-90"><a href="#cb17-90" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>running_loss<span class="op">/</span><span class="bu">len</span>(train_loader)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb17-91"><a href="#cb17-91" tabindex="-1"></a></span>
<span id="cb17-92"><a href="#cb17-92" tabindex="-1"></a>train_model(model, train_loader, criterion, optimizer)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a><span class="co"># Function to plot confusion matrix</span></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a><span class="kw">def</span> plot_confusion_matrix(labels, predictions, title):</span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>    cm <span class="op">=</span> confusion_matrix(labels, predictions, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>    disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>[<span class="st">"T-shirt/top"</span>, <span class="st">"Trouser"</span>])</span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a>    disp.plot(cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a>    plt.show()</span>
<span id="cb18-10"><a href="#cb18-10" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" tabindex="-1"></a><span class="co"># Function to evaluate model on a dataset</span></span>
<span id="cb18-12"><a href="#cb18-12" tabindex="-1"></a><span class="kw">def</span> evaluate_model(model, dataloader, device):</span>
<span id="cb18-13"><a href="#cb18-13" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb18-14"><a href="#cb18-14" tabindex="-1"></a>    all_labels <span class="op">=</span> []</span>
<span id="cb18-15"><a href="#cb18-15" tabindex="-1"></a>    all_predictions <span class="op">=</span> []</span>
<span id="cb18-16"><a href="#cb18-16" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb18-17"><a href="#cb18-17" tabindex="-1"></a>        <span class="cf">for</span> inputs, labels <span class="kw">in</span> dataloader:</span>
<span id="cb18-18"><a href="#cb18-18" tabindex="-1"></a>            inputs, labels <span class="op">=</span> inputs.to(device), labels.to(device)</span>
<span id="cb18-19"><a href="#cb18-19" tabindex="-1"></a>            outputs <span class="op">=</span> model(inputs)</span>
<span id="cb18-20"><a href="#cb18-20" tabindex="-1"></a>            _, preds <span class="op">=</span> torch.<span class="bu">max</span>(outputs, <span class="dv">1</span>)</span>
<span id="cb18-21"><a href="#cb18-21" tabindex="-1"></a>            all_labels.extend(labels.cpu().numpy())</span>
<span id="cb18-22"><a href="#cb18-22" tabindex="-1"></a>            all_predictions.extend(preds.cpu().numpy())</span>
<span id="cb18-23"><a href="#cb18-23" tabindex="-1"></a>    <span class="cf">return</span> np.array(all_labels), np.array(all_predictions)</span>
<span id="cb18-24"><a href="#cb18-24" tabindex="-1"></a></span>
<span id="cb18-25"><a href="#cb18-25" tabindex="-1"></a><span class="co"># Evaluate on train data</span></span>
<span id="cb18-26"><a href="#cb18-26" tabindex="-1"></a>train_labels, train_predictions <span class="op">=</span> evaluate_model(model, train_loader, device)</span>
<span id="cb18-27"><a href="#cb18-27" tabindex="-1"></a>plot_confusion_matrix(train_labels, train_predictions, <span class="st">"Confusion Matrix for Train Data"</span>)</span>
<span id="cb18-28"><a href="#cb18-28" tabindex="-1"></a></span>
<span id="cb18-29"><a href="#cb18-29" tabindex="-1"></a><span class="co"># Evaluate on test data</span></span>
<span id="cb18-30"><a href="#cb18-30" tabindex="-1"></a>test_labels, test_predictions <span class="op">=</span> evaluate_model(model, test_loader, device)</span>
<span id="cb18-31"><a href="#cb18-31" tabindex="-1"></a>plot_confusion_matrix(test_labels, test_predictions, <span class="st">"Confusion Matrix for Test Data"</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> gaussian_kde</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a><span class="im">from</span> pytorch_ood.detector <span class="im">import</span> EnergyBased</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_fscore_support, accuracy_score</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a><span class="co"># Compute softmax scores</span></span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a><span class="kw">def</span> get_softmax_scores(model, dataloader):</span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb19-8"><a href="#cb19-8" tabindex="-1"></a>    softmax_scores <span class="op">=</span> []</span>
<span id="cb19-9"><a href="#cb19-9" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-10"><a href="#cb19-10" tabindex="-1"></a>        <span class="cf">for</span> inputs, _ <span class="kw">in</span> dataloader:</span>
<span id="cb19-11"><a href="#cb19-11" tabindex="-1"></a>            inputs <span class="op">=</span> inputs.to(device)</span>
<span id="cb19-12"><a href="#cb19-12" tabindex="-1"></a>            outputs <span class="op">=</span> model(inputs)</span>
<span id="cb19-13"><a href="#cb19-13" tabindex="-1"></a>            softmax <span class="op">=</span> torch.nn.functional.softmax(outputs, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-14"><a href="#cb19-14" tabindex="-1"></a>            softmax_scores.extend(softmax.cpu().numpy())</span>
<span id="cb19-15"><a href="#cb19-15" tabindex="-1"></a>    <span class="cf">return</span> np.array(softmax_scores)</span>
<span id="cb19-16"><a href="#cb19-16" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" tabindex="-1"></a>id_softmax_scores <span class="op">=</span> get_softmax_scores(model, test_loader)</span>
<span id="cb19-18"><a href="#cb19-18" tabindex="-1"></a>ood_softmax_scores <span class="op">=</span> get_softmax_scores(model, ood_loader)</span>
<span id="cb19-19"><a href="#cb19-19" tabindex="-1"></a></span>
<span id="cb19-20"><a href="#cb19-20" tabindex="-1"></a><span class="co"># Initialize the energy-based OOD detector</span></span>
<span id="cb19-21"><a href="#cb19-21" tabindex="-1"></a>energy_detector <span class="op">=</span> EnergyBased(model, t<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb19-22"><a href="#cb19-22" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" tabindex="-1"></a><span class="co"># Compute energy scores</span></span>
<span id="cb19-24"><a href="#cb19-24" tabindex="-1"></a><span class="kw">def</span> get_energy_scores(detector, dataloader):</span>
<span id="cb19-25"><a href="#cb19-25" tabindex="-1"></a>    scores <span class="op">=</span> []</span>
<span id="cb19-26"><a href="#cb19-26" tabindex="-1"></a>    detector.model.<span class="bu">eval</span>()</span>
<span id="cb19-27"><a href="#cb19-27" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-28"><a href="#cb19-28" tabindex="-1"></a>        <span class="cf">for</span> inputs, _ <span class="kw">in</span> dataloader:</span>
<span id="cb19-29"><a href="#cb19-29" tabindex="-1"></a>            inputs <span class="op">=</span> inputs.to(device)</span>
<span id="cb19-30"><a href="#cb19-30" tabindex="-1"></a>            score <span class="op">=</span> detector.predict(inputs)</span>
<span id="cb19-31"><a href="#cb19-31" tabindex="-1"></a>            scores.extend(score.cpu().numpy())</span>
<span id="cb19-32"><a href="#cb19-32" tabindex="-1"></a>    <span class="cf">return</span> np.array(scores)</span>
<span id="cb19-33"><a href="#cb19-33" tabindex="-1"></a></span>
<span id="cb19-34"><a href="#cb19-34" tabindex="-1"></a>id_energy_scores <span class="op">=</span> get_energy_scores(energy_detector, test_loader)</span>
<span id="cb19-35"><a href="#cb19-35" tabindex="-1"></a>ood_energy_scores <span class="op">=</span> get_energy_scores(energy_detector, ood_loader)</span>
<span id="cb19-36"><a href="#cb19-36" tabindex="-1"></a></span>
<span id="cb19-37"><a href="#cb19-37" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-38"><a href="#cb19-38" tabindex="-1"></a></span>
<span id="cb19-39"><a href="#cb19-39" tabindex="-1"></a></span>
<span id="cb19-40"><a href="#cb19-40" tabindex="-1"></a><span class="co"># Plot PSDs</span></span>
<span id="cb19-41"><a href="#cb19-41" tabindex="-1"></a></span>
<span id="cb19-42"><a href="#cb19-42" tabindex="-1"></a><span class="co"># Function to plot PSD</span></span>
<span id="cb19-43"><a href="#cb19-43" tabindex="-1"></a><span class="kw">def</span> plot_psd(id_scores, ood_scores, method_name):</span>
<span id="cb19-44"><a href="#cb19-44" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb19-45"><a href="#cb19-45" tabindex="-1"></a>    alpha <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb19-46"><a href="#cb19-46" tabindex="-1"></a></span>
<span id="cb19-47"><a href="#cb19-47" tabindex="-1"></a>    <span class="co"># Plot PSD for ID scores</span></span>
<span id="cb19-48"><a href="#cb19-48" tabindex="-1"></a>    id_density <span class="op">=</span> gaussian_kde(id_scores)</span>
<span id="cb19-49"><a href="#cb19-49" tabindex="-1"></a>    x_id <span class="op">=</span> np.linspace(id_scores.<span class="bu">min</span>(), id_scores.<span class="bu">max</span>(), <span class="dv">1000</span>)</span>
<span id="cb19-50"><a href="#cb19-50" tabindex="-1"></a>    plt.plot(x_id, id_density(x_id), label<span class="op">=</span><span class="ss">f'ID (</span><span class="sc">{</span>method_name<span class="sc">}</span><span class="ss">)'</span>, color<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-51"><a href="#cb19-51" tabindex="-1"></a></span>
<span id="cb19-52"><a href="#cb19-52" tabindex="-1"></a>    <span class="co"># Plot PSD for OOD scores</span></span>
<span id="cb19-53"><a href="#cb19-53" tabindex="-1"></a>    ood_density <span class="op">=</span> gaussian_kde(ood_scores)</span>
<span id="cb19-54"><a href="#cb19-54" tabindex="-1"></a>    x_ood <span class="op">=</span> np.linspace(ood_scores.<span class="bu">min</span>(), ood_scores.<span class="bu">max</span>(), <span class="dv">1000</span>)</span>
<span id="cb19-55"><a href="#cb19-55" tabindex="-1"></a>    plt.plot(x_ood, ood_density(x_ood), label<span class="op">=</span><span class="ss">f'OOD (</span><span class="sc">{</span>method_name<span class="sc">}</span><span class="ss">)'</span>, color<span class="op">=</span><span class="st">'red'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb19-56"><a href="#cb19-56" tabindex="-1"></a></span>
<span id="cb19-57"><a href="#cb19-57" tabindex="-1"></a>    plt.xlabel(<span class="st">'Score'</span>)</span>
<span id="cb19-58"><a href="#cb19-58" tabindex="-1"></a>    plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb19-59"><a href="#cb19-59" tabindex="-1"></a>    plt.title(<span class="ss">f'Probability Density Distributions for </span><span class="sc">{</span>method_name<span class="sc">}</span><span class="ss"> Scores'</span>)</span>
<span id="cb19-60"><a href="#cb19-60" tabindex="-1"></a>    plt.legend()</span>
<span id="cb19-61"><a href="#cb19-61" tabindex="-1"></a>    plt.show()</span>
<span id="cb19-62"><a href="#cb19-62" tabindex="-1"></a></span>
<span id="cb19-63"><a href="#cb19-63" tabindex="-1"></a><span class="co"># Plot PSD for softmax scores</span></span>
<span id="cb19-64"><a href="#cb19-64" tabindex="-1"></a>plot_psd(id_softmax_scores[:, <span class="dv">1</span>], ood_softmax_scores[:, <span class="dv">1</span>], <span class="st">'Softmax'</span>)</span>
<span id="cb19-65"><a href="#cb19-65" tabindex="-1"></a></span>
<span id="cb19-66"><a href="#cb19-66" tabindex="-1"></a><span class="co"># Plot PSD for energy scores</span></span>
<span id="cb19-67"><a href="#cb19-67" tabindex="-1"></a>plot_psd(id_energy_scores, ood_energy_scores, <span class="st">'Energy'</span>)</span>
<span id="cb19-68"><a href="#cb19-68" tabindex="-1"></a></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_fscore_support, accuracy_score, confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a><span class="co"># Define thresholds to evaluate</span></span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a>thresholds <span class="op">=</span> np.linspace(id_energy_scores.<span class="bu">min</span>(), id_energy_scores.<span class="bu">max</span>(), <span class="dv">50</span>)</span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" tabindex="-1"></a><span class="co"># Store evaluation metrics for each threshold</span></span>
<span id="cb20-9"><a href="#cb20-9" tabindex="-1"></a>accuracies <span class="op">=</span> []</span>
<span id="cb20-10"><a href="#cb20-10" tabindex="-1"></a>precisions <span class="op">=</span> []</span>
<span id="cb20-11"><a href="#cb20-11" tabindex="-1"></a>recalls <span class="op">=</span> []</span>
<span id="cb20-12"><a href="#cb20-12" tabindex="-1"></a>f1_scores <span class="op">=</span> []</span>
<span id="cb20-13"><a href="#cb20-13" tabindex="-1"></a></span>
<span id="cb20-14"><a href="#cb20-14" tabindex="-1"></a><span class="co"># True labels for OOD data (since they are not part of the original labels)</span></span>
<span id="cb20-15"><a href="#cb20-15" tabindex="-1"></a>ood_true_labels <span class="op">=</span> np.full(<span class="bu">len</span>(ood_energy_scores), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb20-16"><a href="#cb20-16" tabindex="-1"></a></span>
<span id="cb20-17"><a href="#cb20-17" tabindex="-1"></a><span class="co"># We need the test_labels to be aligned with the ID data</span></span>
<span id="cb20-18"><a href="#cb20-18" tabindex="-1"></a>id_true_labels <span class="op">=</span> test_labels[:<span class="bu">len</span>(id_energy_scores)]</span>
<span id="cb20-19"><a href="#cb20-19" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" tabindex="-1"></a><span class="cf">for</span> threshold <span class="kw">in</span> thresholds:</span>
<span id="cb20-21"><a href="#cb20-21" tabindex="-1"></a>    <span class="co"># Classify OOD examples based on energy scores</span></span>
<span id="cb20-22"><a href="#cb20-22" tabindex="-1"></a>    ood_classifications <span class="op">=</span> np.where(ood_energy_scores <span class="op">&gt;=</span> threshold, <span class="op">-</span><span class="dv">1</span>,  <span class="co"># classified as OOD</span></span>
<span id="cb20-23"><a href="#cb20-23" tabindex="-1"></a>                                   np.where(ood_energy_scores <span class="op">&lt;</span> threshold, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as ID</span></span>
<span id="cb20-24"><a href="#cb20-24" tabindex="-1"></a></span>
<span id="cb20-25"><a href="#cb20-25" tabindex="-1"></a>    <span class="co"># Classify ID examples based on energy scores</span></span>
<span id="cb20-26"><a href="#cb20-26" tabindex="-1"></a>    id_classifications <span class="op">=</span> np.where(id_energy_scores <span class="op">&gt;=</span> threshold, <span class="op">-</span><span class="dv">1</span>,  <span class="co"># classified as OOD</span></span>
<span id="cb20-27"><a href="#cb20-27" tabindex="-1"></a>                                  np.where(id_energy_scores <span class="op">&lt;</span> threshold, id_true_labels, <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as ID</span></span>
<span id="cb20-28"><a href="#cb20-28" tabindex="-1"></a></span>
<span id="cb20-29"><a href="#cb20-29" tabindex="-1"></a>    <span class="co"># Combine OOD and ID classifications and true labels</span></span>
<span id="cb20-30"><a href="#cb20-30" tabindex="-1"></a>    all_predictions <span class="op">=</span> np.concatenate([ood_classifications, id_classifications])</span>
<span id="cb20-31"><a href="#cb20-31" tabindex="-1"></a>    all_true_labels <span class="op">=</span> np.concatenate([ood_true_labels, id_true_labels])</span>
<span id="cb20-32"><a href="#cb20-32" tabindex="-1"></a></span>
<span id="cb20-33"><a href="#cb20-33" tabindex="-1"></a>    <span class="co"># Evaluate metrics</span></span>
<span id="cb20-34"><a href="#cb20-34" tabindex="-1"></a>    precision, recall, f1, _ <span class="op">=</span> precision_recall_fscore_support(all_true_labels, all_predictions, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>], average<span class="op">=</span><span class="st">'macro'</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb20-35"><a href="#cb20-35" tabindex="-1"></a>    accuracy <span class="op">=</span> accuracy_score(all_true_labels, all_predictions)</span>
<span id="cb20-36"><a href="#cb20-36" tabindex="-1"></a></span>
<span id="cb20-37"><a href="#cb20-37" tabindex="-1"></a>    accuracies.append(accuracy)</span>
<span id="cb20-38"><a href="#cb20-38" tabindex="-1"></a>    precisions.append(precision)</span>
<span id="cb20-39"><a href="#cb20-39" tabindex="-1"></a>    recalls.append(recall)</span>
<span id="cb20-40"><a href="#cb20-40" tabindex="-1"></a>    f1_scores.append(f1)</span>
<span id="cb20-41"><a href="#cb20-41" tabindex="-1"></a></span>
<span id="cb20-42"><a href="#cb20-42" tabindex="-1"></a><span class="co"># Find the best thresholds for each metric</span></span>
<span id="cb20-43"><a href="#cb20-43" tabindex="-1"></a>best_f1_index <span class="op">=</span> np.argmax(f1_scores)</span>
<span id="cb20-44"><a href="#cb20-44" tabindex="-1"></a>best_f1_threshold <span class="op">=</span> thresholds[best_f1_index]</span>
<span id="cb20-45"><a href="#cb20-45" tabindex="-1"></a></span>
<span id="cb20-46"><a href="#cb20-46" tabindex="-1"></a>best_precision_index <span class="op">=</span> np.argmax(precisions)</span>
<span id="cb20-47"><a href="#cb20-47" tabindex="-1"></a>best_precision_threshold <span class="op">=</span> thresholds[best_precision_index]</span>
<span id="cb20-48"><a href="#cb20-48" tabindex="-1"></a></span>
<span id="cb20-49"><a href="#cb20-49" tabindex="-1"></a>best_recall_index <span class="op">=</span> np.argmax(recalls)</span>
<span id="cb20-50"><a href="#cb20-50" tabindex="-1"></a>best_recall_threshold <span class="op">=</span> thresholds[best_recall_index]</span>
<span id="cb20-51"><a href="#cb20-51" tabindex="-1"></a></span>
<span id="cb20-52"><a href="#cb20-52" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best F1 threshold: </span><span class="sc">{</span>best_f1_threshold<span class="sc">}</span><span class="ss">, F1 Score: </span><span class="sc">{</span>f1_scores[best_f1_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-53"><a href="#cb20-53" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Precision threshold: </span><span class="sc">{</span>best_precision_threshold<span class="sc">}</span><span class="ss">, Precision: </span><span class="sc">{</span>precisions[best_precision_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-54"><a href="#cb20-54" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Recall threshold: </span><span class="sc">{</span>best_recall_threshold<span class="sc">}</span><span class="ss">, Recall: </span><span class="sc">{</span>recalls[best_recall_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-55"><a href="#cb20-55" tabindex="-1"></a></span>
<span id="cb20-56"><a href="#cb20-56" tabindex="-1"></a><span class="co"># Plot metrics as functions of the threshold</span></span>
<span id="cb20-57"><a href="#cb20-57" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb20-58"><a href="#cb20-58" tabindex="-1"></a>plt.plot(thresholds, precisions, label<span class="op">=</span><span class="st">'Precision'</span>, color<span class="op">=</span><span class="st">'g'</span>)</span>
<span id="cb20-59"><a href="#cb20-59" tabindex="-1"></a>plt.plot(thresholds, recalls, label<span class="op">=</span><span class="st">'Recall'</span>, color<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb20-60"><a href="#cb20-60" tabindex="-1"></a>plt.plot(thresholds, f1_scores, label<span class="op">=</span><span class="st">'F1 Score'</span>, color<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb20-61"><a href="#cb20-61" tabindex="-1"></a></span>
<span id="cb20-62"><a href="#cb20-62" tabindex="-1"></a><span class="co"># Add best threshold indicators</span></span>
<span id="cb20-63"><a href="#cb20-63" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>best_f1_threshold, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best F1 Threshold: </span><span class="sc">{</span>best_f1_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb20-64"><a href="#cb20-64" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>best_precision_threshold, color<span class="op">=</span><span class="st">'g'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best Precision Threshold: </span><span class="sc">{</span>best_precision_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb20-65"><a href="#cb20-65" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>best_recall_threshold, color<span class="op">=</span><span class="st">'b'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best Recall Threshold: </span><span class="sc">{</span>best_recall_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb20-66"><a href="#cb20-66" tabindex="-1"></a></span>
<span id="cb20-67"><a href="#cb20-67" tabindex="-1"></a>plt.xlabel(<span class="st">'Threshold'</span>)</span>
<span id="cb20-68"><a href="#cb20-68" tabindex="-1"></a>plt.ylabel(<span class="st">'Metric Value'</span>)</span>
<span id="cb20-69"><a href="#cb20-69" tabindex="-1"></a>plt.title(<span class="st">'Evaluation Metrics as Functions of Threshold (Energy-Based OOD Detection)'</span>)</span>
<span id="cb20-70"><a href="#cb20-70" tabindex="-1"></a>plt.legend()</span>
<span id="cb20-71"><a href="#cb20-71" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a><span class="co"># Threshold value for the energy score</span></span>
<span id="cb21-6"><a href="#cb21-6" tabindex="-1"></a>upper_threshold <span class="op">=</span> best_f1_threshold  <span class="co"># Using the best F1 threshold from the previous calculation</span></span>
<span id="cb21-7"><a href="#cb21-7" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" tabindex="-1"></a><span class="co"># Classifying OOD examples based on energy scores</span></span>
<span id="cb21-9"><a href="#cb21-9" tabindex="-1"></a>ood_classifications <span class="op">=</span> np.where(ood_energy_scores <span class="op">&gt;=</span> upper_threshold, <span class="op">-</span><span class="dv">1</span>,  <span class="co"># classified as OOD</span></span>
<span id="cb21-10"><a href="#cb21-10" tabindex="-1"></a>                               np.where(ood_energy_scores <span class="op">&lt;</span> upper_threshold, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as ID</span></span>
<span id="cb21-11"><a href="#cb21-11" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" tabindex="-1"></a><span class="co"># Classifying ID examples based on energy scores</span></span>
<span id="cb21-13"><a href="#cb21-13" tabindex="-1"></a>id_classifications <span class="op">=</span> np.where(id_energy_scores <span class="op">&gt;=</span> upper_threshold, <span class="op">-</span><span class="dv">1</span>,  <span class="co"># classified as OOD</span></span>
<span id="cb21-14"><a href="#cb21-14" tabindex="-1"></a>                              np.where(id_energy_scores <span class="op">&lt;</span> upper_threshold, id_true_labels, <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as ID</span></span>
<span id="cb21-15"><a href="#cb21-15" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" tabindex="-1"></a><span class="co"># Combine OOD and ID classifications and true labels</span></span>
<span id="cb21-17"><a href="#cb21-17" tabindex="-1"></a>all_predictions <span class="op">=</span> np.concatenate([ood_classifications, id_classifications])</span>
<span id="cb21-18"><a href="#cb21-18" tabindex="-1"></a>all_true_labels <span class="op">=</span> np.concatenate([ood_true_labels, id_true_labels])</span>
<span id="cb21-19"><a href="#cb21-19" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb21-21"><a href="#cb21-21" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(all_true_labels, all_predictions, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb21-22"><a href="#cb21-22" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" tabindex="-1"></a><span class="co"># Plotting the confusion matrix</span></span>
<span id="cb21-24"><a href="#cb21-24" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>[<span class="st">"Shirt"</span>, <span class="st">"Pants"</span>, <span class="st">"OOD"</span>])</span>
<span id="cb21-25"><a href="#cb21-25" tabindex="-1"></a>disp.plot(cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb21-26"><a href="#cb21-26" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix for OOD and ID Classification (Energy-Based)'</span>)</span>
<span id="cb21-27"><a href="#cb21-27" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
</div>
</div>
</div>
<div class="section level1">
<h1 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a></h1>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"></code></pre>
</div>
<div class="section level2">
<h2 id="references-and-supplemental-resources">References and supplemental resources<a class="anchor" aria-label="anchor" href="#references-and-supplemental-resources"></a></h2>
<ul><li><a href="https://www.youtube.com/watch?v=hgLC9_9ZCJI" class="external-link uri">https://www.youtube.com/watch?v=hgLC9_9ZCJI</a></li>
<li>Generalized Out-of-Distribution Detection: A Survey: <a href="https://arxiv.org/abs/2110.11334" class="external-link uri">https://arxiv.org/abs/2110.11334</a> # Glossary</li>
<li>ID/OOD: In-distribution, out-of-distribution. Generally, the OOD
instances can be defined as instances (x, y) sampled from an underlying
distribution other than the training distribution P(Xtrain, Ytrain),
where Xtrain and Ytrain are the training corpus and training label set,
respectively.</li>
<li>OOD instances with semantic shift: OOD instances with semantic shift
refer to instances that do not belong to y_train. More specifically,
instances with semantic shift may come from unknown categories or
irrelevant tasks.</li>
<li>OOD instances with covariate shift: OOD instances with non-semantic
shift refer to the instances that belong to y_train but are sampled from
a distribution other than x_train, e.g., a different
domain/corpus/location.</li>
<li>Closed-world assumption: an assumption that the training and test
data are sampled from the same distribution. However, training data can
rarely capture the entire distribution. In real-world scenarios,
out-of-distribution (OOD) instances, which come from categories that are
not known to the model, can often be present in inference phases.</li>
<li>Inference-time OOD: After training, use some kind of scoring
function to determine if test inputs are OOD or not.</li>
<li>Output-based OOD: Output-based OOD detection methods leverage the
model’s output distribution to identify OOD instances. These methods
typically involve analyzing the softmax scores, confidence scores, or
other output statistics to detect anomalies.</li>
</ul><!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 --></div>
</div>



      </div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="6-confidence-intervals.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="7b-OOD-detection-distance-based.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="6-confidence-intervals.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Estimating model
        </a>
        <a class="chapter-link float-end" href="7b-OOD-detection-distance-based.html" rel="next">
          Next: OOD Detection:...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries-incubator/fair-explainable-ml/edit/main/episodes/7a-OOD-detection-output-based.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries-incubator/fair-explainable-ml/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries-incubator/fair-explainable-ml/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries-incubator/fair-explainable-ml/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:apmeyer4@wisc.edu">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.5" class="external-link">sandpaper (0.16.5)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.6" class="external-link">pegboard (0.7.6)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.3" class="external-link">varnish (1.0.3)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://carpentries-incubator.github.io/fair-explainable-ml/7a-OOD-detection-output-based.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "fairness, explainability, fair machine learning, interpretable machine learning, xai, lesson, The Carpentries",
  "name": "OOD Detection: Overview, Output-Based Methods",
  "creativeWorkStatus": "active",
  "url": "https://carpentries-incubator.github.io/fair-explainable-ml/7a-OOD-detection-output-based.html",
  "identifier": "https://carpentries-incubator.github.io/fair-explainable-ml/7a-OOD-detection-output-based.html",
  "dateCreated": "2023-12-05",
  "dateModified": "2024-07-31",
  "datePublished": "2024-07-31"
}

  </script><script>
		feather.replace();
	</script></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

