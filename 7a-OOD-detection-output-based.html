<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Trustworthy AI: Explainability, Bias, Fairness, and Safety: OOD detection: overview, output-based methods</title><meta name="viewport" content="width=device-width, initial-scale=1"><script src="assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="assets/styles.css"><script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="favicons/incubator/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="favicons/incubator/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="favicons/incubator/favicon-16x16.png"><link rel="manifest" href="favicons/incubator/site.webmanifest"><link rel="mask-icon" href="favicons/incubator/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="black"></head><body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Carpentries Incubator" src="assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text"><li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul></li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/7a-OOD-detection-output-based.html';">Instructor View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Trustworthy AI: Explainability, Bias, Fairness, and Safety
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Trustworthy AI: Explainability, Bias, Fairness, and Safety
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Trustworthy AI: Explainability, Bias, Fairness, and Safety
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 100%" class="percentage">
    100%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 100%" aria-valuenow="100" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text"><li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul></li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/7a-OOD-detection-output-based.html">Instructor View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->

            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="0-introduction.html">1. Overview</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="1-preparing-to-train.html">2. Preparing to train a model</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="2-model-eval-and-fairness.html">3. Model evaluation and fairness</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="3-model-fairness-deep-dive.html">4. Model fairness: hands-on</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="4-explainability-vs-interpretability.html">5. Interpretablility versus explainability</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="5a-explainable-AI-method-overview.html">6. Explainability methods overview</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="5b-deep-dive-into-methods.html">7. Explainability methods: deep dive</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="5c-probes.html">8. Explainability methods: linear probe</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="5d-gradcam.html">9. Explainability methods: GradCAM</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush11">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading11">
        <a href="6-confidence-intervals.html">10. Estimating model uncertainty: overview</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        11. OOD detection: overview, output-based methods
        </span>
      
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush13">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading13">
        <a href="7b-OOD-detection-distance-based.html">12. OOD detection: distance-based and contrastive learning</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush14">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading14">
        <a href="7c-OOD-detection-algo-design.html">13. OOD detection: training-time regularization</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush15">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading15">
        <a href="8-releasing-a-model.html">14. Documenting and releasing a model</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources"><a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">

            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="6-confidence-intervals.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="7b-OOD-detection-distance-based.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="6-confidence-intervals.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Estimating model
        </a>
        <a class="chapter-link float-end" href="7b-OOD-detection-distance-based.html" rel="next">
          Next: OOD detection:...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>OOD detection: overview, output-based methods</h1>
        <p>Last updated on 2024-11-15 |

        <a href="https://github.com/carpentries-incubator/fair-explainable-ml/edit/main/episodes/7a-OOD-detection-output-based.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>



        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>What are out-of-distribution (OOD) data and why is detecting them
important in machine learning models?</li>
<li>How do output-based methods like softmax and energy-based methods
work for OOD detection?</li>
<li>What are the limitations of output-based OOD detection methods?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Understand the concept of out-of-distribution data and its
significance in building trustworthy machine learning models.</li>
<li>Learn about different output-based methods for OOD detection,
including softmax and energy-based methods</li>
<li>Identify the strengths and limitations of output-based OOD detection
techniques.</li>
</ul></div>
</div>
</div>
</div>
</div>
<div class="section level1">
<h1 id="introduction-to-out-of-distribution-ood-data">Introduction to Out-of-Distribution (OOD) Data<a class="anchor" aria-label="anchor" href="#introduction-to-out-of-distribution-ood-data"></a></h1>
<div class="section level2">
<h2 id="what-is-ood-data">What is OOD data?<a class="anchor" aria-label="anchor" href="#what-is-ood-data"></a></h2>
<p>Out-of-distribution (OOD) data refers to data that significantly
differs from the training data on which a machine learning model was
built. For example, the image below compares the training data
distribution of CIFAR-10, a popular dataset used for image
classification, with the vastly broader and more diverse distribution of
images found on the internet:</p>
<figure><img src="https://raw.githubusercontent.com/carpentries-incubator/fair-explainable-ml/main/images/OOD-internet-vs-CIFAR10.jpg" alt="OpenAI: CIFAR-10 training distribution vs. internet" class="figure mx-auto d-block"><div class="figcaption">OpenAI: CIFAR-10 training distribution
vs. internet</div>
</figure><p>CIFAR-10 contains 60,000 images across 10 distinct classes (e.g.,
airplanes, dogs, trucks), with carefully curated examples for each
class. However, the internet features an essentially infinite variety of
images, many of which fall outside these predefined classes or include
unseen variations (e.g., new breeds of dogs or novel vehicle designs).
This contrast highlights the challenges models face when they encounter
data that significantly differs from their training distribution.</p>
</div>
<div class="section level2">
<h2 id="when-does-ood-arise">When does OOD arise?<a class="anchor" aria-label="anchor" href="#when-does-ood-arise"></a></h2>
<p>The difference between in-distribution (ID) and OOD data can arise
from: - <strong>Semantic shift</strong>: The OOD sample belongs to a
class that was not present during training. - <strong>Covariate
shift</strong>: The OOD sample comes from a domain where the input
feature distribution is drastically different from the training
data.</p>
</div>
<div class="section level2">
<h2 id="why-does-ood-data-matter">Why does OOD data matter?<a class="anchor" aria-label="anchor" href="#why-does-ood-data-matter"></a></h2>
<p>Models trained on a specific distribution might make incorrect
predictions on OOD data, leading to unreliable outputs. In critical
applications (e.g., healthcare, autonomous driving), encountering OOD
data without proper handling can have severe consequences.</p>
<div class="section level3">
<h3 id="ex1-tesla-crashes-into-jet">Ex1: Tesla crashes into jet<a class="anchor" aria-label="anchor" href="#ex1-tesla-crashes-into-jet"></a></h3>
<p>In April 2022, a <a href="https://www.newsweek.com/video-tesla-smart-summon-mode-ramming-3m-jet-viewed-34m-times-1700310" class="external-link">Tesla
Model Y crashed into a $3.5 million private jet</a> at an aviation trade
show in Spokane, Washington, while operating on the “Smart Summon”
feature. The feature allows Tesla vehicles to autonomously navigate
parking lots to their owners, but in this case, it resulted in a
significant mishap. - The Tesla was summoned by its owner using the
Tesla app, which requires holding down a button to keep the car moving.
The car continued to move forward even after making contact with the
jet, pushing the expensive aircraft and causing notable damage. - The
crash highlighted several issues with Tesla’s Smart Summon feature,
particularly its object detection capabilities. The system failed to
recognize and appropriately react to the presence of the jet, a problem
that has been observed in other scenarios where the car’s sensors
struggle with objects that are lifted off the ground or have unusual
shapes.</p>
</div>
<div class="section level3">
<h3 id="ex2-ibm-watson-for-oncology">Ex2: IBM Watson for Oncology<a class="anchor" aria-label="anchor" href="#ex2-ibm-watson-for-oncology"></a></h3>
<p>IBM Watson for Oncology faced several issues due to OOD data. The
system was primarily trained on data from Memorial Sloan Kettering
Cancer Center (MSK), which did not generalize well to other healthcare
settings. This led to the following problems: 1. Unsafe Recommendations:
Watson for Oncology provided treatment recommendations that were not
safe or aligned with standard care guidelines in many cases outside of
MSK. This happened because the training data was not representative of
the diverse medical practices and patient populations in different
regions 2. Bias in Training Data: The system’s recommendations were
biased towards the practices at MSK, failing to account for different
treatment protocols and patient needs elsewhere. This bias is a classic
example of an OOD issue, where the model encounters data (patients and
treatments) during deployment that significantly differ from its
training data</p>
</div>
<div class="section level3">
<h3 id="ex3-doctors-using-gpt3">Ex3: Doctors using GPT3<a class="anchor" aria-label="anchor" href="#ex3-doctors-using-gpt3"></a></h3>
<div class="section level4">
<h4 id="misdiagnosis-and-inaccurate-medical-advice">Misdiagnosis and Inaccurate Medical Advice<a class="anchor" aria-label="anchor" href="#misdiagnosis-and-inaccurate-medical-advice"></a></h4>
<p>In various studies and real-world applications, GPT-3 has been shown
to generate inaccurate medical advice when faced with OOD data. This can
be attributed to the fact that the training data, while extensive, does
not cover all possible medical scenarios and nuances, leading to
hallucinations or incorrect responses when encountering unfamiliar
input.</p>
<p>A <a href="https://hai.stanford.edu/news/generating-medical-errors-genai-and-erroneous-medical-references" class="external-link">study
published by researchers at Stanford</a> found that GPT-3, even when
using retrieval-augmented generation, provided unsupported medical
advice in about 30% of its statements. For example, it suggested the use
of a specific dosage for a defibrillator based on monophasic technology,
while the cited source only discussed biphasic technology, which
operates differently.</p>
</div>
<div class="section level4">
<h4 id="fake-medical-literature-references">Fake Medical Literature References<a class="anchor" aria-label="anchor" href="#fake-medical-literature-references"></a></h4>
<p>Another critical OOD issue is the generation of fake or non-existent
medical references by LLMs. When LLMs are prompted to provide citations
for their responses, they sometimes generate references that sound
plausible but do not actually exist. This can be particularly
problematic in academic and medical contexts where accurate sourcing is
crucial.</p>
<p>In <a href="https://hai.stanford.edu/news/generating-medical-errors-genai-and-erroneous-medical-references" class="external-link">evaluations
of GPT-3’s ability to generate medical literature references</a> , it
was found that a significant portion of the references were either
entirely fabricated or did not support the claims being made. This was
especially true for complex medical inquiries that the model had not
seen in its training data.</p>
</div>
</div>
</div>
</div>
<div class="section level1">
<h1 id="detecting-and-handling-ood-data">Detecting and Handling OOD Data<a class="anchor" aria-label="anchor" href="#detecting-and-handling-ood-data"></a></h1>
<p>Given the problems posed by OOD data, a reliable model should
identify such instances, and then:</p>
<ol style="list-style-type: decimal"><li>Reject them during inference</li>
<li>Ideally, hand these OOD instances to a model trained on a more
similar distribution (an in-distribution).</li>
</ol><p>The second step is much more complicated/involved since it requires
matching OOD data to essentially an infinite number of possible classes.
For the current scope of this workshop, we will focus on just the first
step.</p>
<p>How can we determine whether a given instance is OOD or ID? Over the
past several years, there have been a wide assortment of new methods
developed to tackle this task. In this episode, we will cover a few of
the most common approaches and discuss advantages/disadvantages of
each.</p>
<div class="section level2">
<h2 id="threshold-based-methods">Threshold-based methods<a class="anchor" aria-label="anchor" href="#threshold-based-methods"></a></h2>
<p>Threshold-based methods are one of the simplest and most intuitive
approaches for detecting out-of-distribution (OOD) data. The central
idea is to define a threshold on a certain score or confidence measure,
beyond which the data point is considered out-of-distribution.
Typically, these scores are derived from the model’s output
probabilities or other statistical measures of uncertainty. There are
two general classes of threshold-based methods: output-based and
distance-based.</p>
<div class="section level3">
<h3 id="output-based-thresholds">Output-based thresholds<a class="anchor" aria-label="anchor" href="#output-based-thresholds"></a></h3>
<p>Output-based Out-of-Distribution (OOD) detection refers to methods
that determine whether a given input is out-of-distribution based on the
output of a trained model. These methods typically analyze the model’s
confidence scores, energy scores, or other output metrics to identify
data points that are unlikely to belong to the distribution the model
was trained on. The main approaches within output-based OOD detection
include:</p>
<ul><li>
<strong>Softmax scores</strong>: The softmax output of a neural
network represents the predicted probabilities for each class. A common
threshold-based method involves setting a confidence threshold, and if
the maximum softmax score of an instance falls below this threshold, it
is flagged as OOD.</li>
<li>
<strong>Energy</strong>: The energy-based method also uses the
network’s output but measures the uncertainty in a more nuanced way by
calculating an energy score. The energy score typically captures the
confidence more robustly, especially in high-dimensional spaces, and can
be considered a more general and reliable approach than just using
softmax probabilities.</li>
</ul></div>
<div class="section level3">
<h3 id="distance-based-thresholds">Distance-based thresholds<a class="anchor" aria-label="anchor" href="#distance-based-thresholds"></a></h3>
<p>Distance-based methods calculate the distance of an instance from the
distribution of training data features learned by the model. If the
distance is beyond a certain threshold, the instance is considered OOD.
Common distance-based approaches include:</p>
<ul><li>
<strong>Mahalanobis distance:</strong> This method calculates the
Mahalanobis distance of a data point from the mean of the training data
distribution. A high Mahalanobis distance indicates that the instance is
likely OOD.</li>
<li>
<strong>K-nearest neighbors (KNN):</strong> This method involves
computing the distance to the k-nearest neighbors in the training data.
If the average distance to these neighbors is high, the instance is
considered OOD.</li>
</ul><p>We will focus on output-based methods (softmax and energy) in this
episode and then do a deep dive into distance-based methods in the next
episode.</p>
</div>
</div>
</div>
<div class="section level1">
<h1 id="example-1-softmax-scores">Example 1: Softmax scores<a class="anchor" aria-label="anchor" href="#example-1-softmax-scores"></a></h1>
<p>Softmax-based out-of-distribution (OOD) detection methods are a
fundamental aspect of understanding how models differentiate between
in-distribution and OOD data. Even though energy-based methods are
becoming more popular, grasping softmax OOD detection methods provides
essential scaffolding for learning more advanced techniques.
Furthermore, softmax thresholding is still in use throughout ML
literature, and learning more about this method will help you better
assess results from others.</p>
<p>In this first example, we will train a simple logistic regression
model to classify images as T-shirts or pants. We will then evaluate how
our model reacts to data outside of these two classes (“semantic
shift”).</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># some settings I'm playing around with when designing this lesson</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>verbose <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>alpha<span class="op">=</span><span class="fl">0.2</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>max_iter <span class="op">=</span> <span class="dv">10</span> <span class="co"># increase after testing phase</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>n_epochs <span class="op">=</span> <span class="dv">10</span> <span class="co"># increase after testing phase</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="prepare-the-id-train-and-test-and-ood-data">Prepare the ID (train and test) and OOD data<a class="anchor" aria-label="anchor" href="#prepare-the-id-train-and-test-and-ood-data"></a></h3>
<ul><li>ID = T-shirts/Blouses, Pants</li>
<li>OOD = any other class. For Illustrative purposes, we’ll focus on
images of sandals as the OOD class.</li>
</ul><div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="im">from</span> keras.datasets <span class="im">import</span> fashion_mnist</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="kw">def</span> prep_ID_OOD_datasests(ID_class_labels, OOD_class_labels):</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>    <span class="co"># Load Fashion MNIST dataset</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>    (train_images, train_labels), (test_images, test_labels) <span class="op">=</span> fashion_mnist.load_data()</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>    </span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>    <span class="co"># Prepare OOD data: Sandals = 5</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>    ood_filter <span class="op">=</span> np.isin(test_labels, OOD_class_labels)</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>    ood_data <span class="op">=</span> test_images[ood_filter]</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>    ood_labels <span class="op">=</span> test_labels[ood_filter]</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'ood_data.shape=</span><span class="sc">{</span>ood_data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>    </span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>    <span class="co"># Filter data for T-shirts (0) and Trousers (1) as in-distribution</span></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>    train_filter <span class="op">=</span> np.isin(train_labels, ID_class_labels)</span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>    test_filter <span class="op">=</span> np.isin(test_labels, ID_class_labels)</span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>    </span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a>    train_data <span class="op">=</span> train_images[train_filter]</span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a>    train_labels <span class="op">=</span> train_labels[train_filter]</span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'train_data.shape=</span><span class="sc">{</span>train_data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>    </span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a>    test_data <span class="op">=</span> test_images[test_filter]</span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a>    test_labels <span class="op">=</span> test_labels[test_filter]</span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'test_data.shape=</span><span class="sc">{</span>test_data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a>    <span class="cf">return</span> train_data, test_data, ood_data, train_labels, test_labels, ood_labels</span>
<span id="cb2-30"><a href="#cb2-30" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" tabindex="-1"></a><span class="kw">def</span> plot_data_sample(train_data, ood_data):</span>
<span id="cb2-33"><a href="#cb2-33" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-34"><a href="#cb2-34" tabindex="-1"></a><span class="co">    Plots a sample of in-distribution and OOD data.</span></span>
<span id="cb2-35"><a href="#cb2-35" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb2-37"><a href="#cb2-37" tabindex="-1"></a><span class="co">    - train_data: np.array, array of in-distribution data images</span></span>
<span id="cb2-38"><a href="#cb2-38" tabindex="-1"></a><span class="co">    - ood_data: np.array, array of out-of-distribution data images</span></span>
<span id="cb2-39"><a href="#cb2-39" tabindex="-1"></a></span>
<span id="cb2-40"><a href="#cb2-40" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb2-41"><a href="#cb2-41" tabindex="-1"></a><span class="co">    - fig: matplotlib.figure.Figure, the figure object containing the plots</span></span>
<span id="cb2-42"><a href="#cb2-42" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-43"><a href="#cb2-43" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>))</span>
<span id="cb2-44"><a href="#cb2-44" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb2-45"><a href="#cb2-45" tabindex="-1"></a>        plt.subplot(<span class="dv">2</span>, <span class="dv">5</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb2-46"><a href="#cb2-46" tabindex="-1"></a>        plt.imshow(train_data[i], cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb2-47"><a href="#cb2-47" tabindex="-1"></a>        plt.title(<span class="st">"In-Dist"</span>)</span>
<span id="cb2-48"><a href="#cb2-48" tabindex="-1"></a>        plt.axis(<span class="st">'off'</span>)</span>
<span id="cb2-49"><a href="#cb2-49" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb2-50"><a href="#cb2-50" tabindex="-1"></a>        plt.subplot(<span class="dv">2</span>, <span class="dv">5</span>, i <span class="op">+</span> <span class="dv">6</span>)</span>
<span id="cb2-51"><a href="#cb2-51" tabindex="-1"></a>        plt.imshow(ood_data[i], cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb2-52"><a href="#cb2-52" tabindex="-1"></a>        plt.title(<span class="st">"OOD"</span>)</span>
<span id="cb2-53"><a href="#cb2-53" tabindex="-1"></a>        plt.axis(<span class="st">'off'</span>)</span>
<span id="cb2-54"><a href="#cb2-54" tabindex="-1"></a>    </span>
<span id="cb2-55"><a href="#cb2-55" tabindex="-1"></a>    <span class="cf">return</span> fig</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>train_data, test_data, ood_data, train_labels, test_labels, ood_labels <span class="op">=</span> prep_ID_OOD_datasests([<span class="dv">0</span>,<span class="dv">1</span>], [<span class="dv">5</span>])</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>fig <span class="op">=</span> plot_data_sample(train_data, ood_data)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>fig.savefig(<span class="st">'../images/OOD-detection_image-data-preview.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>plt.show()</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span></code></pre>
</div>
<figure><img src="https://raw.githubusercontent.com/carpentries-incubator/fair-explainable-ml/main/images/OOD-detection_image-data-preview.png" alt="Preview of image dataset" class="figure mx-auto d-block"><div class="figcaption">Preview of image dataset</div>
</figure></div>
<div class="section level2">
<h2 id="visualizing-ood-and-id-data">Visualizing OOD and ID data<a class="anchor" aria-label="anchor" href="#visualizing-ood-and-id-data"></a></h2>
<div class="section level3">
<h3 id="pca">PCA<a class="anchor" aria-label="anchor" href="#pca"></a></h3>
<p>PCA visualization can provide insights into how well a model is
separating ID and OOD data. If the OOD data overlaps significantly with
ID data in the PCA space, it might indicate that the model could
struggle to correctly identify OOD samples.</p>
<p><strong>Focus on Linear Relationships</strong>: PCA is a linear
dimensionality reduction technique. It assumes that the directions of
maximum variance in the data can be captured by linear combinations of
the original features. This can be a limitation when the data has
complex, non-linear relationships, as PCA may not capture the true
structure of the data. However, if you’re using a linear model (as we
are here), PCA can be more appropriate for visualizing in-distribution
(ID) and out-of-distribution (OOD) data because both PCA and linear
models operate under linear assumptions. PCA will effectively capture
the main variance in the data as seen by the linear model, making it
easier to understand the decision boundaries and how OOD data deviates
from the ID data within those boundaries.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Flatten images for PCA and logistic regression</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>train_data_flat <span class="op">=</span> train_data.reshape((train_data.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>test_data_flat <span class="op">=</span> test_data.reshape((test_data.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>ood_data_flat <span class="op">=</span> ood_data.reshape((ood_data.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'train_data_flat.shape=</span><span class="sc">{</span>train_data_flat<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'test_data_flat.shape=</span><span class="sc">{</span>test_data_flat<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'ood_data_flat.shape=</span><span class="sc">{</span>ood_data_flat<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Perform PCA to visualize the first two principal components</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>train_data_pca <span class="op">=</span> pca.fit_transform(train_data_flat)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>test_data_pca <span class="op">=</span> pca.transform(test_data_flat)</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>ood_data_pca <span class="op">=</span> pca.transform(ood_data_flat)</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co"># Plotting PCA components</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>scatter1 <span class="op">=</span> plt.scatter(train_data_pca[train_labels <span class="op">==</span> <span class="dv">0</span>, <span class="dv">0</span>], train_data_pca[train_labels <span class="op">==</span> <span class="dv">0</span>, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'T-shirt/top (ID)'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>scatter2 <span class="op">=</span> plt.scatter(train_data_pca[train_labels <span class="op">==</span> <span class="dv">1</span>, <span class="dv">0</span>], train_data_pca[train_labels <span class="op">==</span> <span class="dv">1</span>, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Pants (ID)'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>scatter3 <span class="op">=</span> plt.scatter(ood_data_pca[:, <span class="dv">0</span>], ood_data_pca[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Sandals (OOD)'</span>, edgecolor<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="co"># Create a single legend for all classes</span></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>plt.legend(handles<span class="op">=</span>[scatter1, scatter2, scatter3], loc<span class="op">=</span><span class="st">"upper right"</span>)</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>plt.xlabel(<span class="st">'First Principal Component'</span>)</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>plt.ylabel(<span class="st">'Second Principal Component'</span>)</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>plt.title(<span class="st">'PCA of In-Distribution and OOD Data'</span>)</span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>plt.savefig(<span class="st">'../images/OOD-detection_PCA-image-dataset.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p><img src="https://raw.githubusercontent.com/carpentries-incubator/fair-explainable-ml/main/images/OOD-detection_PCA-image-dataset.png" alt="PCA visualization" class="figure"> From this plot, we see that sandals are more
likely to be confused as T-shirts than pants. It also may be surprising
to see that these data clouds overlap so much given their semantic
differences. Why might this be?</p>
<ul><li>
<strong>Over-reliance on linear relationships</strong>: Part of this
has to do with the fact that we’re only looking at linear relationships
and treating each pixel as its own input feature, which is usually never
a great idea when working with image data. In our next example, we’ll
switch to the more modern approach of CNNs.</li>
<li>
<strong>Semantic gap != feature gap</strong>: Another factor of note
is that images that have a wide semantic gap may not necessarily
translate to a wide gap in terms of the data’s visual features (e.g.,
ankle boots and bags might both be small, have leather, and have
zippers). Part of an effective OOD detection scheme involves thinking
carefully about what sorts of data contanimations may be observed by the
model, and assessing how similar these contaminations may be to your
desired class labels. ## Train and evaluate model on ID data</li>
</ul><div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Train a logistic regression classifier</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span>max_iter, solver<span class="op">=</span><span class="st">'lbfgs'</span>, multi_class<span class="op">=</span><span class="st">'multinomial'</span>).fit(train_data_flat, train_labels)</span></code></pre>
</div>
<p>Before we worry about the impact of OOD data, let’s first verify that
we have a reasonably accurate model for the ID data.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Evaluate the model on in-distribution data</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>in_dist_preds <span class="op">=</span> model.predict(test_data_flat)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>in_dist_accuracy <span class="op">=</span> accuracy_score(test_labels, in_dist_preds)</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'In-Distribution Accuracy: </span><span class="sc">{</span>in_dist_accuracy<span class="sc">:.2f}</span><span class="ss">'</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co"># Generate and display confusion matrix</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(test_labels, in_dist_preds, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>[<span class="st">'T-shirt/top'</span>, <span class="st">'Pants'</span>])</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>disp.plot(cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>plt.savefig(<span class="st">'../images/OOD-detection_ID-confusion-matrix.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="https://raw.githubusercontent.com/carpentries-incubator/fair-explainable-ml/main/images/OOD-detection_ID-confusion-matrix.png" alt="ID confusion matrix" class="figure mx-auto d-block"><div class="figcaption">ID confusion matrix</div>
</figure></div>
</div>
<div class="section level2">
<h2 id="how-does-our-model-view-ood-data">How does our model view OOD data?<a class="anchor" aria-label="anchor" href="#how-does-our-model-view-ood-data"></a></h2>
<p>A basic question we can start with is to ask, on average, how are OOD
samples classified? Are they more likely to be Tshirts or pants? For
this kind of question, we can calculate the probability scores for the
OOD data, and compare this to the ID data.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Predict probabilities using the model on OOD data (Sandals)</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>ood_probs <span class="op">=</span> model.predict_proba(ood_data_flat)</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>avg_ood_prob <span class="op">=</span> np.mean(ood_probs, <span class="dv">0</span>)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Avg. probability of sandal being T-shirt: </span><span class="sc">{</span>avg_ood_prob[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Avg. probability of sandal being pants: </span><span class="sc">{</span>avg_ood_prob[<span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>id_probs <span class="op">=</span> model.predict_proba(train_data_flat)</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>id_probs_shirts <span class="op">=</span> id_probs[train_labels<span class="op">==</span><span class="dv">0</span>,:]</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>id_probs_pants <span class="op">=</span> id_probs[train_labels<span class="op">==</span><span class="dv">1</span>,:]</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>avg_tshirt_prob <span class="op">=</span> np.mean(id_probs_shirts, <span class="dv">0</span>)</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>avg_pants_prob <span class="op">=</span> np.mean(id_probs_pants, <span class="dv">0</span>)</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Avg. probability of T-shirt being T-shirt: </span><span class="sc">{</span>avg_tshirt_prob[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Avg. probability of pants being pants: </span><span class="sc">{</span>avg_pants_prob[<span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre>
</div>
<p>Based on the difference in averages here, it looks like softmax may
provide at least a somewhat useful signal in separating ID and OOD data.
Let’s take a closer look by plotting histograms of all probability
scores across our classes of interest (ID-Tshirt, ID-Pants, and
OOD).</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># Creating the figure and subplots</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">4</span>), sharey<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>bins<span class="op">=</span><span class="dv">60</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="co"># Plotting the histogram of probabilities for OOD data (Sandals)</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>axes[<span class="dv">0</span>].hist(ood_probs[:, <span class="dv">0</span>], bins<span class="op">=</span>bins, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'T-shirt probability'</span>)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Probability'</span>)</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'OOD Data (Sandals)'</span>)</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="co"># Plotting the histogram of probabilities for ID data (T-shirt)</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>axes[<span class="dv">1</span>].hist(id_probs_shirts[:, <span class="dv">0</span>], bins<span class="op">=</span>bins, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'T-shirt probability'</span>, color<span class="op">=</span><span class="st">'orange'</span>)</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Probability'</span>)</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'ID Data (T-shirt/top)'</span>)</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>axes[<span class="dv">1</span>].legend()</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a><span class="co"># Plotting the histogram of probabilities for ID data (Pants)</span></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>axes[<span class="dv">2</span>].hist(id_probs_pants[:, <span class="dv">1</span>], bins<span class="op">=</span>bins, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Pants probability'</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'Probability'</span>)</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'ID Data (Pants)'</span>)</span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>axes[<span class="dv">2</span>].legend()</span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a><span class="co"># Adjusting layout</span></span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>plt.savefig(<span class="st">'../images/OOD-detection_histograms.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a><span class="co"># Displaying the plot</span></span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p><img src="https://raw.githubusercontent.com/carpentries-incubator/fair-explainable-ml/main/images/OOD-detection_histograms.png" alt="Histograms of ID oand OOD data" class="figure"> Alternatively, for a better
comparison across all three classes, we can use a probability density
plot. This will allow for an easier comparison when the counts across
classes lie on vastly different sclaes (i.e., max of 35 vs max of
5000).</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> gaussian_kde</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="co"># Create figure</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="co"># Define bins</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.4</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a><span class="co"># Plot PDF for ID T-shirt (T-shirt probability)</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>density_id_shirts <span class="op">=</span> gaussian_kde(id_probs_shirts[:, <span class="dv">0</span>])</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>x_id_shirts <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>plt.plot(x_id_shirts, density_id_shirts(x_id_shirts), label<span class="op">=</span><span class="st">'ID T-shirt (T-shirt probability)'</span>, color<span class="op">=</span><span class="st">'orange'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a><span class="co"># Plot PDF for ID Pants (Pants probability)</span></span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>density_id_pants <span class="op">=</span> gaussian_kde(id_probs_pants[:, <span class="dv">0</span>])</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a>x_id_pants <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>plt.plot(x_id_pants, density_id_pants(x_id_pants), label<span class="op">=</span><span class="st">'ID Pants (T-shirt probability)'</span>, color<span class="op">=</span><span class="st">'green'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a><span class="co"># Plot PDF for OOD (T-shirt probability)</span></span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a>density_ood <span class="op">=</span> gaussian_kde(ood_probs[:, <span class="dv">0</span>])</span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a>x_ood <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a>plt.plot(x_ood, density_ood(x_ood), label<span class="op">=</span><span class="st">'OOD (T-shirt probability)'</span>, color<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" tabindex="-1"></a><span class="co"># Adding labels and title</span></span>
<span id="cb11-25"><a href="#cb11-25" tabindex="-1"></a>plt.xlabel(<span class="st">'Probability'</span>)</span>
<span id="cb11-26"><a href="#cb11-26" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb11-27"><a href="#cb11-27" tabindex="-1"></a>plt.title(<span class="st">'Probability Density Distributions for OOD and ID Data'</span>)</span>
<span id="cb11-28"><a href="#cb11-28" tabindex="-1"></a>plt.legend()</span>
<span id="cb11-29"><a href="#cb11-29" tabindex="-1"></a></span>
<span id="cb11-30"><a href="#cb11-30" tabindex="-1"></a>plt.savefig(<span class="st">'../images/OOD-detection_PSDs.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb11-31"><a href="#cb11-31" tabindex="-1"></a></span>
<span id="cb11-32"><a href="#cb11-32" tabindex="-1"></a><span class="co"># Displaying the plot</span></span>
<span id="cb11-33"><a href="#cb11-33" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p><img src="https://raw.githubusercontent.com/carpentries-incubator/fair-explainable-ml/main/images/OOD-detection_PSDs.png" alt="Probability densities" class="figure"> Unfortunately, we observe a significant
amount of overlap between OOD data and high T-shirt probability.
Furthermore, the blue line doesn’t seem to decrease much as you move
from 0.9 to 1, suggesting that even a very high threshold is likely to
lead to OOD contamination (while also tossing out a significant portion
of ID data).</p>
<p>For pants, the problem is much less severe. It looks like a low
threshold (on this T-shirt probability scale) can separate nearly all
OOD samples from being pants.</p>
<div class="section level3">
<h3 id="setting-a-threshold">Setting a threshold<a class="anchor" aria-label="anchor" href="#setting-a-threshold"></a></h3>
<p>Let’s put our observations to the test and produce a confusion matrix
that includes ID-pants, ID-Tshirts, and OOD class labels. We’ll start
with a high threshold of 0.9 to see how that performs.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="kw">def</span> softmax_thresh_classifications(probs, threshold):</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>    classifications <span class="op">=</span> np.where(probs[:, <span class="dv">1</span>] <span class="op">&gt;=</span> threshold, <span class="dv">1</span>,  <span class="co"># classified as pants</span></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>                               np.where(probs[:, <span class="dv">0</span>] <span class="op">&gt;=</span> threshold, <span class="dv">0</span>,  <span class="co"># classified as shirts</span></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>                                        <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as OOD</span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>    <span class="cf">return</span> classifications</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_fscore_support</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co"># Assuming ood_probs, id_probs, and train_labels are defined</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="co"># Threshold values</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>upper_threshold <span class="op">=</span> <span class="fl">0.9</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="co"># Classifying OOD examples (sandals)</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>ood_classifications <span class="op">=</span> softmax_thresh_classifications(ood_probs, upper_threshold)</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a><span class="co"># Classifying ID examples (T-shirts and pants)</span></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>id_classifications <span class="op">=</span> softmax_thresh_classifications(id_probs, upper_threshold)</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a><span class="co"># Combine OOD and ID classifications and true labels</span></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a>all_predictions <span class="op">=</span> np.concatenate([ood_classifications, id_classifications])</span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a>all_true_labels <span class="op">=</span> np.concatenate([<span class="op">-</span><span class="dv">1</span> <span class="op">*</span> np.ones(ood_classifications.shape), train_labels])</span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(all_true_labels, all_predictions, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a><span class="co"># Plotting the confusion matrix</span></span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>[<span class="st">"Shirt"</span>, <span class="st">"Pants"</span>, <span class="st">"OOD"</span>])</span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a>disp.plot(cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix for OOD and ID Classification'</span>)</span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a>plt.savefig(<span class="st">'../images/OOD-detection_ID-OOD-confusion-matrix1.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a>plt.show()</span>
<span id="cb13-28"><a href="#cb13-28" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" tabindex="-1"></a><span class="co"># Looking at F1, precision, and recall</span></span>
<span id="cb13-30"><a href="#cb13-30" tabindex="-1"></a>precision, recall, f1, _ <span class="op">=</span> precision_recall_fscore_support(all_true_labels, all_predictions, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>], average<span class="op">=</span><span class="st">'macro'</span>) <span class="co"># discuss macro vs micro .</span></span>
<span id="cb13-31"><a href="#cb13-31" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"F1: </span><span class="sc">{</span>f1<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-33"><a href="#cb13-33" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision: </span><span class="sc">{</span>precision<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-34"><a href="#cb13-34" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall: </span><span class="sc">{</span>recall<span class="sc">}</span><span class="ss">"</span>)</span></code></pre>
</div>
<p><img src="https://raw.githubusercontent.com/carpentries-incubator/fair-explainable-ml/main/images/OOD-detection_ID-OOD-confusion-matrix1.png" alt="Probability densities" class="figure"> Even with a high threshold of 0.9, we end
up with nearly a couple hundred OOD samples classified as ID. In
addition, over 800 ID samples had to be tossed out due to
uncertainty.</p>
</div>
<div class="section level3">
<h3 id="quick-exercise">Quick exercise<a class="anchor" aria-label="anchor" href="#quick-exercise"></a></h3>
<p>What threhsold is required to ensure that no OOD samples are
incorrectly considered as IID? What percentage of ID samples are
mistaken as OOD at this threshold? Answer: 0.9999,
(3826+2414)/(3826+2414+2174+3586)=52%</p>
<p>With a very conservative threshold, we can make sure very few OOD
samples are incorrectly classified as ID. However, the flip side is that
conservative thresholds tend to incorrectly classify many ID samples as
being OOD. In this case, we incorrectly assume almost 20% of shirts are
OOD samples.</p>
</div>
</div>
<div class="section level2">
<h2 id="iterative-threshold-determination">Iterative Threshold Determination<a class="anchor" aria-label="anchor" href="#iterative-threshold-determination"></a></h2>
<p>In practice, selecting an appropriate threshold is an iterative
process that balances the trade-off between correctly identifying
in-distribution (ID) data and accurately flagging out-of-distribution
(OOD) data. Here’s how you can iteratively determine the threshold:</p>
<ul><li><p><strong>Define Evaluation Metrics</strong>: While confusion
matrices are an excellent tool when you’re ready to more closely examine
the data, we need a single metric that can summarize threshold
performance so we can easily compare across threshold. Common metrics
include accuracy, precision, recall, or the F1 score for both ID and OOD
detection.</p></li>
<li><p><strong>Evaluate Over a Range of Thresholds</strong>: Test
different threshold values and evaluate the performance on a validation
set containing both ID and OOD data.</p></li>
<li><p><strong>Select the Optimal Threshold</strong>: Choose the
threshold that provides the best balance according to your chosen
metrics.</p></li>
</ul><p>Use the below code to determine what threshold should be set to
ensure precision = 100%. What threshold is required for recall to be
100%? What threshold gives the highest F1 score?</p>
<div class="section level3">
<h3 id="callout-on-averaging-schemes">Callout on averaging schemes<a class="anchor" aria-label="anchor" href="#callout-on-averaging-schemes"></a></h3>
<p>F1 scores can be calculated per class, and then averaged in different
ways (macro, micro, or weighted) when dealing with multiclass or
multilabel classification problems. Here are the key types of averaging
methods:</p>
<ul><li><p>Macro-Averaging: Calculates the F1 score for each class
independently and then takes the average of these scores. This treats
all classes equally, regardless of their support (number of true
instances for each class).</p></li>
<li><p>Micro-Averaging: Aggregates the contributions of all classes to
compute the average F1 score. This is typically used for imbalanced
datasets as it gives more weight to classes with more
instances.</p></li>
<li><p>Weighted-Averaging: Calculates the F1 score for each class
independently and then takes the average, weighted by the number of true
instances for each class. This accounts for class imbalance by giving
more weight to classes with more instances.</p></li>
</ul></div>
<div class="section level3">
<h3 id="callout-on-including-ood-data-in-f1-calculation">Callout on including OOD data in F1 calculation<a class="anchor" aria-label="anchor" href="#callout-on-including-ood-data-in-f1-calculation"></a></h3>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># from sklearn.metrics import precision_recall_fscore_support, accuracy_score</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a><span class="kw">def</span> eval_softmax_thresholds(thresholds, ood_probs, id_probs):</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>    <span class="co"># Store evaluation metrics for each threshold</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>    precisions <span class="op">=</span> []</span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>    recalls <span class="op">=</span> []</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>    f1_scores <span class="op">=</span> []</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>    </span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>    <span class="cf">for</span> threshold <span class="kw">in</span> thresholds:</span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>        <span class="co"># Classifying OOD examples (sandals)</span></span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a>        ood_classifications <span class="op">=</span> softmax_thresh_classifications(ood_probs, threshold)</span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a>        </span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a>        <span class="co"># Classifying ID examples (T-shirts and pants)</span></span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a>        id_classifications <span class="op">=</span> softmax_thresh_classifications(id_probs, threshold)</span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a>        </span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a>        <span class="co"># Combine OOD and ID classifications and true labels</span></span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a>        all_predictions <span class="op">=</span> np.concatenate([ood_classifications, id_classifications])</span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a>        all_true_labels <span class="op">=</span> np.concatenate([<span class="op">-</span><span class="dv">1</span> <span class="op">*</span> np.ones(ood_classifications.shape), train_labels])</span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a>        </span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a>        <span class="co"># Evaluate metrics</span></span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a>        precision, recall, f1, _ <span class="op">=</span> precision_recall_fscore_support(all_true_labels, all_predictions, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>], average<span class="op">=</span><span class="st">'macro'</span>) <span class="co"># discuss macro vs micro .</span></span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a>        precisions.append(precision)</span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a>        recalls.append(recall)</span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a>        f1_scores.append(f1)</span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a>        </span>
<span id="cb14-26"><a href="#cb14-26" tabindex="-1"></a>    <span class="cf">return</span> precisions, recalls, f1_scores</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co"># Define thresholds to evaluate</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>thresholds <span class="op">=</span> np.linspace(<span class="fl">.5</span>, <span class="dv">1</span>, <span class="dv">50</span>)</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a><span class="co"># Evaluate on all thresholds</span></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>precisions, recalls, f1_scores <span class="op">=</span> eval_softmax_thresholds(thresholds, ood_probs, id_probs)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="kw">def</span> plot_metrics_vs_thresholds(thresholds, f1_scores, precisions, recalls, OOD_signal):</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>    <span class="co"># Find the best thresholds for each metric</span></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>    best_f1_index <span class="op">=</span> np.argmax(f1_scores)</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>    best_f1_threshold <span class="op">=</span> thresholds[best_f1_index]</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>    </span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>    best_precision_index <span class="op">=</span> np.argmax(precisions)</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>    best_precision_threshold <span class="op">=</span> thresholds[best_precision_index]</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>    </span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>    best_recall_index <span class="op">=</span> np.argmax(recalls)</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a>    best_recall_threshold <span class="op">=</span> thresholds[best_recall_index]</span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>    </span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best F1 threshold: </span><span class="sc">{</span>best_f1_threshold<span class="sc">}</span><span class="ss">, F1 Score: </span><span class="sc">{</span>f1_scores[best_f1_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best Precision threshold: </span><span class="sc">{</span>best_precision_threshold<span class="sc">}</span><span class="ss">, Precision: </span><span class="sc">{</span>precisions[best_precision_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best Recall threshold: </span><span class="sc">{</span>best_recall_threshold<span class="sc">}</span><span class="ss">, Recall: </span><span class="sc">{</span>recalls[best_recall_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" tabindex="-1"></a>    <span class="co"># Create a new figure</span></span>
<span id="cb16-17"><a href="#cb16-17" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb16-18"><a href="#cb16-18" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" tabindex="-1"></a>    <span class="co"># Plot metrics as functions of the threshold</span></span>
<span id="cb16-20"><a href="#cb16-20" tabindex="-1"></a>    ax.plot(thresholds, precisions, label<span class="op">=</span><span class="st">'Precision'</span>, color<span class="op">=</span><span class="st">'g'</span>)</span>
<span id="cb16-21"><a href="#cb16-21" tabindex="-1"></a>    ax.plot(thresholds, recalls, label<span class="op">=</span><span class="st">'Recall'</span>, color<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb16-22"><a href="#cb16-22" tabindex="-1"></a>    ax.plot(thresholds, f1_scores, label<span class="op">=</span><span class="st">'F1 Score'</span>, color<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb16-23"><a href="#cb16-23" tabindex="-1"></a>    </span>
<span id="cb16-24"><a href="#cb16-24" tabindex="-1"></a>    <span class="co"># Add best threshold indicators</span></span>
<span id="cb16-25"><a href="#cb16-25" tabindex="-1"></a>    ax.axvline(x<span class="op">=</span>best_f1_threshold, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best F1 Threshold: </span><span class="sc">{</span>best_f1_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb16-26"><a href="#cb16-26" tabindex="-1"></a>    ax.axvline(x<span class="op">=</span>best_precision_threshold, color<span class="op">=</span><span class="st">'g'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best Precision Threshold: </span><span class="sc">{</span>best_precision_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb16-27"><a href="#cb16-27" tabindex="-1"></a>    ax.axvline(x<span class="op">=</span>best_recall_threshold, color<span class="op">=</span><span class="st">'b'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best Recall Threshold: </span><span class="sc">{</span>best_recall_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb16-28"><a href="#cb16-28" tabindex="-1"></a>    ax.set_xlabel(<span class="ss">f'</span><span class="sc">{</span>OOD_signal<span class="sc">}</span><span class="ss"> Threshold'</span>)</span>
<span id="cb16-29"><a href="#cb16-29" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Metric Value'</span>)</span>
<span id="cb16-30"><a href="#cb16-30" tabindex="-1"></a>    ax.set_title(<span class="st">'Evaluation Metrics as Functions of Threshold'</span>)</span>
<span id="cb16-31"><a href="#cb16-31" tabindex="-1"></a>    ax.legend()</span>
<span id="cb16-32"><a href="#cb16-32" tabindex="-1"></a></span>
<span id="cb16-33"><a href="#cb16-33" tabindex="-1"></a>    <span class="cf">return</span> fig, best_f1_threshold, best_precision_threshold, best_recall_threshold</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>fig, best_f1_threshold, best_precision_threshold, best_recall_threshold <span class="op">=</span> plot_metrics_vs_thresholds(thresholds, f1_scores, precisions, recalls, <span class="st">'Softmax'</span>)</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>fig.savefig(<span class="st">'../images/OOD-detection_metrics_vs_softmax-thresholds.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span></code></pre>
</div>
<figure><img src="https://raw.githubusercontent.com/carpentries-incubator/fair-explainable-ml/main/images/OOD-detection_metrics_vs_softmax-thresholds.png" alt="OOD-detection_metrics_vs_softmax-thresholds" class="figure mx-auto d-block"><div class="figcaption">OOD-detection_metrics_vs_softmax-thresholds</div>
</figure><div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="co"># Threshold values</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>upper_threshold <span class="op">=</span> best_f1_threshold</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a><span class="co"># upper_threshold = best_precision_threshold</span></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a><span class="co"># Classifying OOD examples (sandals)</span></span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>ood_classifications <span class="op">=</span> softmax_thresh_classifications(ood_probs, upper_threshold)</span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a><span class="co"># Classifying ID examples (T-shirts and pants)</span></span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a>id_classifications <span class="op">=</span> softmax_thresh_classifications(id_probs, upper_threshold)</span>
<span id="cb18-10"><a href="#cb18-10" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" tabindex="-1"></a><span class="co"># Combine OOD and ID classifications and true labels</span></span>
<span id="cb18-12"><a href="#cb18-12" tabindex="-1"></a>all_predictions <span class="op">=</span> np.concatenate([ood_classifications, id_classifications])</span>
<span id="cb18-13"><a href="#cb18-13" tabindex="-1"></a>all_true_labels <span class="op">=</span> np.concatenate([<span class="op">-</span><span class="dv">1</span> <span class="op">*</span> np.ones(ood_classifications.shape), train_labels])</span>
<span id="cb18-14"><a href="#cb18-14" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb18-16"><a href="#cb18-16" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(all_true_labels, all_predictions, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb18-17"><a href="#cb18-17" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" tabindex="-1"></a><span class="co"># Plotting the confusion matrix</span></span>
<span id="cb18-19"><a href="#cb18-19" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>[<span class="st">"Shirt"</span>, <span class="st">"Pants"</span>, <span class="st">"OOD"</span>])</span>
<span id="cb18-20"><a href="#cb18-20" tabindex="-1"></a>disp.plot(cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb18-21"><a href="#cb18-21" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix for OOD and ID Classification'</span>)</span>
<span id="cb18-22"><a href="#cb18-22" tabindex="-1"></a>plt.savefig(<span class="st">'../images/OOD-detection_ID-OOD-confusion-matrix2.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb18-23"><a href="#cb18-23" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="https://raw.githubusercontent.com/carpentries-incubator/fair-explainable-ml/main/images/OOD-detection_ID-OOD-confusion-matrix2.png" alt="Optimized threshold confusion matrix" class="figure mx-auto d-block"><div class="figcaption">Optimized threshold confusion matrix</div>
</figure></div>
</div>
</div>
<div class="section level1">
<h1 id="example-2-energy-based-ood-detection">Example 2: Energy-Based OOD Detection<a class="anchor" aria-label="anchor" href="#example-2-energy-based-ood-detection"></a></h1>
<p><strong>TODO</strong>: Provide background and intuiiton surrounding
energy-based measure. Some notes below:</p>
<p>Liu et al., Energy-based Out-of-distribution Detection, NeurIPS 2020;
<a href="https://arxiv.org/pdf/2010.03759" class="external-link uri">https://arxiv.org/pdf/2010.03759</a></p>
<ul><li><p>E(x, y) = energy value</p></li>
<li><p>if x and y are “compatitble”, lower energy</p></li>
<li>
<p>Energy can be turned into probability through Gibbs
distribution</p>
<ul><li>looks at integral over all possible y’s</li>
</ul></li>
<li><p>With energy scores, ID and OOD distributions become much more
separable</p></li>
<li><p>Another “output-based” method like softmax</p></li>
<li><p>I believe this measure is explicitly designed to work with neural
nets, but may (?) work with other models</p></li>
</ul><div class="section level2">
<h2 id="introducing-pytorch-ood">Introducing PyTorch OOD<a class="anchor" aria-label="anchor" href="#introducing-pytorch-ood"></a></h2>
<p>The PyTorch-OOD library provides methods for OOD detection and other
closely related fields, such as anomoly detection or novelty detection.
Visit the docs to learn more: <a href="https://pytorch-ood.readthedocs.io/en/latest/info.html" class="external-link">pytorch-ood.readthedocs.io/en/latest/info.html</a></p>
<p>This library will provide a streamlined way to calculate both energy
and softmax scores from a trained model. ### Setup example In this
example, we will train a CNN model on the FashionMNIST dataset. We will
then repeat a similar process as we did with softmax scores to evaluate
how well the energy metric can separate ID and OOD data.</p>
<p>We’ll start by fresh by loading our data again. This time, let’s
treat all remaining classes in the MNIST fashion dataset as OOD. This
should yield a more robust model that is more reliable when presented
with all kinds of data.</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>train_data, test_data, ood_data, train_labels, test_labels, ood_labels <span class="op">=</span> prep_ID_OOD_datasests([<span class="dv">0</span>,<span class="dv">1</span>], <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">2</span>,<span class="dv">10</span>))) <span class="co"># use remaining 8 classes in dataset as OOD</span></span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>fig <span class="op">=</span> plot_data_sample(train_data, ood_data)</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>fig.savefig(<span class="st">'../images/OOD-detection_image-data-preview.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="visualizing-ood-and-id-data-1">Visualizing OOD and ID data<a class="anchor" aria-label="anchor" href="#visualizing-ood-and-id-data-1"></a></h2>
<div class="section level3">
<h3 id="umap-or-similar">UMAP (or similar)<a class="anchor" aria-label="anchor" href="#umap-or-similar"></a></h3>
<p>Recall in our previous example, we used PCA to visualize the ID and
OOD data distributions. This was appropriate given that we were
evaluating OOD/ID data in the context of a linear model. However, when
working with nonlinear models such as CNNs, it makes more sense to
investigate how the data is represented in a nonlinear space. Nonlinear
embedding methods, such as Uniform Manifold Approximation and Projection
(UMAP), are more suitable in such scenarios.</p>
<p>UMAP is a non-linear dimensionality reduction technique that
preserves both the global structure and the local neighborhood
relationships in the data. UMAP is often better at maintaining the
continuity of data points that lie on non-linear manifolds. It can
reveal nonlinear patterns and structures that PCA might miss, making it
a valuable tool for analyzing ID and OOD distributions.</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>plot_umap <span class="op">=</span> <span class="va">True</span> <span class="co"># leave off for now to save time testing downstream materials</span></span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="cf">if</span> plot_umap:</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>    <span class="im">import</span> umap</span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a>    <span class="co"># Flatten images for PCA and logistic regression</span></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a>    train_data_flat <span class="op">=</span> train_data.reshape((train_data.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a>    test_data_flat <span class="op">=</span> test_data.reshape((test_data.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a>    ood_data_flat <span class="op">=</span> ood_data.reshape((ood_data.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb20-8"><a href="#cb20-8" tabindex="-1"></a>    </span>
<span id="cb20-9"><a href="#cb20-9" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'train_data_flat.shape=</span><span class="sc">{</span>train_data_flat<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb20-10"><a href="#cb20-10" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'test_data_flat.shape=</span><span class="sc">{</span>test_data_flat<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb20-11"><a href="#cb20-11" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'ood_data_flat.shape=</span><span class="sc">{</span>ood_data_flat<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb20-12"><a href="#cb20-12" tabindex="-1"></a>    </span>
<span id="cb20-13"><a href="#cb20-13" tabindex="-1"></a>    <span class="co"># Perform UMAP to visualize the data</span></span>
<span id="cb20-14"><a href="#cb20-14" tabindex="-1"></a>    umap_reducer <span class="op">=</span> umap.UMAP(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb20-15"><a href="#cb20-15" tabindex="-1"></a>    combined_data <span class="op">=</span> np.vstack([train_data_flat, ood_data_flat])</span>
<span id="cb20-16"><a href="#cb20-16" tabindex="-1"></a>    combined_labels <span class="op">=</span> np.hstack([train_labels, np.full(ood_data_flat.shape[<span class="dv">0</span>], <span class="dv">2</span>)])  <span class="co"># Use 2 for OOD class</span></span>
<span id="cb20-17"><a href="#cb20-17" tabindex="-1"></a>    </span>
<span id="cb20-18"><a href="#cb20-18" tabindex="-1"></a>    umap_results <span class="op">=</span> umap_reducer.fit_transform(combined_data)</span>
<span id="cb20-19"><a href="#cb20-19" tabindex="-1"></a>    </span>
<span id="cb20-20"><a href="#cb20-20" tabindex="-1"></a>    <span class="co"># Split the results back into in-distribution and OOD data</span></span>
<span id="cb20-21"><a href="#cb20-21" tabindex="-1"></a>    umap_in_dist <span class="op">=</span> umap_results[:<span class="bu">len</span>(train_data_flat)]</span>
<span id="cb20-22"><a href="#cb20-22" tabindex="-1"></a>    umap_ood <span class="op">=</span> umap_results[<span class="bu">len</span>(train_data_flat):]</span></code></pre>
</div>
<p>The warning message indicates that UMAP has overridden the n_jobs
parameter to 1 due to the random_state being set. This behavior ensures
reproducibility by using a single job. If you want to avoid the warning
and still use parallelism, you can remove the random_state parameter.
However, removing random_state will mean that the results might not be
reproducible.</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="cf">if</span> plot_umap:</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>    umap_alpha <span class="op">=</span> <span class="fl">.02</span></span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a>    <span class="co"># Plotting UMAP components</span></span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb21-6"><a href="#cb21-6" tabindex="-1"></a>    </span>
<span id="cb21-7"><a href="#cb21-7" tabindex="-1"></a>    <span class="co"># Plot in-distribution data</span></span>
<span id="cb21-8"><a href="#cb21-8" tabindex="-1"></a>    scatter1 <span class="op">=</span> plt.scatter(umap_in_dist[train_labels <span class="op">==</span> <span class="dv">0</span>, <span class="dv">0</span>], umap_in_dist[train_labels <span class="op">==</span> <span class="dv">0</span>, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'T-shirts (ID)'</span>, alpha<span class="op">=</span>umap_alpha)</span>
<span id="cb21-9"><a href="#cb21-9" tabindex="-1"></a>    scatter2 <span class="op">=</span> plt.scatter(umap_in_dist[train_labels <span class="op">==</span> <span class="dv">1</span>, <span class="dv">0</span>], umap_in_dist[train_labels <span class="op">==</span> <span class="dv">1</span>, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Trousers (ID)'</span>, alpha<span class="op">=</span>umap_alpha)</span>
<span id="cb21-10"><a href="#cb21-10" tabindex="-1"></a>    </span>
<span id="cb21-11"><a href="#cb21-11" tabindex="-1"></a>    <span class="co"># Plot OOD data</span></span>
<span id="cb21-12"><a href="#cb21-12" tabindex="-1"></a>    scatter3 <span class="op">=</span> plt.scatter(umap_ood[:, <span class="dv">0</span>], umap_ood[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'OOD'</span>, edgecolor<span class="op">=</span><span class="st">'k'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb21-13"><a href="#cb21-13" tabindex="-1"></a>    </span>
<span id="cb21-14"><a href="#cb21-14" tabindex="-1"></a>    <span class="co"># Create a single legend for all classes</span></span>
<span id="cb21-15"><a href="#cb21-15" tabindex="-1"></a>    plt.legend(handles<span class="op">=</span>[scatter1, scatter2, scatter3], loc<span class="op">=</span><span class="st">"upper right"</span>)</span>
<span id="cb21-16"><a href="#cb21-16" tabindex="-1"></a>    plt.xlabel(<span class="st">'First UMAP Component'</span>)</span>
<span id="cb21-17"><a href="#cb21-17" tabindex="-1"></a>    plt.ylabel(<span class="st">'Second UMAP Component'</span>)</span>
<span id="cb21-18"><a href="#cb21-18" tabindex="-1"></a>    plt.title(<span class="st">'UMAP of In-Distribution and OOD Data'</span>)</span>
<span id="cb21-19"><a href="#cb21-19" tabindex="-1"></a>    plt.show()</span></code></pre>
</div>
</div>
</div>
<div class="section level2">
<h2 id="train-cnn">Train CNN<a class="anchor" aria-label="anchor" href="#train-cnn"></a></h2>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a><span class="co"># Convert to PyTorch tensors and normalize</span></span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a>train_data_tensor <span class="op">=</span> torch.tensor(train_data, dtype<span class="op">=</span>torch.float32).unsqueeze(<span class="dv">1</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a>test_data_tensor <span class="op">=</span> torch.tensor(test_data, dtype<span class="op">=</span>torch.float32).unsqueeze(<span class="dv">1</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a>ood_data_tensor <span class="op">=</span> torch.tensor(ood_data, dtype<span class="op">=</span>torch.float32).unsqueeze(<span class="dv">1</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb22-11"><a href="#cb22-11" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" tabindex="-1"></a>train_labels_tensor <span class="op">=</span> torch.tensor(train_labels, dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb22-13"><a href="#cb22-13" tabindex="-1"></a>test_labels_tensor <span class="op">=</span> torch.tensor(test_labels, dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb22-14"><a href="#cb22-14" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" tabindex="-1"></a>train_dataset <span class="op">=</span> torch.utils.data.TensorDataset(train_data_tensor, train_labels_tensor)</span>
<span id="cb22-16"><a href="#cb22-16" tabindex="-1"></a>test_dataset <span class="op">=</span> torch.utils.data.TensorDataset(test_data_tensor, test_labels_tensor)</span>
<span id="cb22-17"><a href="#cb22-17" tabindex="-1"></a>ood_dataset <span class="op">=</span> torch.utils.data.TensorDataset(ood_data_tensor, torch.zeros(ood_data_tensor.shape[<span class="dv">0</span>], dtype<span class="op">=</span>torch.<span class="bu">long</span>))</span>
<span id="cb22-18"><a href="#cb22-18" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" tabindex="-1"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(train_dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-20"><a href="#cb22-20" tabindex="-1"></a>test_loader <span class="op">=</span> torch.utils.data.DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb22-21"><a href="#cb22-21" tabindex="-1"></a>ood_loader <span class="op">=</span> torch.utils.data.DataLoader(ood_dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb22-22"><a href="#cb22-22" tabindex="-1"></a></span>
<span id="cb22-23"><a href="#cb22-23" tabindex="-1"></a><span class="co"># Define a simple CNN model</span></span>
<span id="cb22-24"><a href="#cb22-24" tabindex="-1"></a><span class="kw">class</span> SimpleCNN(nn.Module):</span>
<span id="cb22-25"><a href="#cb22-25" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb22-26"><a href="#cb22-26" tabindex="-1"></a>        <span class="bu">super</span>(SimpleCNN, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb22-27"><a href="#cb22-27" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">1</span>, <span class="dv">32</span>, kernel_size<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb22-28"><a href="#cb22-28" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">32</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb22-29"><a href="#cb22-29" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">64</span><span class="op">*</span><span class="dv">5</span><span class="op">*</span><span class="dv">5</span>, <span class="dv">128</span>)  <span class="co"># Updated this line</span></span>
<span id="cb22-30"><a href="#cb22-30" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">128</span>, <span class="dv">2</span>)</span>
<span id="cb22-31"><a href="#cb22-31" tabindex="-1"></a></span>
<span id="cb22-32"><a href="#cb22-32" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb22-33"><a href="#cb22-33" tabindex="-1"></a>        x <span class="op">=</span> F.relu(F.max_pool2d(<span class="va">self</span>.conv1(x), <span class="dv">2</span>))</span>
<span id="cb22-34"><a href="#cb22-34" tabindex="-1"></a>        x <span class="op">=</span> F.relu(F.max_pool2d(<span class="va">self</span>.conv2(x), <span class="dv">2</span>))</span>
<span id="cb22-35"><a href="#cb22-35" tabindex="-1"></a>        x <span class="op">=</span> x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">64</span><span class="op">*</span><span class="dv">5</span><span class="op">*</span><span class="dv">5</span>)  <span class="co"># Updated this line</span></span>
<span id="cb22-36"><a href="#cb22-36" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.fc1(x))</span>
<span id="cb22-37"><a href="#cb22-37" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb22-38"><a href="#cb22-38" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb22-39"><a href="#cb22-39" tabindex="-1"></a></span>
<span id="cb22-40"><a href="#cb22-40" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span>)</span>
<span id="cb22-41"><a href="#cb22-41" tabindex="-1"></a>model <span class="op">=</span> SimpleCNN().to(device)</span>
<span id="cb22-42"><a href="#cb22-42" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb22-43"><a href="#cb22-43" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb22-44"><a href="#cb22-44" tabindex="-1"></a></span>
<span id="cb22-45"><a href="#cb22-45" tabindex="-1"></a><span class="kw">def</span> train_model(model, train_loader, criterion, optimizer, epochs<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb22-46"><a href="#cb22-46" tabindex="-1"></a>    model.train()</span>
<span id="cb22-47"><a href="#cb22-47" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb22-48"><a href="#cb22-48" tabindex="-1"></a>        running_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb22-49"><a href="#cb22-49" tabindex="-1"></a>        <span class="cf">for</span> inputs, labels <span class="kw">in</span> train_loader:</span>
<span id="cb22-50"><a href="#cb22-50" tabindex="-1"></a>            inputs, labels <span class="op">=</span> inputs.to(device), labels.to(device)</span>
<span id="cb22-51"><a href="#cb22-51" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb22-52"><a href="#cb22-52" tabindex="-1"></a>            outputs <span class="op">=</span> model(inputs)</span>
<span id="cb22-53"><a href="#cb22-53" tabindex="-1"></a>            loss <span class="op">=</span> criterion(outputs, labels)</span>
<span id="cb22-54"><a href="#cb22-54" tabindex="-1"></a>            loss.backward()</span>
<span id="cb22-55"><a href="#cb22-55" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb22-56"><a href="#cb22-56" tabindex="-1"></a>            running_loss <span class="op">+=</span> loss.item()</span>
<span id="cb22-57"><a href="#cb22-57" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>running_loss<span class="op">/</span><span class="bu">len</span>(train_loader)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb22-58"><a href="#cb22-58" tabindex="-1"></a></span>
<span id="cb22-59"><a href="#cb22-59" tabindex="-1"></a>train_model(model, train_loader, criterion, optimizer)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a><span class="co"># Function to plot confusion matrix</span></span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a><span class="kw">def</span> plot_confusion_matrix(labels, predictions, title):</span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a>    cm <span class="op">=</span> confusion_matrix(labels, predictions, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a>    disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>[<span class="st">"T-shirt/top"</span>, <span class="st">"Trouser"</span>])</span>
<span id="cb23-7"><a href="#cb23-7" tabindex="-1"></a>    disp.plot(cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb23-8"><a href="#cb23-8" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb23-9"><a href="#cb23-9" tabindex="-1"></a>    plt.show()</span>
<span id="cb23-10"><a href="#cb23-10" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" tabindex="-1"></a><span class="co"># Function to evaluate model on a dataset</span></span>
<span id="cb23-12"><a href="#cb23-12" tabindex="-1"></a><span class="kw">def</span> evaluate_model(model, dataloader, device):</span>
<span id="cb23-13"><a href="#cb23-13" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb23-14"><a href="#cb23-14" tabindex="-1"></a>    all_labels <span class="op">=</span> []</span>
<span id="cb23-15"><a href="#cb23-15" tabindex="-1"></a>    all_predictions <span class="op">=</span> []</span>
<span id="cb23-16"><a href="#cb23-16" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb23-17"><a href="#cb23-17" tabindex="-1"></a>        <span class="cf">for</span> inputs, labels <span class="kw">in</span> dataloader:</span>
<span id="cb23-18"><a href="#cb23-18" tabindex="-1"></a>            inputs, labels <span class="op">=</span> inputs.to(device), labels.to(device)</span>
<span id="cb23-19"><a href="#cb23-19" tabindex="-1"></a>            outputs <span class="op">=</span> model(inputs)</span>
<span id="cb23-20"><a href="#cb23-20" tabindex="-1"></a>            _, preds <span class="op">=</span> torch.<span class="bu">max</span>(outputs, <span class="dv">1</span>)</span>
<span id="cb23-21"><a href="#cb23-21" tabindex="-1"></a>            all_labels.extend(labels.cpu().numpy())</span>
<span id="cb23-22"><a href="#cb23-22" tabindex="-1"></a>            all_predictions.extend(preds.cpu().numpy())</span>
<span id="cb23-23"><a href="#cb23-23" tabindex="-1"></a>    <span class="cf">return</span> np.array(all_labels), np.array(all_predictions)</span>
<span id="cb23-24"><a href="#cb23-24" tabindex="-1"></a></span>
<span id="cb23-25"><a href="#cb23-25" tabindex="-1"></a><span class="co"># Evaluate on train data</span></span>
<span id="cb23-26"><a href="#cb23-26" tabindex="-1"></a>train_labels, train_predictions <span class="op">=</span> evaluate_model(model, train_loader, device)</span>
<span id="cb23-27"><a href="#cb23-27" tabindex="-1"></a>plot_confusion_matrix(train_labels, train_predictions, <span class="st">"Confusion Matrix for Train Data"</span>)</span>
<span id="cb23-28"><a href="#cb23-28" tabindex="-1"></a></span>
<span id="cb23-29"><a href="#cb23-29" tabindex="-1"></a><span class="co"># Evaluate on test data</span></span>
<span id="cb23-30"><a href="#cb23-30" tabindex="-1"></a>test_labels, test_predictions <span class="op">=</span> evaluate_model(model, test_loader, device)</span>
<span id="cb23-31"><a href="#cb23-31" tabindex="-1"></a>plot_confusion_matrix(test_labels, test_predictions, <span class="st">"Confusion Matrix for Test Data"</span>)</span>
<span id="cb23-32"><a href="#cb23-32" tabindex="-1"></a></span>
<span id="cb23-33"><a href="#cb23-33" tabindex="-1"></a><span class="co"># Evaluate on OOD data</span></span>
<span id="cb23-34"><a href="#cb23-34" tabindex="-1"></a>ood_labels, ood_predictions <span class="op">=</span> evaluate_model(model, ood_loader, device)</span>
<span id="cb23-35"><a href="#cb23-35" tabindex="-1"></a>plot_confusion_matrix(ood_labels, ood_predictions, <span class="st">"Confusion Matrix for OOD Data"</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> gaussian_kde</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a><span class="im">from</span> pytorch_ood.detector <span class="im">import</span> EnergyBased</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_fscore_support, accuracy_score</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a><span class="co"># Compute softmax scores</span></span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a><span class="kw">def</span> get_softmax_scores(model, dataloader):</span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a>    softmax_scores <span class="op">=</span> []</span>
<span id="cb24-9"><a href="#cb24-9" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-10"><a href="#cb24-10" tabindex="-1"></a>        <span class="cf">for</span> inputs, _ <span class="kw">in</span> dataloader:</span>
<span id="cb24-11"><a href="#cb24-11" tabindex="-1"></a>            inputs <span class="op">=</span> inputs.to(device)</span>
<span id="cb24-12"><a href="#cb24-12" tabindex="-1"></a>            outputs <span class="op">=</span> model(inputs)</span>
<span id="cb24-13"><a href="#cb24-13" tabindex="-1"></a>            softmax <span class="op">=</span> torch.nn.functional.softmax(outputs, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-14"><a href="#cb24-14" tabindex="-1"></a>            softmax_scores.extend(softmax.cpu().numpy())</span>
<span id="cb24-15"><a href="#cb24-15" tabindex="-1"></a>    <span class="cf">return</span> np.array(softmax_scores)</span>
<span id="cb24-16"><a href="#cb24-16" tabindex="-1"></a></span>
<span id="cb24-17"><a href="#cb24-17" tabindex="-1"></a>id_softmax_scores <span class="op">=</span> get_softmax_scores(model, test_loader)</span>
<span id="cb24-18"><a href="#cb24-18" tabindex="-1"></a>ood_softmax_scores <span class="op">=</span> get_softmax_scores(model, ood_loader)</span>
<span id="cb24-19"><a href="#cb24-19" tabindex="-1"></a></span>
<span id="cb24-20"><a href="#cb24-20" tabindex="-1"></a><span class="co"># Initialize the energy-based OOD detector</span></span>
<span id="cb24-21"><a href="#cb24-21" tabindex="-1"></a>energy_detector <span class="op">=</span> EnergyBased(model, t<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb24-22"><a href="#cb24-22" tabindex="-1"></a></span>
<span id="cb24-23"><a href="#cb24-23" tabindex="-1"></a><span class="co"># Compute energy scores</span></span>
<span id="cb24-24"><a href="#cb24-24" tabindex="-1"></a><span class="kw">def</span> get_energy_scores(detector, dataloader):</span>
<span id="cb24-25"><a href="#cb24-25" tabindex="-1"></a>    scores <span class="op">=</span> []</span>
<span id="cb24-26"><a href="#cb24-26" tabindex="-1"></a>    detector.model.<span class="bu">eval</span>()</span>
<span id="cb24-27"><a href="#cb24-27" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-28"><a href="#cb24-28" tabindex="-1"></a>        <span class="cf">for</span> inputs, _ <span class="kw">in</span> dataloader:</span>
<span id="cb24-29"><a href="#cb24-29" tabindex="-1"></a>            inputs <span class="op">=</span> inputs.to(device)</span>
<span id="cb24-30"><a href="#cb24-30" tabindex="-1"></a>            score <span class="op">=</span> detector.predict(inputs)</span>
<span id="cb24-31"><a href="#cb24-31" tabindex="-1"></a>            scores.extend(score.cpu().numpy())</span>
<span id="cb24-32"><a href="#cb24-32" tabindex="-1"></a>    <span class="cf">return</span> np.array(scores)</span>
<span id="cb24-33"><a href="#cb24-33" tabindex="-1"></a></span>
<span id="cb24-34"><a href="#cb24-34" tabindex="-1"></a>id_energy_scores <span class="op">=</span> get_energy_scores(energy_detector, test_loader)</span>
<span id="cb24-35"><a href="#cb24-35" tabindex="-1"></a>ood_energy_scores <span class="op">=</span> get_energy_scores(energy_detector, ood_loader)</span>
<span id="cb24-36"><a href="#cb24-36" tabindex="-1"></a></span>
<span id="cb24-37"><a href="#cb24-37" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb24-38"><a href="#cb24-38" tabindex="-1"></a></span>
<span id="cb24-39"><a href="#cb24-39" tabindex="-1"></a></span>
<span id="cb24-40"><a href="#cb24-40" tabindex="-1"></a><span class="co"># Plot PSDs</span></span>
<span id="cb24-41"><a href="#cb24-41" tabindex="-1"></a></span>
<span id="cb24-42"><a href="#cb24-42" tabindex="-1"></a><span class="co"># Function to plot PSD</span></span>
<span id="cb24-43"><a href="#cb24-43" tabindex="-1"></a><span class="kw">def</span> plot_psd(id_scores, ood_scores, method_name):</span>
<span id="cb24-44"><a href="#cb24-44" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb24-45"><a href="#cb24-45" tabindex="-1"></a>    alpha <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb24-46"><a href="#cb24-46" tabindex="-1"></a></span>
<span id="cb24-47"><a href="#cb24-47" tabindex="-1"></a>    <span class="co"># Plot PSD for ID scores</span></span>
<span id="cb24-48"><a href="#cb24-48" tabindex="-1"></a>    id_density <span class="op">=</span> gaussian_kde(id_scores)</span>
<span id="cb24-49"><a href="#cb24-49" tabindex="-1"></a>    x_id <span class="op">=</span> np.linspace(id_scores.<span class="bu">min</span>(), id_scores.<span class="bu">max</span>(), <span class="dv">1000</span>)</span>
<span id="cb24-50"><a href="#cb24-50" tabindex="-1"></a>    plt.plot(x_id, id_density(x_id), label<span class="op">=</span><span class="ss">f'ID (</span><span class="sc">{</span>method_name<span class="sc">}</span><span class="ss">)'</span>, color<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb24-51"><a href="#cb24-51" tabindex="-1"></a></span>
<span id="cb24-52"><a href="#cb24-52" tabindex="-1"></a>    <span class="co"># Plot PSD for OOD scores</span></span>
<span id="cb24-53"><a href="#cb24-53" tabindex="-1"></a>    ood_density <span class="op">=</span> gaussian_kde(ood_scores)</span>
<span id="cb24-54"><a href="#cb24-54" tabindex="-1"></a>    x_ood <span class="op">=</span> np.linspace(ood_scores.<span class="bu">min</span>(), ood_scores.<span class="bu">max</span>(), <span class="dv">1000</span>)</span>
<span id="cb24-55"><a href="#cb24-55" tabindex="-1"></a>    plt.plot(x_ood, ood_density(x_ood), label<span class="op">=</span><span class="ss">f'OOD (</span><span class="sc">{</span>method_name<span class="sc">}</span><span class="ss">)'</span>, color<span class="op">=</span><span class="st">'red'</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb24-56"><a href="#cb24-56" tabindex="-1"></a></span>
<span id="cb24-57"><a href="#cb24-57" tabindex="-1"></a>    plt.xlabel(<span class="st">'Score'</span>)</span>
<span id="cb24-58"><a href="#cb24-58" tabindex="-1"></a>    plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb24-59"><a href="#cb24-59" tabindex="-1"></a>    plt.title(<span class="ss">f'Probability Density Distributions for </span><span class="sc">{</span>method_name<span class="sc">}</span><span class="ss"> Scores'</span>)</span>
<span id="cb24-60"><a href="#cb24-60" tabindex="-1"></a>    plt.legend()</span>
<span id="cb24-61"><a href="#cb24-61" tabindex="-1"></a>    plt.show()</span>
<span id="cb24-62"><a href="#cb24-62" tabindex="-1"></a></span>
<span id="cb24-63"><a href="#cb24-63" tabindex="-1"></a><span class="co"># Plot PSD for softmax scores</span></span>
<span id="cb24-64"><a href="#cb24-64" tabindex="-1"></a>plot_psd(id_softmax_scores[:, <span class="dv">1</span>], ood_softmax_scores[:, <span class="dv">1</span>], <span class="st">'Softmax'</span>)</span>
<span id="cb24-65"><a href="#cb24-65" tabindex="-1"></a></span>
<span id="cb24-66"><a href="#cb24-66" tabindex="-1"></a><span class="co"># Plot PSD for energy scores</span></span>
<span id="cb24-67"><a href="#cb24-67" tabindex="-1"></a>plot_psd(id_energy_scores, ood_energy_scores, <span class="st">'Energy'</span>)</span>
<span id="cb24-68"><a href="#cb24-68" tabindex="-1"></a></span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_fscore_support, accuracy_score, confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" tabindex="-1"></a><span class="co"># Define thresholds to evaluate</span></span>
<span id="cb25-6"><a href="#cb25-6" tabindex="-1"></a>thresholds <span class="op">=</span> np.linspace(id_energy_scores.<span class="bu">min</span>(), id_energy_scores.<span class="bu">max</span>(), <span class="dv">50</span>)</span>
<span id="cb25-7"><a href="#cb25-7" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" tabindex="-1"></a><span class="co"># Store evaluation metrics for each threshold</span></span>
<span id="cb25-9"><a href="#cb25-9" tabindex="-1"></a>accuracies <span class="op">=</span> []</span>
<span id="cb25-10"><a href="#cb25-10" tabindex="-1"></a>precisions <span class="op">=</span> []</span>
<span id="cb25-11"><a href="#cb25-11" tabindex="-1"></a>recalls <span class="op">=</span> []</span>
<span id="cb25-12"><a href="#cb25-12" tabindex="-1"></a>f1_scores <span class="op">=</span> []</span>
<span id="cb25-13"><a href="#cb25-13" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" tabindex="-1"></a><span class="co"># True labels for OOD data (since they are not part of the original labels)</span></span>
<span id="cb25-15"><a href="#cb25-15" tabindex="-1"></a>ood_true_labels <span class="op">=</span> np.full(<span class="bu">len</span>(ood_energy_scores), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb25-16"><a href="#cb25-16" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" tabindex="-1"></a><span class="co"># We need the test_labels to be aligned with the ID data</span></span>
<span id="cb25-18"><a href="#cb25-18" tabindex="-1"></a>id_true_labels <span class="op">=</span> test_labels[:<span class="bu">len</span>(id_energy_scores)]</span>
<span id="cb25-19"><a href="#cb25-19" tabindex="-1"></a></span>
<span id="cb25-20"><a href="#cb25-20" tabindex="-1"></a><span class="cf">for</span> threshold <span class="kw">in</span> thresholds:</span>
<span id="cb25-21"><a href="#cb25-21" tabindex="-1"></a>    <span class="co"># Classify OOD examples based on energy scores</span></span>
<span id="cb25-22"><a href="#cb25-22" tabindex="-1"></a>    ood_classifications <span class="op">=</span> np.where(ood_energy_scores <span class="op">&gt;=</span> threshold, <span class="op">-</span><span class="dv">1</span>,  <span class="co"># classified as OOD</span></span>
<span id="cb25-23"><a href="#cb25-23" tabindex="-1"></a>                                   np.where(ood_energy_scores <span class="op">&lt;</span> threshold, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as ID</span></span>
<span id="cb25-24"><a href="#cb25-24" tabindex="-1"></a></span>
<span id="cb25-25"><a href="#cb25-25" tabindex="-1"></a>    <span class="co"># Classify ID examples based on energy scores</span></span>
<span id="cb25-26"><a href="#cb25-26" tabindex="-1"></a>    id_classifications <span class="op">=</span> np.where(id_energy_scores <span class="op">&gt;=</span> threshold, <span class="op">-</span><span class="dv">1</span>,  <span class="co"># classified as OOD</span></span>
<span id="cb25-27"><a href="#cb25-27" tabindex="-1"></a>                                  np.where(id_energy_scores <span class="op">&lt;</span> threshold, id_true_labels, <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as ID</span></span>
<span id="cb25-28"><a href="#cb25-28" tabindex="-1"></a></span>
<span id="cb25-29"><a href="#cb25-29" tabindex="-1"></a>    <span class="co"># Combine OOD and ID classifications and true labels</span></span>
<span id="cb25-30"><a href="#cb25-30" tabindex="-1"></a>    all_predictions <span class="op">=</span> np.concatenate([ood_classifications, id_classifications])</span>
<span id="cb25-31"><a href="#cb25-31" tabindex="-1"></a>    all_true_labels <span class="op">=</span> np.concatenate([ood_true_labels, id_true_labels])</span>
<span id="cb25-32"><a href="#cb25-32" tabindex="-1"></a></span>
<span id="cb25-33"><a href="#cb25-33" tabindex="-1"></a>    <span class="co"># Evaluate metrics</span></span>
<span id="cb25-34"><a href="#cb25-34" tabindex="-1"></a>    precision, recall, f1, _ <span class="op">=</span> precision_recall_fscore_support(all_true_labels, all_predictions, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>], average<span class="op">=</span><span class="st">'macro'</span>)<span class="co">#, zero_division=0)</span></span>
<span id="cb25-35"><a href="#cb25-35" tabindex="-1"></a>    accuracy <span class="op">=</span> accuracy_score(all_true_labels, all_predictions)</span>
<span id="cb25-36"><a href="#cb25-36" tabindex="-1"></a></span>
<span id="cb25-37"><a href="#cb25-37" tabindex="-1"></a>    accuracies.append(accuracy)</span>
<span id="cb25-38"><a href="#cb25-38" tabindex="-1"></a>    precisions.append(precision)</span>
<span id="cb25-39"><a href="#cb25-39" tabindex="-1"></a>    recalls.append(recall)</span>
<span id="cb25-40"><a href="#cb25-40" tabindex="-1"></a>    f1_scores.append(f1)</span>
<span id="cb25-41"><a href="#cb25-41" tabindex="-1"></a></span>
<span id="cb25-42"><a href="#cb25-42" tabindex="-1"></a><span class="co"># Find the best thresholds for each metric</span></span>
<span id="cb25-43"><a href="#cb25-43" tabindex="-1"></a>best_f1_index <span class="op">=</span> np.argmax(f1_scores)</span>
<span id="cb25-44"><a href="#cb25-44" tabindex="-1"></a>best_f1_threshold <span class="op">=</span> thresholds[best_f1_index]</span>
<span id="cb25-45"><a href="#cb25-45" tabindex="-1"></a></span>
<span id="cb25-46"><a href="#cb25-46" tabindex="-1"></a>best_precision_index <span class="op">=</span> np.argmax(precisions)</span>
<span id="cb25-47"><a href="#cb25-47" tabindex="-1"></a>best_precision_threshold <span class="op">=</span> thresholds[best_precision_index]</span>
<span id="cb25-48"><a href="#cb25-48" tabindex="-1"></a></span>
<span id="cb25-49"><a href="#cb25-49" tabindex="-1"></a>best_recall_index <span class="op">=</span> np.argmax(recalls)</span>
<span id="cb25-50"><a href="#cb25-50" tabindex="-1"></a>best_recall_threshold <span class="op">=</span> thresholds[best_recall_index]</span>
<span id="cb25-51"><a href="#cb25-51" tabindex="-1"></a></span>
<span id="cb25-52"><a href="#cb25-52" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best F1 threshold: </span><span class="sc">{</span>best_f1_threshold<span class="sc">}</span><span class="ss">, F1 Score: </span><span class="sc">{</span>f1_scores[best_f1_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-53"><a href="#cb25-53" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Precision threshold: </span><span class="sc">{</span>best_precision_threshold<span class="sc">}</span><span class="ss">, Precision: </span><span class="sc">{</span>precisions[best_precision_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-54"><a href="#cb25-54" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best Recall threshold: </span><span class="sc">{</span>best_recall_threshold<span class="sc">}</span><span class="ss">, Recall: </span><span class="sc">{</span>recalls[best_recall_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-55"><a href="#cb25-55" tabindex="-1"></a></span>
<span id="cb25-56"><a href="#cb25-56" tabindex="-1"></a><span class="co"># Plot metrics as functions of the threshold</span></span>
<span id="cb25-57"><a href="#cb25-57" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb25-58"><a href="#cb25-58" tabindex="-1"></a>plt.plot(thresholds, precisions, label<span class="op">=</span><span class="st">'Precision'</span>, color<span class="op">=</span><span class="st">'g'</span>)</span>
<span id="cb25-59"><a href="#cb25-59" tabindex="-1"></a>plt.plot(thresholds, recalls, label<span class="op">=</span><span class="st">'Recall'</span>, color<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb25-60"><a href="#cb25-60" tabindex="-1"></a>plt.plot(thresholds, f1_scores, label<span class="op">=</span><span class="st">'F1 Score'</span>, color<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb25-61"><a href="#cb25-61" tabindex="-1"></a></span>
<span id="cb25-62"><a href="#cb25-62" tabindex="-1"></a><span class="co"># Add best threshold indicators</span></span>
<span id="cb25-63"><a href="#cb25-63" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>best_f1_threshold, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best F1 Threshold: </span><span class="sc">{</span>best_f1_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb25-64"><a href="#cb25-64" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>best_precision_threshold, color<span class="op">=</span><span class="st">'g'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best Precision Threshold: </span><span class="sc">{</span>best_precision_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb25-65"><a href="#cb25-65" tabindex="-1"></a>plt.axvline(x<span class="op">=</span>best_recall_threshold, color<span class="op">=</span><span class="st">'b'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best Recall Threshold: </span><span class="sc">{</span>best_recall_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb25-66"><a href="#cb25-66" tabindex="-1"></a></span>
<span id="cb25-67"><a href="#cb25-67" tabindex="-1"></a>plt.xlabel(<span class="st">'Threshold'</span>)</span>
<span id="cb25-68"><a href="#cb25-68" tabindex="-1"></a>plt.ylabel(<span class="st">'Metric Value'</span>)</span>
<span id="cb25-69"><a href="#cb25-69" tabindex="-1"></a>plt.title(<span class="st">'Evaluation Metrics as Functions of Threshold (Energy-Based OOD Detection)'</span>)</span>
<span id="cb25-70"><a href="#cb25-70" tabindex="-1"></a>plt.legend()</span>
<span id="cb25-71"><a href="#cb25-71" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb26">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a></span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_fscore_support, accuracy_score, confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb26-5"><a href="#cb26-5" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-7"><a href="#cb26-7" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb26-8"><a href="#cb26-8" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_fscore_support, accuracy_score</span>
<span id="cb26-9"><a href="#cb26-9" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" tabindex="-1"></a><span class="kw">def</span> evaluate_ood_detection(id_scores, ood_scores, id_true_labels, id_predictions, ood_predictions, score_type<span class="op">=</span><span class="st">'energy'</span>):</span>
<span id="cb26-11"><a href="#cb26-11" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb26-12"><a href="#cb26-12" tabindex="-1"></a><span class="co">    Evaluate OOD detection based on either energy scores or softmax scores.</span></span>
<span id="cb26-13"><a href="#cb26-13" tabindex="-1"></a></span>
<span id="cb26-14"><a href="#cb26-14" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb26-15"><a href="#cb26-15" tabindex="-1"></a><span class="co">    - id_scores: np.array, scores for in-distribution (ID) data</span></span>
<span id="cb26-16"><a href="#cb26-16" tabindex="-1"></a><span class="co">    - ood_scores: np.array, scores for out-of-distribution (OOD) data</span></span>
<span id="cb26-17"><a href="#cb26-17" tabindex="-1"></a><span class="co">    - id_true_labels: np.array, true labels for ID data</span></span>
<span id="cb26-18"><a href="#cb26-18" tabindex="-1"></a><span class="co">    - id_predictions: np.array, predicted labels for ID data</span></span>
<span id="cb26-19"><a href="#cb26-19" tabindex="-1"></a><span class="co">    - ood_predictions: np.array, predicted labels for OOD data</span></span>
<span id="cb26-20"><a href="#cb26-20" tabindex="-1"></a><span class="co">    - score_type: str, type of score used ('energy' or 'softmax')</span></span>
<span id="cb26-21"><a href="#cb26-21" tabindex="-1"></a></span>
<span id="cb26-22"><a href="#cb26-22" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb26-23"><a href="#cb26-23" tabindex="-1"></a><span class="co">    - Best thresholds for F1, Precision, and Recall</span></span>
<span id="cb26-24"><a href="#cb26-24" tabindex="-1"></a><span class="co">    - Plots of Precision, Recall, and F1 Score as functions of the threshold</span></span>
<span id="cb26-25"><a href="#cb26-25" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb26-26"><a href="#cb26-26" tabindex="-1"></a>    <span class="co"># Define thresholds to evaluate</span></span>
<span id="cb26-27"><a href="#cb26-27" tabindex="-1"></a>    <span class="cf">if</span> score_type <span class="op">==</span> <span class="st">'softmax'</span>:</span>
<span id="cb26-28"><a href="#cb26-28" tabindex="-1"></a>        thresholds <span class="op">=</span> np.linspace(<span class="fl">0.5</span>, <span class="fl">1.0</span>, <span class="dv">200</span>)</span>
<span id="cb26-29"><a href="#cb26-29" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb26-30"><a href="#cb26-30" tabindex="-1"></a>        thresholds <span class="op">=</span> np.linspace(id_scores.<span class="bu">min</span>(), id_scores.<span class="bu">max</span>(), <span class="dv">50</span>)</span>
<span id="cb26-31"><a href="#cb26-31" tabindex="-1"></a></span>
<span id="cb26-32"><a href="#cb26-32" tabindex="-1"></a>    <span class="co"># Store evaluation metrics for each threshold</span></span>
<span id="cb26-33"><a href="#cb26-33" tabindex="-1"></a>    accuracies <span class="op">=</span> []</span>
<span id="cb26-34"><a href="#cb26-34" tabindex="-1"></a>    precisions <span class="op">=</span> []</span>
<span id="cb26-35"><a href="#cb26-35" tabindex="-1"></a>    recalls <span class="op">=</span> []</span>
<span id="cb26-36"><a href="#cb26-36" tabindex="-1"></a>    f1_scores <span class="op">=</span> []</span>
<span id="cb26-37"><a href="#cb26-37" tabindex="-1"></a></span>
<span id="cb26-38"><a href="#cb26-38" tabindex="-1"></a>    <span class="co"># True labels for OOD data (since they are not part of the original labels)</span></span>
<span id="cb26-39"><a href="#cb26-39" tabindex="-1"></a>    <span class="cf">if</span> score_type <span class="op">==</span> <span class="st">"energy"</span>:</span>
<span id="cb26-40"><a href="#cb26-40" tabindex="-1"></a>        ood_true_labels <span class="op">=</span> np.full(<span class="bu">len</span>(ood_scores), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb26-41"><a href="#cb26-41" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb26-42"><a href="#cb26-42" tabindex="-1"></a>        ood_true_labels <span class="op">=</span> np.full(<span class="bu">len</span>(ood_scores[:,<span class="dv">0</span>]), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb26-43"><a href="#cb26-43" tabindex="-1"></a></span>
<span id="cb26-44"><a href="#cb26-44" tabindex="-1"></a>    <span class="cf">for</span> threshold <span class="kw">in</span> thresholds:</span>
<span id="cb26-45"><a href="#cb26-45" tabindex="-1"></a>        <span class="co"># Classify OOD examples based on scores</span></span>
<span id="cb26-46"><a href="#cb26-46" tabindex="-1"></a>        <span class="cf">if</span> score_type <span class="op">==</span> <span class="st">'energy'</span>:</span>
<span id="cb26-47"><a href="#cb26-47" tabindex="-1"></a>            ood_classifications <span class="op">=</span> np.where(ood_scores <span class="op">&gt;=</span> threshold, <span class="op">-</span><span class="dv">1</span>, ood_predictions)</span>
<span id="cb26-48"><a href="#cb26-48" tabindex="-1"></a>            id_classifications <span class="op">=</span> np.where(id_scores <span class="op">&gt;=</span> threshold, <span class="op">-</span><span class="dv">1</span>, id_predictions)</span>
<span id="cb26-49"><a href="#cb26-49" tabindex="-1"></a>        <span class="cf">elif</span> score_type <span class="op">==</span> <span class="st">'softmax'</span>:</span>
<span id="cb26-50"><a href="#cb26-50" tabindex="-1"></a>            ood_classifications <span class="op">=</span> np.where(ood_scores[:,<span class="dv">0</span>] <span class="op">&lt;=</span> threshold, <span class="op">-</span><span class="dv">1</span>, ood_predictions)</span>
<span id="cb26-51"><a href="#cb26-51" tabindex="-1"></a>            id_classifications <span class="op">=</span> np.where(id_scores[:,<span class="dv">0</span>] <span class="op">&lt;=</span> threshold, <span class="op">-</span><span class="dv">1</span>, id_predictions)</span>
<span id="cb26-52"><a href="#cb26-52" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb26-53"><a href="#cb26-53" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Invalid score_type. Use 'energy' or 'softmax'."</span>)</span>
<span id="cb26-54"><a href="#cb26-54" tabindex="-1"></a></span>
<span id="cb26-55"><a href="#cb26-55" tabindex="-1"></a>        <span class="co"># Combine OOD and ID classifications and true labels</span></span>
<span id="cb26-56"><a href="#cb26-56" tabindex="-1"></a>        all_predictions <span class="op">=</span> np.concatenate([ood_classifications, id_classifications])</span>
<span id="cb26-57"><a href="#cb26-57" tabindex="-1"></a>        all_true_labels <span class="op">=</span> np.concatenate([ood_true_labels, id_true_labels])</span>
<span id="cb26-58"><a href="#cb26-58" tabindex="-1"></a></span>
<span id="cb26-59"><a href="#cb26-59" tabindex="-1"></a>        <span class="co"># Evaluate metrics</span></span>
<span id="cb26-60"><a href="#cb26-60" tabindex="-1"></a>        precision, recall, f1, _ <span class="op">=</span> precision_recall_fscore_support(all_true_labels, all_predictions, labels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>], average<span class="op">=</span><span class="st">'macro'</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb26-61"><a href="#cb26-61" tabindex="-1"></a>        accuracy <span class="op">=</span> accuracy_score(all_true_labels, all_predictions)</span>
<span id="cb26-62"><a href="#cb26-62" tabindex="-1"></a></span>
<span id="cb26-63"><a href="#cb26-63" tabindex="-1"></a>        accuracies.append(accuracy)</span>
<span id="cb26-64"><a href="#cb26-64" tabindex="-1"></a>        precisions.append(precision)</span>
<span id="cb26-65"><a href="#cb26-65" tabindex="-1"></a>        recalls.append(recall)</span>
<span id="cb26-66"><a href="#cb26-66" tabindex="-1"></a>        f1_scores.append(f1)</span>
<span id="cb26-67"><a href="#cb26-67" tabindex="-1"></a></span>
<span id="cb26-68"><a href="#cb26-68" tabindex="-1"></a>    <span class="co"># Find the best thresholds for each metric</span></span>
<span id="cb26-69"><a href="#cb26-69" tabindex="-1"></a>    best_f1_index <span class="op">=</span> np.argmax(f1_scores)</span>
<span id="cb26-70"><a href="#cb26-70" tabindex="-1"></a>    best_f1_threshold <span class="op">=</span> thresholds[best_f1_index]</span>
<span id="cb26-71"><a href="#cb26-71" tabindex="-1"></a></span>
<span id="cb26-72"><a href="#cb26-72" tabindex="-1"></a>    best_precision_index <span class="op">=</span> np.argmax(precisions)</span>
<span id="cb26-73"><a href="#cb26-73" tabindex="-1"></a>    best_precision_threshold <span class="op">=</span> thresholds[best_precision_index]</span>
<span id="cb26-74"><a href="#cb26-74" tabindex="-1"></a></span>
<span id="cb26-75"><a href="#cb26-75" tabindex="-1"></a>    best_recall_index <span class="op">=</span> np.argmax(recalls)</span>
<span id="cb26-76"><a href="#cb26-76" tabindex="-1"></a>    best_recall_threshold <span class="op">=</span> thresholds[best_recall_index]</span>
<span id="cb26-77"><a href="#cb26-77" tabindex="-1"></a></span>
<span id="cb26-78"><a href="#cb26-78" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best F1 threshold: </span><span class="sc">{</span>best_f1_threshold<span class="sc">}</span><span class="ss">, F1 Score: </span><span class="sc">{</span>f1_scores[best_f1_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-79"><a href="#cb26-79" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best Precision threshold: </span><span class="sc">{</span>best_precision_threshold<span class="sc">}</span><span class="ss">, Precision: </span><span class="sc">{</span>precisions[best_precision_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-80"><a href="#cb26-80" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best Recall threshold: </span><span class="sc">{</span>best_recall_threshold<span class="sc">}</span><span class="ss">, Recall: </span><span class="sc">{</span>recalls[best_recall_index]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-81"><a href="#cb26-81" tabindex="-1"></a></span>
<span id="cb26-82"><a href="#cb26-82" tabindex="-1"></a>    <span class="co"># Plot metrics as functions of the threshold</span></span>
<span id="cb26-83"><a href="#cb26-83" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb26-84"><a href="#cb26-84" tabindex="-1"></a>    plt.plot(thresholds, precisions, label<span class="op">=</span><span class="st">'Precision'</span>, color<span class="op">=</span><span class="st">'g'</span>)</span>
<span id="cb26-85"><a href="#cb26-85" tabindex="-1"></a>    plt.plot(thresholds, recalls, label<span class="op">=</span><span class="st">'Recall'</span>, color<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb26-86"><a href="#cb26-86" tabindex="-1"></a>    plt.plot(thresholds, f1_scores, label<span class="op">=</span><span class="st">'F1 Score'</span>, color<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb26-87"><a href="#cb26-87" tabindex="-1"></a></span>
<span id="cb26-88"><a href="#cb26-88" tabindex="-1"></a>    <span class="co"># Add best threshold indicators</span></span>
<span id="cb26-89"><a href="#cb26-89" tabindex="-1"></a>    plt.axvline(x<span class="op">=</span>best_f1_threshold, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best F1 Threshold: </span><span class="sc">{</span>best_f1_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb26-90"><a href="#cb26-90" tabindex="-1"></a>    plt.axvline(x<span class="op">=</span>best_precision_threshold, color<span class="op">=</span><span class="st">'g'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best Precision Threshold: </span><span class="sc">{</span>best_precision_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb26-91"><a href="#cb26-91" tabindex="-1"></a>    plt.axvline(x<span class="op">=</span>best_recall_threshold, color<span class="op">=</span><span class="st">'b'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Best Recall Threshold: </span><span class="sc">{</span>best_recall_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb26-92"><a href="#cb26-92" tabindex="-1"></a></span>
<span id="cb26-93"><a href="#cb26-93" tabindex="-1"></a>    plt.xlabel(<span class="st">'Threshold'</span>)</span>
<span id="cb26-94"><a href="#cb26-94" tabindex="-1"></a>    plt.ylabel(<span class="st">'Metric Value'</span>)</span>
<span id="cb26-95"><a href="#cb26-95" tabindex="-1"></a>    plt.title(<span class="ss">f'Evaluation Metrics as Functions of Threshold (</span><span class="sc">{</span>score_type<span class="sc">.</span>capitalize()<span class="sc">}</span><span class="ss">-Based OOD Detection)'</span>)</span>
<span id="cb26-96"><a href="#cb26-96" tabindex="-1"></a>    plt.legend()</span>
<span id="cb26-97"><a href="#cb26-97" tabindex="-1"></a>    plt.show()</span>
<span id="cb26-98"><a href="#cb26-98" tabindex="-1"></a></span>
<span id="cb26-99"><a href="#cb26-99" tabindex="-1"></a>    <span class="co"># plot confusion matrix</span></span>
<span id="cb26-100"><a href="#cb26-100" tabindex="-1"></a>    <span class="co"># Threshold value for the energy score</span></span>
<span id="cb26-101"><a href="#cb26-101" tabindex="-1"></a>    upper_threshold <span class="op">=</span> best_f1_threshold  <span class="co"># Using the best F1 threshold from the previous calculation</span></span>
<span id="cb26-102"><a href="#cb26-102" tabindex="-1"></a>    <span class="cf">if</span> score_type <span class="op">==</span> <span class="st">'energy'</span>:</span>
<span id="cb26-103"><a href="#cb26-103" tabindex="-1"></a>        <span class="co"># Classifying OOD examples based on energy scores</span></span>
<span id="cb26-104"><a href="#cb26-104" tabindex="-1"></a>        ood_classifications <span class="op">=</span> np.where(ood_energy_scores <span class="op">&gt;=</span> upper_threshold, <span class="op">-</span><span class="dv">1</span>,  <span class="co"># classified as OOD</span></span>
<span id="cb26-105"><a href="#cb26-105" tabindex="-1"></a>                                  np.where(ood_energy_scores <span class="op">&lt;</span> upper_threshold, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as ID</span></span>
<span id="cb26-106"><a href="#cb26-106" tabindex="-1"></a>        <span class="co"># Classifying ID examples based on energy scores</span></span>
<span id="cb26-107"><a href="#cb26-107" tabindex="-1"></a>        id_classifications <span class="op">=</span> np.where(id_energy_scores <span class="op">&gt;=</span> upper_threshold, <span class="op">-</span><span class="dv">1</span>,  <span class="co"># classified as OOD</span></span>
<span id="cb26-108"><a href="#cb26-108" tabindex="-1"></a>                                  np.where(id_energy_scores <span class="op">&lt;</span> upper_threshold, id_true_labels, <span class="op">-</span><span class="dv">1</span>))  <span class="co"># classified as ID</span></span>
<span id="cb26-109"><a href="#cb26-109" tabindex="-1"></a>    <span class="cf">elif</span> score_type <span class="op">==</span> <span class="st">'softmax'</span>:</span>
<span id="cb26-110"><a href="#cb26-110" tabindex="-1"></a>        <span class="co"># Classifying OOD examples based on softmax scores</span></span>
<span id="cb26-111"><a href="#cb26-111" tabindex="-1"></a>        ood_classifications <span class="op">=</span> softmax_thresh_classifications(ood_scores, upper_threshold)</span>
<span id="cb26-112"><a href="#cb26-112" tabindex="-1"></a></span>
<span id="cb26-113"><a href="#cb26-113" tabindex="-1"></a>        <span class="co"># Classifying ID examples based on softmax scores</span></span>
<span id="cb26-114"><a href="#cb26-114" tabindex="-1"></a>        id_classifications <span class="op">=</span> softmax_thresh_classifications(id_scores, upper_threshold)</span>
<span id="cb26-115"><a href="#cb26-115" tabindex="-1"></a>    <span class="co"># Combine OOD and ID classifications and true labels</span></span>
<span id="cb26-116"><a href="#cb26-116" tabindex="-1"></a>    all_predictions <span class="op">=</span> np.concatenate([ood_classifications, id_classifications])</span>
<span id="cb26-117"><a href="#cb26-117" tabindex="-1"></a>    all_true_labels <span class="op">=</span> np.concatenate([ood_true_labels, id_true_labels])</span>
<span id="cb26-118"><a href="#cb26-118" tabindex="-1"></a>    <span class="co"># Confusion matrix</span></span>
<span id="cb26-119"><a href="#cb26-119" tabindex="-1"></a>    cm <span class="op">=</span> confusion_matrix(all_true_labels, all_predictions, labels<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb26-120"><a href="#cb26-120" tabindex="-1"></a></span>
<span id="cb26-121"><a href="#cb26-121" tabindex="-1"></a>    <span class="co"># Plotting the confusion matrix</span></span>
<span id="cb26-122"><a href="#cb26-122" tabindex="-1"></a>    disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>[<span class="st">"Shirt"</span>, <span class="st">"Pants"</span>, <span class="st">"OOD"</span>])</span>
<span id="cb26-123"><a href="#cb26-123" tabindex="-1"></a>    disp.plot(cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb26-124"><a href="#cb26-124" tabindex="-1"></a>    plt.title(<span class="ss">f'Confusion Matrix for OOD and ID Classification (</span><span class="sc">{</span>score_type<span class="sc">.</span>capitalize()<span class="sc">}</span><span class="ss">-Based)'</span>)</span>
<span id="cb26-125"><a href="#cb26-125" tabindex="-1"></a>    plt.show()</span>
<span id="cb26-126"><a href="#cb26-126" tabindex="-1"></a></span>
<span id="cb26-127"><a href="#cb26-127" tabindex="-1"></a></span>
<span id="cb26-128"><a href="#cb26-128" tabindex="-1"></a>    <span class="cf">return</span> best_f1_threshold, best_precision_threshold, best_recall_threshold</span>
<span id="cb26-129"><a href="#cb26-129" tabindex="-1"></a></span>
<span id="cb26-130"><a href="#cb26-130" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb26-131"><a href="#cb26-131" tabindex="-1"></a><span class="co"># Assuming id_energy_scores, ood_energy_scores, id_true_labels, and test_labels are already defined</span></span>
<span id="cb26-132"><a href="#cb26-132" tabindex="-1"></a>best_f1_threshold, best_precision_threshold, best_recall_threshold <span class="op">=</span> evaluate_ood_detection(id_energy_scores, ood_energy_scores, test_labels, test_predictions, ood_predictions, score_type<span class="op">=</span><span class="st">'energy'</span>)</span>
<span id="cb26-133"><a href="#cb26-133" tabindex="-1"></a>best_f1_threshold, best_precision_threshold, best_recall_threshold <span class="op">=</span> evaluate_ood_detection(id_softmax_scores, ood_softmax_scores, test_labels, test_predictions, ood_predictions, score_type<span class="op">=</span><span class="st">'softmax'</span>)</span></code></pre>
</div>
</div>
</div>
<div class="section level1">
<h1 id="limitations-of-our-approach-thus-far">Limitations of our approach thus far<a class="anchor" aria-label="anchor" href="#limitations-of-our-approach-thus-far"></a></h1>
<ul><li>Focus on single OOD class: More reliable/accurate thresholds
can/should be obtained using a wider variety (more classes) and larger
sample of OOD data. This is part of the challenge of OOD detection which
is that space of OOD data is vast. <strong>Possible exercise</strong>:
Redo thresholding using all remaining classes in dataset.</li>
</ul><div class="section level2">
<h2 id="references-and-supplemental-resources">References and supplemental resources<a class="anchor" aria-label="anchor" href="#references-and-supplemental-resources"></a></h2>
<ul><li><a href="https://www.youtube.com/watch?v=hgLC9_9ZCJI" class="external-link uri">https://www.youtube.com/watch?v=hgLC9_9ZCJI</a></li>
<li>Generalized Out-of-Distribution Detection: A Survey: <a href="https://arxiv.org/abs/2110.11334" class="external-link uri">https://arxiv.org/abs/2110.11334</a>
</li>
</ul><!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 --></div>
</div>



      </div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="6-confidence-intervals.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="7b-OOD-detection-distance-based.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="6-confidence-intervals.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Estimating model
        </a>
        <a class="chapter-link float-end" href="7b-OOD-detection-distance-based.html" rel="next">
          Next: OOD detection:...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries-incubator/fair-explainable-ml/edit/main/episodes/7a-OOD-detection-output-based.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries-incubator/fair-explainable-ml/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries-incubator/fair-explainable-ml/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries-incubator/fair-explainable-ml/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:apmeyer4@wisc.edu">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.10" class="external-link">sandpaper (0.16.10)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.7" class="external-link">pegboard (0.7.7)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.5" class="external-link">varnish (1.0.5)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://carpentries-incubator.github.io/fair-explainable-ml/7a-OOD-detection-output-based.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "fairness, explainability, fair machine learning, interpretable machine learning, xai, lesson, The Carpentries",
  "name": "OOD detection: overview, output-based methods",
  "creativeWorkStatus": "active",
  "url": "https://carpentries-incubator.github.io/fair-explainable-ml/7a-OOD-detection-output-based.html",
  "identifier": "https://carpentries-incubator.github.io/fair-explainable-ml/7a-OOD-detection-output-based.html",
  "dateCreated": "2023-12-05",
  "dateModified": "2024-11-15",
  "datePublished": "2024-11-15"
}

  </script><script>
		feather.replace();
	</script></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

