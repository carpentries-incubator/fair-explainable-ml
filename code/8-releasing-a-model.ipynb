{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69445e2a",
   "metadata": {},
   "source": [
    "# Documenting and releasing a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509a764",
   "metadata": {},
   "source": [
    ":::::::::::::::::::::::::::::::::::::: questions \n",
    "\n",
    "- Why is model sharing important in the context of reproducibility and responsible use?\n",
    "- What are the challenges, risks, and ethical considerations related to sharing models?\n",
    "- How can model-sharing best practices be applied using tools like model cards and the Hugging Face platform?\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::: objectives\n",
    "\n",
    "- Understand the importance of model sharing and best practices to ensure reproducibility and responsible use of models.\n",
    "- Understand the challenges, risks, and ethical concerns associated with model sharing.\n",
    "- Apply model-sharing best practices through using model cards and the Hugging Face platform.\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::: keypoints \n",
    "\n",
    "- Model cards are the standard technique for communicating information about how machine learning systems were trained and how they should and should not be used.\n",
    "- Models can be shared and reused via the Hugging Face platform.\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "## Discussion \n",
    "\n",
    "### Why should we share trained models?\n",
    "Discuss in small groups and report out: *Why do you believe it is or isn’t important to share ML models? How has model-sharing contributed to your experiences or projects?*\n",
    "\n",
    "### Challenges and risks of model sharing\n",
    "Discuss in small groups and report out: *What are some potential challenges, risks, or ethical concerns associated with model sharing and reproducing ML workflows?*\n",
    "\n",
    "## Saving the model locally\n",
    "Let's review the simplest method for sharing a model first — saving the model locally. When working with PyTorch, it's important to know how to save and load models efficiently. This process ensures that you can pause your work, share your models, or deploy them for inference without having to retrain them from scratch each time.\n",
    "\n",
    "### Defining the model\n",
    "As an example, we'll configure a simple perceptron (single hidden layer) in PyTorch. We'll define a bare bones class for this just so we can initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed23b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, config: Dict[str, int]):\n",
    "        super().__init__()\n",
    "        # Parameter is a trainable tensor initialized with random values\n",
    "        self.param = nn.Parameter(torch.rand(config[\"num_channels\"], config[\"hidden_size\"]))\n",
    "        # Linear layer (fully connected layer) for the output\n",
    "        self.linear = nn.Linear(config[\"hidden_size\"], config[\"num_classes\"])\n",
    "        # Store the configuration\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Forward pass: Add the input to the param tensor, then pass through the linear layer\n",
    "        return self.linear(x + self.param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b92c4b",
   "metadata": {},
   "source": [
    "Initialize model by calling the class with configuration settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2048f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance with specific configuration\n",
    "config = {\"num_channels\": 3, \"hidden_size\": 32, \"num_classes\": 10}\n",
    "model = MyModel(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8282a",
   "metadata": {},
   "source": [
    "Let's pretend we have trained our model and are ready to share it. We can then write a function to save out the model locally as our first step. \n",
    "\n",
    "We'll need both the model weights/biases (model.state_dict()) and the model's configuration (hyperparameter settings). We'll save the configurations as a json since a key/value format is convenient here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9340f53-a0d9-4d2c-b8b3-16d1dd542704",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b5a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to save model and config locally\n",
    "def save_model(model: nn.Module, model_path: str, config_path: str) -> None:\n",
    "    # Save model state dict (weights and biases) as a .pth file\n",
    "    torch.save(model.state_dict(), model_path) #\n",
    "    # Save config\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(model.config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d144a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and config locally\n",
    "save_model(model, \"my_awesome_model.pth\", \"my_awesome_model_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c282e2",
   "metadata": {},
   "source": [
    "To load the model back in, we can write another function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a2b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load model and config locally\n",
    "def load_model(model_class: Any, model_path: str, config_path: str) -> nn.Module:\n",
    "    # Load config\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    # Create model instance with config\n",
    "    model = model_class(config=config)\n",
    "    # Load model state dict\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and config locally\n",
    "loaded_model = load_model(MyModel, \"my_awesome_model.pth\", \"my_awesome_model_config.json\")\n",
    "\n",
    "# Verify the loaded model\n",
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a23fd",
   "metadata": {},
   "source": [
    "## Saving a model to Hugging Face\n",
    "To share your model with a wider audience, we recommend uploading your model to Hugging Face. Hugging Face is a very popular machine learning (ML) platform and community that helps users build, deploy, share, and train machine learning models. It has quickly become the go-to option for sharing models with the public.\n",
    "\n",
    "### Create a Hugging Face account and access Token\n",
    "If you haven't completed these steps from the setup, make sure to do this now.\n",
    "\n",
    "**Create account**: To create an account on Hugging Face, visit: [huggingface.co/join](https://huggingface.co/join). Enter an email address and password, and follow the instructions provided via Hugging Face (you may need to verify your email address) to complete the process.\n",
    "\n",
    "**Setup access token**: Once you have your account created, you’ll need to generate an access token so that you can upload/share models to your Hugging Face account during the workshop. To generate a token, visit the [Access Tokens setting page](https://huggingface.co/settings/tokens) after logging in. \n",
    "\n",
    "### Login to Hugging Face account\n",
    "To login, you will need to retrieve your access token from the [Access Tokens setting page](https://huggingface.co/settings/tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535546ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface-cli login\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cd1634",
   "metadata": {},
   "source": [
    "You might get a message saying you cannot authenticate through git-credential as no helper is defined on your machine. This warning message should not stop you from being able to complete this episode, but it may mean that the token won't be stored on your machine for future use. \n",
    "\n",
    "Once logged in, we will need to edit our model class definition to include Hugging Face's \"push_to_hub\" attribute. To enable the push_to_hub functionality, you'll need to include the PyTorchModelHubMixin \"mixin class\" provided by the huggingface_hub library. A mixin class is a type of class used in object-oriented programming to \"mix in\" additional properties and methods into a class. The PyTorchModelHubMixin class adds methods to your PyTorch model to enable easy saving and loading from the Hugging Face Model Hub.\n",
    "\n",
    " Here's how you can adjust the code to incorporate both saving/loading locally and pushing the model to the Hugging Face Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import PyTorchModelHubMixin # NEW\n",
    "\n",
    "class MyModel(nn.Module, PyTorchModelHubMixin): # PyTorchModelHubMixin is new\n",
    "    def __init__(self, config: Dict[str, Any]):\n",
    "        super().__init__()\n",
    "        # Initialize layers and parameters\n",
    "        self.param = nn.Parameter(torch.rand(config[\"num_channels\"], config[\"hidden_size\"]))\n",
    "        self.linear = nn.Linear(config[\"hidden_size\"], config[\"num_classes\"])\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(x + self.param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e200b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance with specific configuration\n",
    "config = {\"num_channels\": 3, \"hidden_size\": 32, \"num_classes\": 10}\n",
    "model = MyModel(config=config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# push to the hub\n",
    "model.push_to_hub(\"my-awesome-model\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65be6741",
   "metadata": {},
   "source": [
    "**Verifying**: To check your work, head back over to your Hugging Face account and click your profile icon in the top-right of the website. Click \"Profile\" from there to view all of your uploaded models. Alternatively, you can search for your username (or model name) from the [Model Hub](https://huggingface.co/models).\n",
    "\n",
    "#### Loading the model from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f5583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload\n",
    "model = MyModel.from_pretrained(\"qualiaMachine/my-awesome-model\") # adjust qualiaMachine to your username\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8969f18",
   "metadata": {},
   "source": [
    "## Uploading transformer models to Hugging Face\n",
    "\n",
    "Key Differences\n",
    "\n",
    "* **Saving and Loading the Tokenizer**: Transformer models require a tokenizer that needs to be saved and loaded with the model. This is not necessary for custom PyTorch models that typically do not require a separate tokenizer.\n",
    "* **Using Pre-trained Classes**: Transformer models use classes like AutoModelForSequenceClassification and AutoTokenizer from the transformers library, which are pre-built and designed for specific tasks (e.g., sequence classification).\n",
    "* **Methods for Saving and Loading**: The transformers library provides save_pretrained and from_pretrained methods for both models and tokenizers, which handle the serialization and deserialization processes seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0af79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load a pre-trained model and tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Save the model and tokenizer locally (hugging face functions)\n",
    "model.save_pretrained(\"my_transformer_model\")\n",
    "tokenizer.save_pretrained(\"my_transformer_model\")\n",
    "\n",
    "# Load the model and tokenizer from the saved directory\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(\"my_transformer_model\")\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(\"my_transformer_model\")\n",
    "\n",
    "# Verify the loaded model and tokenizer\n",
    "print(loaded_model)\n",
    "print(loaded_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d916fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push the model and tokenizer to Hugging Face Hub\n",
    "model.push_to_hub(\"my-awesome-transformer-model\")\n",
    "tokenizer.push_to_hub(\"my-awesome-transformer-model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c8c80-f5a9-463b-91ec-861de47d814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer from the Hugging Face Hub\n",
    "hub_model = AutoModelForSequenceClassification.from_pretrained(\"qualiaMachine/my-awesome-transformer-model\")\n",
    "hub_tokenizer = AutoTokenizer.from_pretrained(\"qualiaMachine/my-awesome-transformer-model\")\n",
    "\n",
    "# Verify the model and tokenizer loaded from the hub\n",
    "print(hub_model)\n",
    "print(hub_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09e46a",
   "metadata": {},
   "source": [
    ":::::::::::::::::::::::::::::::::::::: challenge\n",
    "\n",
    "### What pieces must be well-documented to ensure reproducible and responsible model sharing?\n",
    "Discuss in small groups and report out: *What type of information needs to be included in the documentation when sharing a model?*\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "\n",
    ":::::::::::::::::::::::::::::::::::::: challenge\n",
    "\n",
    "### Document your model\n",
    "For this challenge, you have two options:\n",
    "\n",
    "1. Start writing a model card for a model you have created for your research. This [template](https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md) from Hugging Face is a good place to start. There is no standardized format for a model card, but as we alluded to in the previous discussion, there are some pieces of info you'll always want to include.\n",
    "2. Find a model on [HuggingFace](https://huggingface.co/) that has a model card, for example, you could search for models using terms like \"sentiment classification\" or \"medical\". Read the model card and evaluate whether the information is clear and complete. Would you be able to recreate the model based on the information presented? Do you feel that there is enough information to be able to evaluate you would be able to adapt this model for your purposes? You can refer to the previous challenge's solution for ideas of what information should be included, but note that not all sections are relevant to all models.\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    ":::::::::::::: solution\n",
    "\n",
    "### Solution\n",
    "Pair up with a classmate and discuss what you wrote/read. Do model cards seem like a useful tool for you moving forwards?\n",
    "\n",
    ":::::::::::::::::::::::::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trustworthy_ML",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
