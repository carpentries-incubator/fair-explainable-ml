{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f22377e",
   "metadata": {},
   "source": [
    "# Explainability methods: linear probe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a541d",
   "metadata": {},
   "source": [
    ":::::::::::::::::::::::::::::::::::::: questions \n",
    "\n",
    "- TODO\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::: objectives\n",
    "\n",
    "- TODO\n",
    "\n",
    "::::::::::::::::::::::::::::::::::::::::::::::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd101f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by importing the necessary libraries.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # This is needed to avoid a warning from huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01bfbad",
   "metadata": {},
   "source": [
    "Now, let's set the random seed to ensure reproducibility. Setting random seeds is like setting a starting point for your machine learning adventure. It ensures that every time you train your model, it starts from the same place, using the same random numbers, making your results consistent and comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfcd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility - pick any number of your choice to set the seed. We use 42, since that is the answer to everything, after all.\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80250f6",
   "metadata": {},
   "source": [
    "##### Loading the Dataset\n",
    "Let's load our data: the IMDB Movie Review dataset. The dataset contains text reviews and their corresponding sentiment labels (positive or negative). \n",
    "The label 1 corresponds to a positive review, and 0 corresponds to a negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb08128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb_dataset(keep_samples: int = 100) -> Tuple[Dataset, Dataset, Dataset]:\n",
    "    '''\n",
    "    Load the IMDB dataset from huggingface.\n",
    "    The dataset contains text reviews and their corresponding sentiment labels (positive or negative).\n",
    "    The label 1 corresponds to a positive review, and 0 corresponds to a negative review.\n",
    "    :param keep_samples: Number of samples to keep, for faster training.\n",
    "    :return: train, dev, test datasets. Each can be treated as a dictionary with keys 'text' and 'label'.\n",
    "    '''\n",
    "    dataset = load_dataset('imdb')\n",
    "\n",
    "    # Keep only a subset of the data for faster training\n",
    "    train_dataset = Dataset.from_dict(dataset['train'].shuffle(seed=42)[:keep_samples])\n",
    "    dev_dataset = Dataset.from_dict(dataset['test'].shuffle(seed=42)[:keep_samples])\n",
    "    test_dataset = Dataset.from_dict(dataset['test'].shuffle(seed=42)[keep_samples:2*keep_samples])\n",
    "\n",
    "    # train_dataset[0] will return {'text': ...., 'label': 0}\n",
    "    logging.info(f'Loaded IMDB dataset: {len(train_dataset)} training samples, {len(dev_dataset)} dev samples, {len(test_dataset)} test samples.')\n",
    "    return train_dataset, dev_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd768987",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, dev_dataset, test_dataset = load_imdb_dataset(keep_samples=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c63eb60",
   "metadata": {},
   "source": [
    "##### Loading the Model\n",
    "\n",
    "We will load a model from huggingface, and use this model to get the embeddings for the probe.\n",
    "We use distilBERT for this example, but feel free to explore other models from huggingface after the exercise.\n",
    "\n",
    "BERT is a transformer-based model, and is known to perform well on a variety of NLP tasks.\n",
    "The model is pre-trained on a large corpus of text, and can be fine-tuned for specific tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc272aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name: str) -> Tuple[AutoModel, AutoTokenizer]:\n",
    "    '''\n",
    "    Load a model from huggingface.\n",
    "    :param model_name: Check huggingface for acceptable model names.\n",
    "    :return: Model and tokenizer.\n",
    "    '''\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name, config=config)\n",
    "    model.config.max_position_embeddings = 128  # Reducing from default 512 to 128 for computational efficiency\n",
    "\n",
    "    logging.info(f'Loaded model and tokenizer: {model_name} with {model.config.num_hidden_layers} layers, '\n",
    "                 f'hidden size {model.config.hidden_size} and sequence length {model.config.max_position_embeddings}.')\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aad0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To play around with other models, find a list of models and their model_ids at: https://huggingface.co/models\n",
    "model, tokenizer = load_model('distilbert-base-uncased') #'bert-base-uncased' has 12 layers and may take a while to process. We'll investigate distilbert instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f2539",
   "metadata": {},
   "source": [
    "Let's see what the model's architecture looks like. How many layers does it have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c895dae9",
   "metadata": {},
   "source": [
    "Let's see if your answer matches the actual number of layers in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e55967",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = model.config.num_hidden_layers\n",
    "print(f'The model has {num_layers} layers.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef0b95",
   "metadata": {},
   "source": [
    "##### Setting up the Probe\n",
    "Before we define the probing classifier or probe, let's set up some utility functions the probe will use. \n",
    "The probe will be trained from hidden representations from a specific layer of the BERT model. The `get_embeddings_from_model` function will retrieve the intermediate layer representations (also known as embeddings) from a user defined layer number.\n",
    "\n",
    "The `visualize_embeddings` method can be used to see what these high dimensional hidden embeddings would look like when converted into a 2D view. The visualization is not intended to be informative in itself, and is only an additional tool used to get a sense of what the inputs to the probing classifier may look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f142de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_from_model(model: AutoModel, tokenizer: AutoTokenizer, layer_num: int, data: list[str]) -> torch.Tensor:\n",
    "    '''\n",
    "    Get the embeddings from a model.\n",
    "    :param model: The model to use. This is needed to get the embeddings.\n",
    "    :param tokenizer: The tokenizer to use. This is needed to convert the data to input IDs.\n",
    "    :param layer_num: The layer to get embeddings from. 0 is the input embeddings, and the last layer is the output embeddings.\n",
    "    :param data: The data to get embeddings for. A list of strings.\n",
    "    :return: The embeddings. Shape is N, L, D, where N is the number of samples, L is the length of the sequence, and D is the dimensionality of the embeddings.\n",
    "    '''\n",
    "    logging.info(f'Getting embeddings from layer {layer_num} for {len(data)} samples...')\n",
    "\n",
    "    # Batch the data for computational efficiency\n",
    "    batch_size = 32\n",
    "    batch_num = 1\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i+batch_size]\n",
    "        logging.info(f'Getting embeddings for batch {batch_num}...')\n",
    "        batch_num += 1\n",
    "\n",
    "        # Tokenize the batch of data\n",
    "        inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "        # Get the embeddings from the model\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "        # Get the embeddings for the specific the layer\n",
    "        embeddings = outputs.hidden_states[layer_num]\n",
    "\n",
    "        # Concatenate the embeddings from each batch\n",
    "        if i == 0:\n",
    "            all_embeddings = embeddings\n",
    "        else:\n",
    "            all_embeddings = torch.cat([all_embeddings, embeddings], dim=0)\n",
    "\n",
    "    logging.info(f'Got embeddings for {len(data)} samples from layer {layer_num}. Shape: {all_embeddings.shape}')\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings(embeddings: torch.Tensor, labels: list, layer_num: int, save_plot: bool = False) -> None:\n",
    "    '''\n",
    "    Visualize the embeddings using t-SNE.\n",
    "    :param embeddings: The embeddings to visualize. Shape is N, L, D, where N is the number of samples, L is the length of the sequence, and D is the dimensionality of the embeddings.\n",
    "    :param labels: The labels for the embeddings. A list of integers.\n",
    "    :return: None\n",
    "    '''\n",
    "\n",
    "    # Since we are working with sentiment analysis, which is sentence based task, we can use sentence embeddings.\n",
    "    # The sentence embeddings are simply the mean of the token embeddings of that sentence.\n",
    "    sentence_embeddings = torch.mean(embeddings, dim=1)  # N, D\n",
    "\n",
    "    # Convert to numpy\n",
    "    sentence_embeddings = sentence_embeddings.detach().numpy()\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Visualize the embeddings using t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    embeddings_2d = tsne.fit_transform(sentence_embeddings)\n",
    "\n",
    "    negative_points = embeddings_2d[labels == 0]\n",
    "    positive_points = embeddings_2d[labels == 1]\n",
    "\n",
    "    # Plot the embeddings. We want to colour the datapoints by label.\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(negative_points[:, 0], negative_points[:, 1], label='Negative', color='red', marker='o', s=10, alpha=0.7)\n",
    "    ax.scatter(positive_points[:, 0], positive_points[:, 1], label='Positive', color='blue', marker='o', s=10, alpha=0.7)\n",
    "    plt.xlabel('t-SNE dimension 1')\n",
    "    plt.ylabel('t-SNE dimension 2')\n",
    "    plt.title(f't-SNE of Sentence Embeddings - Layer{layer_num}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot if needed, then display it\n",
    "    if save_plot:\n",
    "        plt.savefig(f'tsne_layer_{layer_num}.png')\n",
    "    plt.show()\n",
    "\n",
    "    logging.info('Visualized embeddings using t-SNE.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade6219c",
   "metadata": {},
   "source": [
    "Now, it's finally time to define our probe! We set this up as a class, where the probe itself is an object of this class. \n",
    "The class also contains methods used to train and evaluate the probe. \n",
    "\n",
    "Read through this code block in a bit more detail - from this whole exercise, this part provides you with the most useful takeaways on ways to define and train neural networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce14e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probe():\n",
    "    def __init__(self, hidden_dim: int = 768, class_size: int = 2)  -> None:\n",
    "        '''\n",
    "        Initialize the probe.\n",
    "        :param hidden_dim: The dimensionality of the hidden layer of the probe.\n",
    "        :param num_layers: The number of layers in the probe.\n",
    "        :return: None\n",
    "        '''\n",
    "\n",
    "        # The probe is a simple linear classifier, with a hidden layer and an output layer.\n",
    "        # The input to the probe is the embeddings from the model, and the output is the predicted class.\n",
    "\n",
    "        # Exercise: Try playing around with the hidden_dim and num_layers to see how it affects the probe's performance.\n",
    "        # But watch out: if a complex probe performs well on the task, we don't know if the performance\n",
    "        # is because of the model embeddings, or the probe itself learning the task!\n",
    "\n",
    "        self.probe = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, class_size),\n",
    "\n",
    "            # Add more layers here if needed\n",
    "\n",
    "            # Sigmoid is used to convert the hidden states into a probability distribution over the classes\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def train(self, data_embeddings: torch.Tensor, labels: torch.Tensor, num_epochs: int = 10,\n",
    "              learning_rate: float = 0.001, batch_size: int = 32) -> None:\n",
    "        '''\n",
    "        Train the probe on the embeddings of data from the model.\n",
    "        :param data_embeddings: A tensor of shape N, L, D, where N is the number of samples, L is the length of the sequence, and D is the dimensionality of the embeddings.\n",
    "        :param labels: A tensor of shape N, where N is the number of samples. Each element is the label for the corresponding sample.\n",
    "        :param num_epochs: The number of epochs to train the probe for. An epoch is one pass through the entire dataset.\n",
    "        :param learning_rate: How fast the probe learns. A hyperparameter.\n",
    "        :param batch_size: Used to batch the data for computational efficiency. A hyperparameter.\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        # Setup the loss function (training objective) for the training process.\n",
    "        # The cross-entropy loss is used for multi-class classification, and represents the negative log likelihood of the true class.\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # Setup the optimization algorithm to update the probe's parameters during training.\n",
    "        # The Adam optimizer is an extension to stochastic gradient descent, and is a popular choice.\n",
    "        optimizer = torch.optim.Adam(self.probe.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Train the probe\n",
    "        logging.info('Training the probe...')\n",
    "        for epoch in range(num_epochs):  # Pass over the data num_epochs times\n",
    "\n",
    "            for i in range(0, len(data_embeddings), batch_size):\n",
    "\n",
    "                # Iterate through one batch of data at a time\n",
    "                batch_embeddings = data_embeddings[i:i+batch_size].detach()\n",
    "                batch_labels = labels[i:i+batch_size]\n",
    "\n",
    "                # Convert to sentence embeddings, since we are performing a sentence classification task\n",
    "                batch_embeddings = torch.mean(batch_embeddings, dim=1)  # N, D\n",
    "\n",
    "                # Get the probe's predictions, given the embeddings from the model\n",
    "                outputs = self.probe(batch_embeddings)\n",
    "\n",
    "                # Calculate the loss of the predictions, against the true labels\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "\n",
    "                # Backward pass - update the probe's parameters\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        logging.info('Trained the probe.')\n",
    "\n",
    "\n",
    "    def predict(self, data_embeddings: torch.Tensor, batch_size: int = 32) -> torch.Tensor:\n",
    "        '''\n",
    "        Get the probe's predictions on the embeddings from the model, for unseen data.\n",
    "        :param data_embeddings: A tensor of shape N, L, D, where N is the number of samples, L is the length of the sequence, and D is the dimensionality of the embeddings.\n",
    "        :param batch_size: Used to batch the data for computational efficiency.\n",
    "        :return: A tensor of shape N, where N is the number of samples. Each element is the predicted class for the corresponding sample.\n",
    "        '''\n",
    "\n",
    "        # Iterate through batches\n",
    "        for i in range(0, len(data_embeddings), batch_size):\n",
    "\n",
    "            # Iterate through one batch of data at a time\n",
    "            batch_embeddings = data_embeddings[i:i+batch_size]\n",
    "\n",
    "            # Get the probe's predictions\n",
    "            outputs = self.probe(batch_embeddings)\n",
    "\n",
    "            # Get the predicted class for each sample\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Concatenate the predictions from each batch\n",
    "            if i == 0:\n",
    "                all_predicted = predicted\n",
    "            else:\n",
    "                all_predicted = torch.cat([all_predicted, predicted], dim=0)\n",
    "\n",
    "        return all_predicted\n",
    "\n",
    "\n",
    "    def evaluate(self, data_embeddings: torch.tensor, labels: torch.tensor, batch_size: int = 32) -> float:\n",
    "        '''\n",
    "        Evaluate the probe's performance by testing it on unseen data.\n",
    "        :param data_embeddings: A tensor of shape N, L, D, where N is the number of samples, L is the length of the sequence, and D is the dimensionality of the embeddings.\n",
    "        :param labels: A tensor of shape N, where N is the number of samples. Each element is the label for the corresponding sample.\n",
    "        :return: The accuracy of the probe on the unseen data.\n",
    "        '''\n",
    "\n",
    "        # Iterate through batches\n",
    "        for i in range(0, len(data_embeddings), batch_size):\n",
    "\n",
    "            # Iterate through one batch of data at a time\n",
    "            batch_embeddings = data_embeddings[i:i+batch_size]\n",
    "            batch_labels = labels[i:i+batch_size]\n",
    "\n",
    "            # Convert to sentence embeddings, since we are performing a sentence classification task\n",
    "            batch_embeddings = torch.mean(batch_embeddings, dim=1)  # N, D\n",
    "\n",
    "            # Get the probe's predictions\n",
    "            with torch.no_grad():\n",
    "                outputs = self.probe(batch_embeddings)\n",
    "\n",
    "            # Get the predicted class for each sample\n",
    "            _, predicted = torch.max(outputs, dim=-1)\n",
    "\n",
    "            # Concatenate the predictions from each batch\n",
    "            if i == 0:\n",
    "                all_predicted = predicted\n",
    "                all_labels = batch_labels\n",
    "            else:\n",
    "                all_predicted = torch.cat([all_predicted, predicted], dim=0)\n",
    "                all_labels = torch.cat([all_labels, batch_labels], dim=0)\n",
    "\n",
    "        # Calculate the accuracy of the probe\n",
    "        correct = (all_predicted == all_labels).sum().item()\n",
    "        accuracy = correct / all_labels.shape[0]\n",
    "        logging.info(f'Probe accuracy: {accuracy:.2f}')\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the probing classifier (or probe)\n",
    "probe = Probe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b861b5",
   "metadata": {},
   "source": [
    "##### Analysing the model using Probes\n",
    "\n",
    "Time to start evaluating the model using our probing tool! Let's see which layer has most information about sentiment analysis on IMDB.\n",
    "For this, we will train the probe on embeddings from each layer of the model, and see which layer performs the best on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b16cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_wise_accuracies = []\n",
    "best_probe, best_layer, best_accuracy = None, -1, 0\n",
    "\n",
    "for layer_num in range(num_layers):\n",
    "    logging.info(f'\\n\\nEvaluating representations of layer {layer_num+1}...')\n",
    "\n",
    "    train_embeddings = get_embeddings_from_model(model, tokenizer, layer_num=layer_num, data=train_dataset['text'])\n",
    "    dev_embeddings = get_embeddings_from_model(model, tokenizer, layer_num=layer_num, data=dev_dataset['text'])\n",
    "    train_labels, dev_labels = torch.tensor(train_dataset['label'],  dtype=torch.long), torch.tensor(dev_dataset['label'],  dtype=torch.long)\n",
    "\n",
    "    # Before training the probe, let's visualize the embeddings using t-SNE.\n",
    "    # If the layer has information about sentiment analysis, would we see some structure in the embeddings?\n",
    "    # Compare plots from layers where the probe does poorly, with ones where it does well. What do you notice?\n",
    "    visualize_embeddings(embeddings=train_embeddings, labels=train_dataset['label'], layer_num=layer_num, save_plot=False)\n",
    "\n",
    "    # Now, let's train the probe on the embeddings from the model.\n",
    "    # Feel free to play around with the training hyperparameters, and see what works best for your probe.\n",
    "    probe = Probe()\n",
    "    probe.train(data_embeddings=train_embeddings, labels=train_labels,\n",
    "                num_epochs=5, learning_rate=0.001, batch_size=32)\n",
    "\n",
    "    # Let's see how well our probe does on a held out dev set\n",
    "    accuracy = probe.evaluate(data_embeddings=dev_embeddings, labels=dev_labels)\n",
    "    layer_wise_accuracies.append(accuracy)\n",
    "\n",
    "    # Keep track of the best probe\n",
    "    if accuracy > best_accuracy:\n",
    "        best_probe, best_layer, best_accuracy = probe, layer_num, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c7f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing a list of accuracies can be hard to interpret. Let's plot the layer-wise accuracies to see which layer is best.\n",
    "plt.plot(layer_wise_accuracies)\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Probe Accuracy by Layer')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c7faca",
   "metadata": {},
   "source": [
    "Which layer has the best accuracy? What does this tell us about the model?\n",
    "\n",
    "Let's go ahead and stress test this. Is the best layer able to predict sentiment for sentences outside the IMDB dataset?\n",
    "\n",
    "For answering this question, you are the test set! Try to think of challenging sequences for which the model may not be able to predict sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = ['Your sentence here', 'Here is another sentence']\n",
    "embeddings = get_embeddings_from_model(model=model, tokenizer=tokenizer, layer_num=best_layer, data=test_sequences)\n",
    "preds = probe.predict(data_embeddings=embeddings)\n",
    "predictions = ['Positive' if pred == 1 else 'Negative' for pred in preds]\n",
    "print(f'Predictions for test sequences: {predictions}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
